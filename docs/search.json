[{"path":[]},{"path":"https://drizopoulos.github.io/JMbayes2/articles/Baseline_Hazard.html","id":"penalized-b-splines","dir":"Articles","previous_headings":"Baseline Hazard Function","what":"Penalized B-splines","title":"Baseline Hazard Function","text":"submodel event process joint models fitted JMbayes2 relative hazard model postulating multiplicative effect covariates hazard scale. default specification baseline hazard function h_0(t) takes form: \\log \\{ h_0(t) \\} = \\sum \\limits_{p = 1}^P \\gamma_p B_p(t, \\lambda), B_p(t, \\lambda) denotes p-th basis function B-spline knots \\lambda_1, \\ldots, \\lambda_P \\gamma vector spline coefficients. ensure smoothness baseline hazard function, postulate ‘penalized’ prior distribution spline coefficients \\gamma: p(\\gamma \\mid \\tau) \\propto \\tau^{\\rho(K)/2}\\exp \\left (-\\frac{\\tau}{2} \\gamma^\\top K \\gamma \\right ), \\tau smoothing parameter takes \\mbox{Gamma}(5, 0.5) hyper-prior ensure proper posterior, K = \\Delta_r^\\top \\Delta_r, \\Delta_r denotes r-th difference penalty matrix, \\rho(K) denotes rank K. Different baseline hazard functions can specified using base_hazard control arguments jm(). illustrate capability using AIDS dataset. start default joint model time death longitudinal measurements square root transformed CD4 cell counts: default, knots \\lambda_1, \\ldots, \\lambda_P placed equidistantly interval (10^{-8}, T_{max}), T_{max} maximum follow-time. number knots specified control argument base_hazard_segments, default value 9. degree polynomials B-spline basis specified control argument Bsplines_degree; default 2, .e., quadratic polynomials. value r penalty matrix \\Delta_r specified control argument diff; default, second-order differences used. internal function JMbayes2:::plot_hazard() can used depict estimated baseline hazard function:  default specification assumes B-spline approximation time variable original scale. However, argued flexsurv package, specification may undesirable property cumulative hazard function approach zero time zero. Additionally, default approximation baseline hazard based B-spline basis quadratic piecewise polynomial functions. override settings specifying natural cubic spline (also known restricted cubic spline) basis logarithm time using base_hazard argument:  Setting base_hazard = \"log time, ns\" corresponds setting control arguments timescale_base_hazard = \"log\" basis = \"ns\". Using regular expressions look-user input base_hazard argument, jm() function attempts set corresponding control arguments. example, following call also set natural cubic splines log time: update(jointFit1, base_hazard = \"ns, log-time\").","code":"# Cox regression CoxFit <- coxph(Surv(Time, death) ~ drug, data = aids.id)  # a linear mixed model for sqrt(CD4) cell count fm <- lme(CD4 ~ ns(obstime, 2) * drug, data = aids,            random = list(patient = pdDiag(~ ns(obstime, 2))))  # default baseline hazard jointFit1 <- jm(CoxFit, fm, time_var = \"obstime\") JMbayes2:::plot_hazard(jointFit1) jointFit2 <- update(jointFit1, base_hazard = \"log time, ns\") JMbayes2:::plot_hazard(jointFit2)"},{"path":"https://drizopoulos.github.io/JMbayes2/articles/Baseline_Hazard.html","id":"piecewise-constant","dir":"Articles","previous_headings":"Baseline Hazard Function","what":"Piecewise Constant","title":"Baseline Hazard Function","text":"fit piecewise-constant baseline hazard function splitting follow-period five equidistant intervals, use call (note piecewise-constant approximation defined time original scale ):","code":"jointFit3 <- update(jointFit1, base_hazard = \"piecewise constant\",                     base_hazard_segments = 5L) JMbayes2:::plot_hazard(jointFit3)"},{"path":"https://drizopoulos.github.io/JMbayes2/articles/Baseline_Hazard.html","id":"piecewise-linear","dir":"Articles","previous_headings":"Baseline Hazard Function","what":"Piecewise Linear","title":"Baseline Hazard Function","text":"piecewise-linear baseline hazard function log time variable three interconnected lines fitted using syntax:  Via priors argument, specified \\gamma coefficients piecewise-linear baseline hazard penalized. case, normal prior mean zero variance 10.","code":"jointFit4 <- update(jointFit1, base_hazard = \"piecewise linear, log time\",                     base_hazard_segments = 3L,                      priors = list(penalized_bs_gammas = FALSE)) JMbayes2:::plot_hazard(jointFit4)"},{"path":"https://drizopoulos.github.io/JMbayes2/articles/Baseline_Hazard.html","id":"weibull","dir":"Articles","previous_headings":"Baseline Hazard Function","what":"Weibull","title":"Baseline Hazard Function","text":"Weibull baseline hazard function log scale corresponds simple linear model intercept slope term logarithm time variable. Hence, special case models considered . can fit joint model Weibull baseline hazard using call:  baseline hazard function also allows extrapolating beyond range observed event times. Actually, extrapolation possible whenever natural cubic spline basis used. following figure, extrapolate month 24:","code":"jointFit5 <- update(jointFit1, base_hazard = \"weibull\") JMbayes2:::plot_hazard(jointFit5) JMbayes2:::plot_hazard(jointFit5, tmax = 24)"},{"path":"https://drizopoulos.github.io/JMbayes2/articles/Baseline_Hazard.html","id":"stratified-models","dir":"Articles","previous_headings":"Baseline Hazard Function","what":"Stratified Models","title":"Baseline Hazard Function","text":"case stratified models, different baseline hazard fitted per stratum. base_hazard argument can case character vector element specifying baseline hazard per stratum. example, refit Cox model stratifying drug. Via base_hazard specify ddC group baseline hazard Weibull, ddI group penalized natural cubic spline logarithm time variable:  Specifying NA element base_hazard imply default baseline hazard function used stratum.","code":"# Cox regression CoxFit2 <- coxph(Surv(Time, death) ~ strata(drug), data = aids.id)  # default baseline hazard jointFit6 <- jm(CoxFit2, fm, time_var = \"obstime\",                  base_hazard = c(\"weibull\", \"log time, ns\"))  JMbayes2:::plot_hazard(jointFit6)"},{"path":"https://drizopoulos.github.io/JMbayes2/articles/Causal_Effects.html","id":"causal-effects-from-joint-models","dir":"Articles","previous_headings":"","what":"Causal Effects from Joint Models","title":"Causal Effects","text":"illustrate calculation causal effects joint models using PBC dataset longitudinal outcome serBilir composite event transplantation death. start fitting joint model data. longitudinal submodel, specify nonlinear subject-specific trajectories using natural cubic splines. fixed-effects part, also include treatment effect interaction time. survival submodel, include treatment effect. coefficient drugD-penicil survival outcome output produced summary() method denotes residual/direct effect treatment risk composite event. include effect treatment follows via serum bilirubin pathway. illustrate calculation causal risk differences group patients distribution serum bilirubin values Patient 2:  calculate risk difference composite event active treatment D-penicillamine placebo horizon time t_horiz = 6 using longitudinal data year t0 = 4. achieve , create dataset patient’s data. patient received active treatment D-penicillamine; hence, also create version data drug variable set placebo: Note dataP2_placebo dataset, need specify drug factor two levels. also specify last time point know patient still event-free t0. estimate cumulative risk composite event t_horiz active treatment arm using predict() method: set argument return_mcmc TRUE enable calculation credible interval accounts MCMC uncertainty. produce estimate placebo arm: estimated risk difference 95% credible interval calculated corresponding elements Pr1 Pr0 objects, .e.,","code":"pbc2.id$status2 <- as.numeric(pbc2.id$status != \"alive\") lmeFit <- lme(log(serBilir) ~ ns(year, 3, B = c(0, 14.4)) * drug,                     data = pbc2, random = ~ ns(year, 3, B = c(0, 14.4)) | id,                    control = lmeControl(opt = \"optim\")) CoxFit <- coxph(Surv(years, status2) ~ drug, data = pbc2.id) jmFit <- jm(CoxFit, lmeFit, time_var = \"year\") summary(jmFit) #>  #> Call: #> jm(Surv_object = CoxFit, Mixed_objects = lmeFit, time_var = \"year\") #>  #> Data Descriptives: #> Number of Groups: 312        Number of events: 169 (54.2%) #> Number of Observations: #>   log(serBilir): 1945 #>  #>                  DIC     WAIC      LPML #> marginal    4217.836 4527.502 -2937.053 #> conditional 6503.006 6206.639 -3454.250 #>  #> Random-effects covariance matrix: #>                                                                        #>                    StdDev   Corr                                       #> (Intr)             0.9958 (Intr) n(,3,B=c(0,14.4))1 n(,3,B=c(0,14.4))2 #> n(,3,B=c(0,14.4))1 1.5005 0.2219                                       #> n(,3,B=c(0,14.4))2 1.6970 0.4318 0.7505                                #> n(,3,B=c(0,14.4))3 1.8995 0.4247 0.2076             0.6798             #>  #> Survival Outcome: #>                         Mean  StDev    2.5%  97.5%      P   Rhat #> drugD-penicil        -0.0138 0.2061 -0.4079 0.3859 0.9533 1.0037 #> value(log(serBilir))  1.3001 0.0881  1.1354 1.4741 0.0000 1.0109 #>  #> Longitudinal Outcome: log(serBilir) (family = gaussian, link = identity) #>                        Mean  StDev    2.5%  97.5%      P   Rhat #> (Intercept)          0.5863 0.0808  0.4309 0.7430 0.0000 1.0007 #> ns(,3,B=c(0,14.4))1  1.1251 0.1719  0.7905 1.4659 0.0000 1.0058 #> ns(,3,B=c(0,14.4))2  2.1954 0.2329  1.7749 2.6913 0.0000 1.0201 #> ns(,3,B=c(0,14.4))3  2.4177 0.3416  1.8350 3.1714 0.0000 1.0342 #> drugD-penicil       -0.1061 0.1163 -0.3386 0.1217 0.3633 1.0017 #> n(,3,B=c(0,14.4))1:  0.1869 0.2369 -0.2802 0.6490 0.4218 1.0055 #> n(,3,B=c(0,14.4))2: -0.4776 0.3224 -1.1454 0.1111 0.1211 1.0175 #> n(,3,B=c(0,14.4))3: -0.6994 0.4770 -1.7031 0.1481 0.1233 1.0384 #> sigma                0.2894 0.0065  0.2776 0.3027 0.0000 1.0061 #>  #> MCMC summary: #> chains: 3  #> iterations per chain: 3500  #> burn-in per chain: 500  #> thinning: 1  #> time: 20 sec xyplot(log(serBilir) ~ year, data = pbc2, subset = id == 2, type = \"b\",        xlab = \"Follow-up time (years)\", ylab = \"log{serum bilirubin (mg/dL)}\",        main = \"Patient 2\") t0 <- 4 t_horiz <- 6 dataP2_Dpenici <- pbc2[pbc2$id == 2 & pbc2$year <= t0, ] dataP2_Dpenici$years <- t0 dataP2_Dpenici$status2 <- 0  dataP2_placebo <- dataP2_Dpenici dataP2_placebo$drug <- factor(\"placebo\", levels = levels(pbc2$drug)) Pr1 <- predict(jmFit, newdata = dataP2_Dpenici, process = \"event\",                 times = t_horiz, return_mcmc = TRUE) Pr0 <- predict(jmFit, newdata = dataP2_placebo, process = \"event\",                 times = t_horiz, return_mcmc = TRUE) # estimate  Pr1$pred[2L] - Pr0$pred[2L] #> [1] 0.002916423  # MCMC variability quantile(Pr1$mcmc[2L, ] - Pr0$mcmc[2L, ], probs = c(0.025, 0.975)) #>       2.5%      97.5%  #> -0.1790905  0.1952539"},{"path":"https://drizopoulos.github.io/JMbayes2/articles/Causal_Effects.html","id":"time-varying-treatments","dir":"Articles","previous_headings":"Causal Effects from Joint Models","what":"Time-varying treatments","title":"Causal Effects","text":"extended example time-varying treatments / intermediate events showcases calculation variance causal effects includes sampling variability available .","code":""},{"path":[]},{"path":"https://drizopoulos.github.io/JMbayes2/articles/Competing_Risks.html","id":"prepare-data","dir":"Articles","previous_headings":"Competing Risks","what":"Prepare data","title":"Competing Risks","text":"first step fitting joint model competing events JMbayes2 prepare data event process. K competing events, subject must K rows, one possible cause. observed event time T_i subject repeated K times, two indicator variables, namely one identifying cause one indicating whether corresponding event type one occurred. Standard survival datasets include single row per patient can easily transformed competing risks long format using function crisk_setup(). function accepts main arguments survival data standard format single row per patient, name status variable, level status variable corresponds censoring. illustrate use function PBC data, treat competing risks transplantation death: Note patient now represented two rows (two possible causes discontinuation study, death, transplantation), event time variable years identical rows patient, variable CR denotes cause specific line long dataset, variable status2 equals 1 corresponding event occurred.","code":"pbc2.id[pbc2.id$id %in% c(1, 2, 5), c(\"id\", \"years\", \"status\")] #>   id     years       status #> 1  1  1.095170         dead #> 2  2 14.152338        alive #> 5  5  4.120578 transplanted  pbc2.idCR <- crisk_setup(pbc2.id, statusVar = \"status\", censLevel = \"alive\",                           nameStrata = \"CR\")  pbc2.idCR[pbc2.idCR$id %in% c(1, 2, 5),            c(\"id\", \"years\", \"status\", \"status2\", \"CR\")] #>     id     years       status status2           CR #> 1    1  1.095170         dead       1         dead #> 1.1  1  1.095170         dead       0 transplanted #> 2    2 14.152338        alive       0         dead #> 2.1  2 14.152338        alive       0 transplanted #> 5    5  4.120578 transplanted       0         dead #> 5.1  5  4.120578 transplanted       1 transplanted"},{"path":"https://drizopoulos.github.io/JMbayes2/articles/Competing_Risks.html","id":"fit-models","dir":"Articles","previous_headings":"Competing Risks","what":"Fit models","title":"Competing Risks","text":"event process, specify cause-specific relative risk models. Using dataset pbc2.idCR, fit corresponding cause-specific Cox regressions including interaction terms age treatment variable CR, treated stratification variable using strata() function: include two longitudinal outcomes longitudinal process: serum bilirubin prothrombin time. former, use quadratic orthogonal polynomials fixed- random-effects parts, latter, linear evolutions: specify longitudinal outcome separate association coefficient per competing risk, define corresponding functional forms: Finally, competing risks joint model fitted following call jm() (due complexity model, increased number MCMC iterations burn-period per chain):","code":"CoxFit_CR <- coxph(Surv(years, status2) ~ (age + drug) * strata(CR),                      data = pbc2.idCR) fm1 <- lme(log(serBilir) ~ poly(year, 2) * drug, data = pbc2,             random = ~ poly(year, 2) | id) fm2 <- lme(prothrombin ~ year * drug, data = pbc2, random = ~ year | id) CR_forms <- list(     \"log(serBilir)\" = ~ value(log(serBilir)):CR,     \"prothrombin\" = ~ value(prothrombin):CR ) jFit_CR <- jm(CoxFit_CR, list(fm1, fm2), time_var = \"year\",                functional_forms = CR_forms,                n_iter = 25000L, n_burnin = 5000L, n_thin = 5L)  summary(jFit_CR) #>  #> Call: #> jm(Surv_object = CoxFit_CR, Mixed_objects = list(fm1, fm2), time_var = \"year\",  #>     functional_forms = CR_forms, n_iter = 25000L, n_burnin = 5000L,  #>     n_thin = 5L) #>  #> Data Descriptives: #> Number of Groups: 312        Number of events: 169 (27.1%) #> Number of Observations: #>   log(serBilir): 1945 #>   prothrombin: 1945 #>  #>                  DIC     WAIC      LPML #> marginal    10813.89 11466.26 -6444.559 #> conditional 15750.73 15437.04 -8238.648 #>  #> Random-effects covariance matrix: #>                                               #>        StdDev    Corr                         #> (Intr) 1.3444  (Intr)  p(,2)1  p(,2)2  (Intr) #> p(,2)1 23.2294 0.7027                         #> p(,2)2 12.3415 -0.2648 -0.1463                #> (Intr) 0.7859  0.6353  0.4396  -0.3296        #> year   0.3274  0.4330  0.3402  -0.0527 0.0339 #>  #> Survival Outcome: #>                                        Mean  StDev    2.5%   97.5%      P #> age                                 -0.0750 0.0245 -0.1247 -0.0286 0.0007 #> drugD-penicil                       -0.2699 0.4003 -1.0821  0.5001 0.4993 #> age:strata(CR)dead                   0.1376 0.0240  0.0922  0.1868 0.0000 #> drugD-penicil:strata(CR)dead         0.2650 0.4329 -0.5594  1.1367 0.5497 #> value(log(serBilir)):CRtransplanted  1.0270 0.2180  0.6150  1.4722 0.0000 #> value(log(serBilir)):CRdead          1.4521 0.1138  1.2378  1.6872 0.0000 #> value(prothrombin):CRtransplanted    0.1003 0.1408 -0.1837  0.3599 0.5048 #> value(prothrombin):CRdead            0.1444 0.0481  0.0448  0.2306 0.0092 #>                                       Rhat #> age                                 1.0533 #> drugD-penicil                       1.0394 #> age:strata(CR)dead                  1.0885 #> drugD-penicil:strata(CR)dead        1.0407 #> value(log(serBilir)):CRtransplanted 1.0082 #> value(log(serBilir)):CRdead         1.0180 #> value(prothrombin):CRtransplanted   1.0679 #> value(prothrombin):CRdead           1.0233 #>  #> Longitudinal Outcome: log(serBilir) (family = gaussian, link = identity) #>                   Mean  StDev     2.5%   97.5%      P   Rhat #> (Intercept)     1.1970 0.1139   0.9742  1.4210 0.0000 1.0008 #> poly(year, 2)1 27.8727 2.9854  22.0478 33.9114 0.0000 1.0112 #> poly(year, 2)2  1.2406 1.7122  -2.1576  4.5335 0.4642 1.0083 #> drugD-penicil  -0.1908 0.1581  -0.4991  0.1205 0.2217 1.0003 #> p(,2)1         -3.1948 3.5724 -10.1371  3.7562 0.3732 1.0021 #> p(,2)2         -1.0633 2.1598  -5.2556  3.2097 0.6105 1.0025 #> sigma           0.3023 0.0062   0.2903  0.3147 0.0000 1.0001 #>  #> Longitudinal Outcome: prothrombin (family = gaussian, link = identity) #>                       Mean  StDev    2.5%   97.5%      P   Rhat #> (Intercept)        10.6336 0.0832 10.4737 10.7987 0.0000 1.0013 #> year                0.2944 0.0396  0.2170  0.3737 0.0000 1.0014 #> drugD-penicil      -0.0970 0.1170 -0.3266  0.1296 0.4068 1.0004 #> year:drugD-penicil -0.0234 0.0520 -0.1257  0.0786 0.6572 1.0000 #> sigma               1.0554 0.0203  1.0166  1.0967 0.0000 1.0012 #>  #> MCMC summary: #> chains: 3  #> iterations per chain: 25000  #> burn-in per chain: 5000  #> thinning: 5  #> time: 6.7 min"},{"path":"https://drizopoulos.github.io/JMbayes2/articles/Competing_Risks.html","id":"dynamic-predictions","dir":"Articles","previous_headings":"Competing Risks","what":"Dynamic predictions","title":"Competing Risks","text":"Based fitted competing risks joint model, illustrate (dynamic) predictions can calculated cause-specific cumulative risk probabilities. example, show calculations Patient 81 PBC dataset. First, extract data subject. first line extracts longitudinal measurements, second line extracts event times per cause (.e., death transplantation). patient died 6.95 years, make calculation cause-specific cumulative risk relevant, presume event, set event status variable status2 zero. last line combines two datasets list. Note: last step prerequisite predict() method competing risks joint model. , datasets provided arguments newdata newdata2 need named lists two components. first component needs named newdataL contain dataset longitudinal measurements. second component needs named newdataE contain dataset event information. predictions calculated using predict() method. first call function calculates prediction longitudinal outcomes times provided times argument, second call calculates cause-specific cumulative risk probabilities. setting argument return_newdata TRUE calls, can use corresponding plot() method depict predictions:","code":"ND_long <- pbc2[pbc2$id == 81, ] ND_event <- pbc2.idCR[pbc2.idCR$id == 81, ] ND_event$status2 <- 0 ND <- list(newdataL = ND_long, newdataE = ND_event) predLong <- predict(jFit_CR, newdata = ND, return_newdata = TRUE,                     times = seq(6.5, 15, length = 25))  predEvent <- predict(jFit_CR, newdata = ND, return_newdata = TRUE,                      process = \"event\")  plot(predLong, predEvent, outcomes = 1:2, ylim_long_outcome_range = FALSE,      col_line_event = c(\"#03BF3D\", \"#FF0000\"),       fill_CI_event = c(\"#03BF3D4D\", \"#FF00004D\"), pos_ylab_long = c(1.5, 11.5)) legend(x = 8.1, y = 0.45, legend = levels(pbc2.idCR$CR),         lty = 1, lwd = 2, col = c(\"#03BF3D\", \"#FF0000\"), bty = \"n\", cex = 0.8)"},{"path":[]},{"path":"https://drizopoulos.github.io/JMbayes2/articles/Dynamic_Predictions.html","id":"theory","dir":"Articles","previous_headings":"Dynamic Predictions","what":"Theory","title":"Dynamic Predictions","text":"Based general framework joint models presented earlier, interested deriving cumulative risk probabilities new subject j survived time point t provided longitudinal measurements \\mathcal Y_{kj}(t) = \\{ y_{kj}(t_{jl}); 0 \\leq t_{jl} \\leq t, l = 1, \\ldots, n_j, k = 1, \\ldots, K\\}, K denoting number longitudinal outcomes. probabilities interest \\begin{array}{l} \\pi_j(u \\mid t) = \\mbox{Pr}\\{T_j^* \\leq u \\mid T_j^* > t, \\mathcal Y_j(t), \\mathcal D_n\\}\\\\\\\\ = \\displaystyle 1 - \\int\\int \\frac{S(u \\mid b_j, \\theta)}{S(t \\mid b_j, \\theta)} \\; p\\{b_j \\mid T_j^* > t, \\mathcal Y_j(t), \\theta\\} \\; p(\\theta \\mid \\mathcal D_n) \\; db_j d\\theta, \\end{array} S(\\cdot) denotes survival function conditional random effects \\mathcal Y_j(t) = \\{\\mathcal Y_{1j}(t), \\ldots, \\mathcal Y_{Kj}(t)\\}. Combining three terms integrand, can devise Monte Carlo scheme obtain estimates probabilities, namely, Sample value \\tilde \\theta posterior parameters [\\theta \\mid \\mathcal D_n]. Sample value \\tilde b_j posterior random effects [b_j \\mid T_j^* > t, \\mathcal Y_j(t), \\tilde \\theta]. Compute ratio survival probabilities S(u \\mid \\tilde b_j, \\tilde \\theta) \\Big / S(t \\mid \\tilde b_j, \\tilde \\theta). Replicating steps L times, can estimate conditional cumulative risk probabilities 1 - \\frac{1}{L} \\sum_{l=1}^L \\frac{S(u \\mid \\tilde b_j^{(l)}, \\tilde \\theta^{(l)})}{S(t \\mid \\tilde b_j^{(l)}, \\tilde \\theta^{(l)})}, standard error calculating standard deviation across Monte Carlo samples.","code":""},{"path":"https://drizopoulos.github.io/JMbayes2/articles/Dynamic_Predictions.html","id":"example","dir":"Articles","previous_headings":"Dynamic Predictions","what":"Example","title":"Dynamic Predictions","text":"illustrate calculation dynamic predictions using package JMbayes2 trivariate joint model fitted PBC dataset longitudinal outcomes serBilir (continuous), prothrombin time (continuous), ascites (dichotomous). start fitting univariate mixed models. two continuous outcomes, allow nonlinear subject-specific time effects using natural cubic splines. ascites, postulate linear subject-specific profiles log odds. code : Following, fit Cox model time either transplantation death. first line defines composite event indicator, second one fits Cox model also included baseline covariates drug age. code : joint model fitted following call jm(): want calculate predictions longitudinal survival outcomes Patients 25 93. first step, extract data patients store data.frame ND code: use first five years follow-(line three) specify patients event-free point (lines four five). start predictions longitudinal outcomes. produced predict() method class jm objects follow lines procedure described cumulative risk probabilities. difference Step 3, instead calculating cumulative risk, calculate predicted values longitudinal outcomes. two options controlled type_pred argument, namely predictions scale response/outcome (default) linear predictor level. type argument controls whether predictions mean subject (.e., including fixed effects) subject-specific, including fixed random effects. newdata argument provide available measurements two patients. used sample random effects Step 2, presented . done Metropolis-Hastings algorithm runs n_mcmc iterations; iterations last one discarded burn-. Finally, argument n_samples corresponds value L defined specifies number Monte Carlo samples: Argument return_newdata specifies predictions returned extra columns newdata data.frame. default, 95% credible intervals also included. Using plot() method objects returned predict.jm(..., return_newdata = TRUE), can display predictions. following code, first longitudinal outcome:  want calculate predictions future time points, can accordingly specify times argument. following example, calculate predictions time t0 time 12: show predictions second outcome second patient (.e., Patient 93). achieved suitably specifying outcomes subject arguments plot() method:  continue predictions event outcome. let predict() know want cumulative risk probabilities, specify process = \"event\": predictions included extra columns corresponding data.frame. depict predictions longitudinal survival outcomes combined, provide objects plot() method:  , default, plot predictions first subject (.e., Patient 25) first longitudinal outcome (.e., log(serBilir)). However, plot() method series arguments allow users customize plot. illustrate capabilities following figure. First, specify want depict three outcomes using outcomes = 1:3 (note: max three outcomes can simultaneously displayed). Next, specify via subject argument want show predictions Patient 93. Note serum bilirubin, used log transformation specification linear mixed model. Hence, receive predictions transformed scale. show predictions original scale, use fun_long argument. three outcomes, needs list three functions. first one, corresponding serum bilirubin, exp(), two identity() wish transform predictions. Analogously, also fun_event argument transform predictions event outcome, example , set goal obtaining survival probabilities. Using arguments bg, col_points, col_line_long, col_line_event, fill_CI_long, fill_CI_event, changed appearance plot dark theme. Finally, pos_ylab_long specifies relative positive y-axis labels three longitudinal outcomes.","code":"fm1 <- lme(log(serBilir) ~ ns(year, 3) * sex, data = pbc2,            random = ~ ns(year, 3) | id, control = lmeControl(opt = 'optim'))  fm2 <- lme(prothrombin ~ ns(year, 2) * sex, data = pbc2,            random = ~ ns(year, 2) | id, control = lmeControl(opt = 'optim'))  fm3 <- mixed_model(ascites ~ year * sex, data = pbc2,                    random = ~ year | id, family = binomial()) pbc2.id$event <- as.numeric(pbc2.id$status != \"alive\") CoxFit <- coxph(Surv(years, event) ~ drug + age, data = pbc2.id) jointFit <- jm(CoxFit, list(fm1, fm2, fm3), time_var = \"year\") t0 <- 5 ND <- pbc2[pbc2$id %in% c(25, 93), ] ND <- ND[ND$year < t0, ] ND$event <- 0 ND$years <- t0 predLong1 <- predict(jointFit, newdata = ND, return_newdata = TRUE) plot(predLong1) predLong2 <- predict(jointFit, newdata = ND,                      times = seq(t0, 12, length.out = 51),                      return_newdata = TRUE) plot(predLong2, outcomes = 2, subject = 93) predSurv <- predict(jointFit, newdata = ND, process = \"event\",                     times = seq(t0, 12, length.out = 51),                     return_newdata = TRUE) plot(predLong2, predSurv) cols <- c('#F25C78', '#D973B5', '#F28322') plot(predLong2, predSurv, outcomes = 1:3, subject = 93,      fun_long = list(exp, identity, identity),      fun_event = function (x) 1 - x,      ylab_event = \"Survival Probabilities\",      ylab_long = c(\"Serum Bilirubin\", \"Prothrombin\", \"Ascites\"),      bg = '#132743', col_points = cols, col_line_long = cols,      col_line_event = '#F7F7FF', col_axis = \"white\",       fill_CI_long = c(\"#F25C7880\", \"#D973B580\", \"#F2832280\"),      fill_CI_event = \"#F7F7FF80\",      pos_ylab_long = c(1.9, 1.9, 0.08))"},{"path":"https://drizopoulos.github.io/JMbayes2/articles/Dynamic_Predictions.html","id":"predictive-accuracy","dir":"Articles","previous_headings":"Dynamic Predictions","what":"Predictive accuracy","title":"Dynamic Predictions","text":"evaluate discriminative capability model using ROC methodology. calculate components ROC curve using information year five, interested events occurring within three-year window. discriminating patients get event interval (t0, t0 + Dt], (.e., case T_j \\(5, 8]) patients survive least 8 years (.e., T_j > 8). calculations performed following call tvROC(): first line define event indicator pbc2.id data.frame. cut-point asterisk right maximizes Youden’s index. depict ROC curve, use corresponding plot() method: area ROC curve calculated tvAUC() function: function either accepts object class tvROC class jm. latter case, user must also provide newdata, Tstart Dt Thoriz arguments. used dataset one fit model, , principle, discrimination (better) assessed another dataset. tvROC() tvAUC() functions also work Cox regression models right censored data. compare added value using longitudinal data compared using baseline value markers, assess accuracy predictions, produce calibration plot:  syntax calibration_plot() function almost identical tvROC(). kernel density estimation estimated probabilities \\pi_j(t + \\Delta t \\mid t) = \\pi_j(8 \\mid 5) individuals risk year t0 data frame provided newdata argument. grey shaded area represents 95% pointwise confidence intervals predicted cumulative risks probabilities. Using calibration_metrics() function can also calculate metrics accuracy predictions: ICI mean absolute difference observed predicted probabilities, E50 median absolute difference, E90 90% percentile absolute differences. Finally, calculate Brier score overall measure predictive performance. computed tvBrier() function: Brier score evaluates predictive accuracy time Tstart + Dt. summarize predictive accuracy interval (t0, t0 + Dt] can use integrated Brier score. corresponding integral approximated using Simpson’s rule: Function tvBrier() also works Cox models, e.g., tvBrier() tvROC() also implement inverse probability censoring weights account censoring interval (t0, t0 + Dt] using Kaplan-Meier estimate censoring distribution (however, see note ): Notes: obtain valid estimates predictive accuracy measures (.e., time-varying sensitivity, specificity, Brier score) need account censoring. popular method achieve via inverse probability censoring weighting. approach valid, need model weights correctly specified. standard survival analysis, achieved either using Kaplan-Meier estimator Cox model censoring distribution. However, settings joint models used, often case censoring mechanism may depend history longitudinal outcomes complex manner. especially case consider multiple longitudinal outcomes analysis. Also, outcomes may recorded different time points per patient missing data. reasons, settings, Kaplan-Meier-based Cox-based censoring weights may difficult derive biased. functions JMbayes2 calculate predictive accuracy measures use joint-model-based weights account censoring. weights allow censoring depend possible manner history longitudinal outcomes. However, require model appropriately calibrated. calibration curve, produced calibration_plot(), calibration metrics, produced calibration_metrics()), calculated using procedure described Austin et al., 2020.","code":"pbc2$event <- as.numeric(pbc2$status != \"alive\") roc <- tvROC(jointFit, newdata = pbc2, Tstart = t0, Dt = 3) roc #>  #>  Time-dependent Sensitivity and Specificity for the Joint Model jointFit #>  #> At time: 8 #> Using information up to time: 5 (202 subjects still at risk) #> Accounting for censoring using model-based weights #>  #>    cut-off      SN      SP   #> 1     0.00 0.00000 1.00000   #> 2     0.03 0.01513 0.99812   #> 3     0.08 0.03648 0.99812   #> 4     0.09 0.03648 0.99168   #> 5     0.11 0.10052 0.99168   #> 6     0.12 0.11871 0.99072   #> 7     0.13 0.11871 0.98428   #> 8     0.14 0.11871 0.97783   #> 9     0.16 0.15223 0.97506   #> 10    0.18 0.17358 0.97506   #> 11    0.20 0.21628 0.97506   #> 12    0.21 0.23763 0.97506   #> 13    0.25 0.25898 0.97506   #> 14    0.27 0.28033 0.97506   #> 15    0.30 0.32303 0.97506   #> 16    0.31 0.34438 0.96862   #> 17    0.33 0.37464 0.96486   #> 18    0.36 0.41734 0.95842   #> 19    0.37 0.41842 0.95230   #> 20    0.40 0.43977 0.95230   #> 21    0.44 0.47216 0.94919   #> 22    0.46 0.49351 0.94919   #> 23    0.48 0.53621 0.94919   #> 24    0.52 0.53621 0.94274   #> 25    0.53 0.53621 0.93630   #> 26    0.55 0.53621 0.92985   #> 27    0.56 0.57891 0.92985   #> 28    0.58 0.60026 0.92985   #> 29    0.65 0.60026 0.92341   #> 30    0.66 0.62161 0.92341 * #> 31    0.67 0.62429 0.91133   #> 32    0.68 0.62429 0.90488   #> 33    0.69 0.62466 0.89855   #> 34    0.70 0.62466 0.89210   #> 35    0.71 0.65737 0.86975   #> 36    0.72 0.66079 0.85145   #> 37    0.73 0.68214 0.84500   #> 38    0.74 0.68625 0.83980   #> 39    0.75 0.68827 0.82108   #> 40    0.76 0.69335 0.80327   #> 41    0.78 0.71470 0.78394   #> 42    0.79 0.71976 0.77258   #> 43    0.80 0.72024 0.76628   #> 44    0.82 0.72769 0.74919   #> 45    0.83 0.72996 0.73699   #> 46    0.84 0.75692 0.71935   #> 47    0.85 0.77904 0.70025   #> 48    0.86 0.80261 0.68802   #> 49    0.87 0.80679 0.66995   #> 50    0.88 0.80679 0.66351   #> 51    0.89 0.83360 0.63937   #> 52    0.90 0.85677 0.60770   #> 53    0.91 0.86058 0.55729   #> 54    0.92 0.88370 0.52560   #> 55    0.93 0.88683 0.42987   #> 56    0.94 0.92953 0.40409   #> 57    0.95 0.95217 0.32714   #> 58    0.96 0.97586 0.24407   #> 59    0.97 0.97829 0.15457   #> 60    0.98 0.97829 0.09656   #> 61    0.99 0.99989 0.01286   #> 62    1.00 1.00000 0.00000 tvAUC(roc) #>  #>  Time-dependent AUC for the Joint Model jointFit #>  #> Estimated AUC:  0.8282 #> At time: 8 #> Using information up to time: 5 (202 subjects still at risk) #> Accounting for censoring using model-based weights baseline_Cox <- coxph(Surv(years, event) ~ drug + age + log(serBilir) +                            prothrombin + ascites, data = pbc2.id) tvAUC(baseline_Cox, newdata = pbc2.id, Tstart = t0, Dt = 3) #>  #>  Time-dependent AUC for the Cox Model baseline_Cox #>  #> Estimated AUC:  0.6736 #> At time: 8 #> Using information up to time: 5 (202 subjects still at risk) #> Accounting for censoring using model-based weights calibration_plot(jointFit, newdata = pbc2, Tstart = t0, Dt = 3) calibration_metrics(jointFit, pbc2, Tstart = 5, Dt = 3) #>        ICI        E50        E90  #> 0.02984699 0.02453557 0.05820965 tvBrier(jointFit, newdata = pbc2, Tstart = t0, Dt = 3) #>  #> Prediction Error for the Joint Model 'jointFit' #>  #> Estimated Brier score: 0.1242 #> At time: 8 #> For the 202 subjects at risk at time 5 #> Number of subjects with an event in [5, 8): 40 #> Number of subjects with a censored time in [5, 8): 58 #> Accounting for censoring using model-based weights tvBrier(jointFit, newdata = pbc2, Tstart = t0, Dt = 3, integrated = TRUE) #>  #> Prediction Error for the Joint Model 'jointFit' #>  #> Estimated Integrated Brier score: 0.0829 #> In the time interval: [5, 8) #> For the 202 subjects at risk at time 5 #> Number of subjects with an event in [5, 8): 40 #> Number of subjects with a censored time in [5, 8): 58 #> Accounting for censoring using model-based weights tvBrier(baseline_Cox, newdata = pbc2.id, Tstart = t0, Dt = 3, integrated = TRUE) #>  #> Prediction Error for the Cox Model 'baseline_Cox' #>  #> Estimated Integrated Brier score: 0.1163 #> In the time interval: [5, 8) #> For the 202 subjects at risk at time 5 #> Number of subjects with an event in [5, 8): 40 #> Number of subjects with a censored time in [5, 8): 58 #> Accounting for censoring using model-based weights tvBrier(jointFit, newdata = pbc2, Tstart = t0, Dt = 3, integrated = TRUE,         type_weights = \"IPCW\") #>  #> Prediction Error for the Joint Model 'jointFit' #>  #> Estimated Integrated Brier score: 0.0841 #> In the time interval: [5, 8) #> For the 202 subjects at risk at time 5 #> Number of subjects with an event in [5, 8): 40 #> Number of subjects with a censored time in [5, 8): 58 #> Accounting for censoring using inverse probability of censoring Kaplan-Meier weights"},{"path":[]},{"path":"https://drizopoulos.github.io/JMbayes2/articles/Dynamic_Predictions.html","id":"cross-validation","dir":"Articles","previous_headings":"Dynamic Predictions > Internal Validation","what":"Cross-Validation","title":"Dynamic Predictions","text":"calculating predictive accuracy measures presented , used dataset fitted models. known produce overoptimistic accuracy estimates. objective estimates can obtained using internal validation. section illustrates internal validation can performed JMbayes2 using cross-validation Bootstrap methods. testing training datasets techniques can created using create_folds() function. start cross-validation split pbc2 database five folds using syntax: first argument function data.frame wish split V folds. argument id_var specifies name subject’s id variable dataset. output create_folds() list two components named \"training\" \"testing\". component another list V data.frames. Next, define function fit joint models wish consider calculating predictions. function single argument data.frame used fit joint models. use parallel computing optimize computational performance fit models different training datasets. Hence, within function call library(\"JMbayes2\") load package JMbayes2 worker. output function fitted joint model wish internally validate. fit model training datasets using parallel computing facilitated parallel package (note: subsequent computations require time perform depending capabilities computing environment): calculating predictive accuracy measures testing datasets, must create event variable one. achieved following piece code: following syntax calculates integrated Brier score testing datasets follow-year t0 = 5 window Dt = 3 years (use parallel computing ): cross-validated estimate integrated Brier score average estimated Brier scores testing datasets: calculation cross-validated estimate AUC follow-year 5 window 3 years proceeds similarly:","code":"CVdats <- create_folds(pbc2, V = 5, id_var = \"id\") fit_model <- function (data) {     library(\"JMbayes2\")     # data     data$event <- as.numeric(data$status != \"alive\")     data_id <- data[!duplicated(data$id), ]     # mixed-effects models     fm1 <- lme(log(serBilir) ~ ns(year, 3) * sex, data = data,                random = list(id = pdDiag(form = ~ ns(year, 3))),                 control = lmeControl(opt = 'optim'))     fm2 <- lme(prothrombin ~ ns(year, 2) * sex, data = data,                random = list(id = pdDiag(form = ~ ns(year, 2))),                 control = lmeControl(opt = 'optim'))     fm3 <- mixed_model(ascites ~ year * sex, data = data,                        random = ~ year | id, family = binomial())     # Cox model     CoxFit <- coxph(Surv(years, event) ~ drug + age, data = data_id)     # joint model     jm(CoxFit, list(fm1, fm2, fm3), time_var = \"year\") } cl <- parallel::makeCluster(5L) Model_folds <- parallel::parLapply(cl, CVdats$training, fit_model) parallel::stopCluster(cl) CVdats$testing[] <- lapply(CVdats$testing, function (d) {     d$event <- as.numeric(d$status != \"alive\")     d }) calculate_Brier <- function (v, models, testing_data) {     library(\"JMbayes2\")     tvBrier(models[[v]], newdata = testing_data[[v]], Tstart = 5, Dt = 3,              integrated = TRUE) }  cl <- parallel::makeCluster(5L) Brier_per_fold <-      parallel::parLapply(cl, seq_len(5), calculate_Brier, models = Model_folds,                         testing_data = CVdats$testing) parallel::stopCluster(cl) average_Brier <- mean(sapply(Brier_per_fold, \"[[\", \"Brier\")) average_Brier #> [1] 0.0862818 calculate_AUC <- function (v, models, testing_data) {     library(\"JMbayes2\")     tvAUC(models[[v]], newdata = testing_data[[v]], Tstart = 5, Dt = 3) }  cl <- parallel::makeCluster(5L) AUC_per_fold <-      parallel::parLapply(cl, seq_len(5), calculate_AUC, models = Model_folds,                         testing_data = CVdats$testing) parallel::stopCluster(cl)  average_AUC <- mean(sapply(AUC_per_fold, \"[[\", \"auc\")) average_AUC #> [1] 0.8183163"},{"path":"https://drizopoulos.github.io/JMbayes2/articles/Dynamic_Predictions.html","id":"bootstrap","dir":"Articles","previous_headings":"Dynamic Predictions > Internal Validation","what":"Bootstrap","title":"Dynamic Predictions","text":"continue illustration internal validation JMbayes2 using Bootstrap method. training testing datasets created create_folds() function specifying method = \"Bootstrap\": Argument V now denotes number Bootstrap samples want create. training Bootstrap sample sample replacement original dataset pbc2. subjects used specific Bootstrap sample form testing dataset. fit joint model training datasets using parallel computing: calculating predictive accuracy measures testing datasets, must create event variable one. Following calculate integrated Brier score testing dataset compute average: evaluation model’s predictive accuracy testing datasets produce pessimistic estimate model performance. contrary, estimate integrate Brier score pbc2 dataset used fit joint model highly optimistic: Efron Tibshirani (1997) proposed .632 estimator, combines performance obtained original dataset estimates Bootstrap samples reduce upward bias: perform calculations also AUC: 95% confidence interval AUC original sample can derived calculating AUC Bootstrap training samples, .e.,","code":"bootDats <- create_folds(pbc2, V = 10, id_var = \"id\", method = \"Bootstrap\") cl <- parallel::makeCluster(5L) Model_bootSamples <- parallel::parLapply(cl, bootDats$training, fit_model) parallel::stopCluster(cl) bootDats$testing[] <- lapply(bootDats$testing, function (d) {     d$event <- as.numeric(d$status != \"alive\")     d }) cl <- parallel::makeCluster(10L) Brier_per_bootSample <-      parallel::parLapply(cl, seq_len(10), calculate_Brier, models = Model_bootSamples,                         testing_data = bootDats$testing) parallel::stopCluster(cl)  average_Brier_bootSamples <- mean(sapply(Brier_per_bootSample, \"[[\", \"Brier\")) jointFit <- fit_model(pbc2)  Brier_original <- tvBrier(jointFit, newdata = pbc2, Tstart = t0, Dt = 3,                            integrated = TRUE) 0.368 * Brier_original$Brier + 0.632 * average_Brier_bootSamples #> [1] 0.08199523 cl <- parallel::makeCluster(10L) AUC_per_bootSample <-      parallel::parLapply(cl, seq_len(10), calculate_AUC, models = Model_bootSamples,                         testing_data = bootDats$testing) parallel::stopCluster(cl)  average_AUC_bootSamples <- mean(sapply(AUC_per_bootSample, \"[[\", \"auc\"))  AUC_original <- tvAUC(jointFit, newdata = pbc2, Tstart = t0, Dt = 3)  0.368 * AUC_original$auc + 0.632 * average_AUC_bootSamples #> [1] 0.8165295 bootDats$training[] <- lapply(bootDats$training, function (d) {     d$event <- as.numeric(d$status != \"alive\")     d })  cl <- parallel::makeCluster(10L) AUC_per_bootSample_training <-      parallel::parLapply(cl, seq_len(10), calculate_AUC, models = Model_bootSamples,                          testing_data = bootDats$training) parallel::stopCluster(cl) AUC_per_bootSample_training <- sapply(AUC_per_bootSample_training, \"[[\", \"auc\")  AUC_original #>  #>  Time-dependent AUC for the Joint Model jointFit #>  #> Estimated AUC:  0.8175 #> At time: 8 #> Using information up to time: 5 (202 subjects still at risk) #> Accounting for censoring using model-based weights  # 95% Bootstrap CI quantile(AUC_per_bootSample_training, probs = c(0.025, 0.975)) #>      2.5%     97.5%  #> 0.7765123 0.8436562"},{"path":[]},{"path":"https://drizopoulos.github.io/JMbayes2/articles/JMbayes2.html","id":"univariate","dir":"Articles","previous_headings":"Fitting Joint Models with JMbayes2","what":"Univariate","title":"Univariate and Multivariate Joint Models","text":"function fits joint models JMbayes2 called jm(). three required arguments, Surv_object Cox model fitted coxph() Accelerated Failure time model fitted survreg(), Mixed_objects single list mixed models fitted either lme() mixed_model() functions, time_var character string indicating name time variable specification mixed-effects models. illustrate basic use package PBC dataset. start fitting Cox model composite event transplantation death, including sex baseline covariate: aim assess strength association risk composite event serum bilirubin levels collected follow-. describe patient-specific profiles time biomarker using linear mixed model, fixed effects, time, sex, interaction, random effects, random intercepts, random slopes. syntax fit model lme() : joint model links survival longitudinal submodels fitted following call jm() function: output summary() method provides descriptive statistics sample hand, followed fit statistics based marginal (random effects integrated using Laplace approximation) conditional random effects log-likelihood functions, followed estimated variance-covariance matrix random effects, followed estimates survival submodel, followed estimates longitudinal submodel(s), finally information MCMC fitting algorithm. default, jm() adds subject-specific linear predictor mixed model time-varying covariate survival relative risk model. output, named value(log(serBilir)) denote , default, current value functional form used. , assume instantaneous risk event specific time t associated value linear predictor longitudinal outcome time point t. Standard MCMC diagnostics available evaluate convergence. example, traceplot association coefficient value(log(serBilir)) produced following syntax:  density plot call:","code":"pbc2.id$status2 <- as.numeric(pbc2.id$status != 'alive') CoxFit <- coxph(Surv(years, status2) ~ sex, data = pbc2.id) fm1 <- lme(log(serBilir) ~ year * sex, data = pbc2, random = ~ year | id) jointFit1 <- jm(CoxFit, fm1, time_var = \"year\") summary(jointFit1) #>  #> Call: #> jm(Surv_object = CoxFit, Mixed_objects = fm1, time_var = \"year\") #>  #> Data Descriptives: #> Number of Groups: 312        Number of events: 169 (54.2%) #> Number of Observations: #>   log(serBilir): 1945 #>  #>                  DIC     WAIC      LPML #> marginal    4361.435 5361.220 -3356.241 #> conditional 3536.629 3355.317 -1907.678 #>  #> Random-effects covariance matrix: #>                      #>        StdDev   Corr #> (Intr) 1.0028 (Intr) #> year   0.1829 0.3994 #>  #> Survival Outcome: #>                         Mean  StDev    2.5%  97.5%      P   Rhat #> sexfemale            -0.1581 0.2717 -0.6499 0.3848 0.5544 1.0015 #> value(log(serBilir))  1.2433 0.0847  1.0776 1.4140 0.0000 1.0183 #>  #> Longitudinal Outcome: log(serBilir) (family = gaussian, link = identity) #>                   Mean  StDev    2.5%   97.5%      P   Rhat #> (Intercept)     0.7239 0.1720  0.3821  1.0600 0.0000 0.9997 #> year            0.2668 0.0381  0.1929  0.3444 0.0000 1.0024 #> sexfemale      -0.2639 0.1823 -0.6192  0.0882 0.1511 0.9999 #> year:sexfemale -0.0886 0.0404 -0.1681 -0.0093 0.0247 1.0028 #> sigma           0.3465 0.0065  0.3342  0.3596 0.0000 1.0101 #>  #> MCMC summary: #> chains: 3  #> iterations per chain: 3500  #> burn-in per chain: 500  #> thinning: 1  #> time: 16 sec ggtraceplot(jointFit1, \"alphas\") ggdensityplot(jointFit1, \"alphas\")"},{"path":"https://drizopoulos.github.io/JMbayes2/articles/JMbayes2.html","id":"notes","dir":"Articles","previous_headings":"Fitting Joint Models with JMbayes2 > Univariate","what":"Notes","title":"Univariate and Multivariate Joint Models","text":"ordering subjects datasets used fit mixed Cox regression models needs . units time variables mixed Cox models need .","code":""},{"path":"https://drizopoulos.github.io/JMbayes2/articles/JMbayes2.html","id":"multivariate","dir":"Articles","previous_headings":"Fitting Joint Models with JMbayes2","what":"Multivariate","title":"Univariate and Multivariate Joint Models","text":"fit joint model multiple longitudinal outcomes, provide list mixed models second argument jm(). following example, extend joint model fitted including prothrombin time log odds presence absence ascites time-varying covariates relative risk model composite event. Ascites dichotomous outcome, therefore, fit mixed-effects logistic regression model using mixed_model() function GLMMadaptive package. use || random argument mixed_model() specifies random intercepts random slopes assumed uncorrelated. addition, argument which_independent can used determine longitudinal outcomes assumed independent; , illustration, specify first (.e., serum bilirubin) second (.e., prothrombin time) longitudinal outcomes independent. assume longitudinal outcomes independent, can use jm(..., which_independent = \"\"). joint model complex, increase number MCMC iterations, number burn-iterations, thinning per chain using corresponding control arguments: survival submodel output now contains estimated coefficients value(prothrombin) value(ascites), well parameter estimates three longitudinal submodels.","code":"fm2 <- lme(prothrombin ~ year * sex, data = pbc2, random = ~ year | id) fm3 <- mixed_model(ascites ~ year + sex, data = pbc2,                    random = ~ year || id, family = binomial())  jointFit2 <- jm(CoxFit, list(fm1, fm2, fm3), time_var = \"year\",                 which_independent = cbind(1, 2),                 n_iter = 12000L, n_burnin = 2000L, n_thin = 5L) summary(jointFit2) #>  #> Call: #> jm(Surv_object = CoxFit, Mixed_objects = list(fm1, fm2, fm3),  #>     time_var = \"year\", which_independent = cbind(1, 2), n_iter = 12000L,  #>     n_burnin = 2000L, n_thin = 5L) #>  #> Data Descriptives: #> Number of Groups: 312        Number of events: 169 (54.2%) #> Number of Observations: #>   log(serBilir): 1945 #>   prothrombin: 1945 #>   ascites: 1885 #>  #>                  DIC     WAIC      LPML #> marginal    11655.22 16089.26 -8730.453 #> conditional 12879.91 12590.61 -6812.813 #>  #> Random-effects covariance matrix: #>                                                    #>        StdDev   Corr                               #> (Intr) 1.0022 (Intr)   year (Intr)    year  (Intr) #> year   0.1866 0.4490                               #> (Intr) 0.7625                                      #> year   0.3241               -0.0122                #> (Intr) 2.7049 0.5177 0.4745 0.3283  -0.0298        #> year   0.4613 0.4057 0.6660 -0.0592 0.3448         #>  #> Survival Outcome: #>                         Mean  StDev    2.5%  97.5%      P   Rhat #> sexfemale            -0.6621 0.3613 -1.3655 0.0338 0.0607 1.0140 #> value(log(serBilir))  0.4863 0.1786  0.1096 0.8212 0.0147 1.0545 #> value(prothrombin)   -0.0583 0.1244 -0.3296 0.1735 0.6293 1.0612 #> value(ascites)        0.6227 0.1460  0.3708 0.9518 0.0000 1.0703 #>  #> Longitudinal Outcome: log(serBilir) (family = gaussian, link = identity) #>                   Mean  StDev    2.5%   97.5%     P   Rhat #> (Intercept)     0.6926 0.1691  0.3584  1.0311 0.000 1.0003 #> year            0.2694 0.0349  0.2005  0.3383 0.000 1.0004 #> sexfemale      -0.2357 0.1795 -0.5953  0.1183 0.190 1.0002 #> year:sexfemale -0.0800 0.0362 -0.1508 -0.0097 0.024 1.0022 #> sigma           0.3480 0.0068  0.3347  0.3617 0.000 1.0047 #>  #> Longitudinal Outcome: prothrombin (family = gaussian, link = identity) #>                   Mean  StDev    2.5%   97.5%      P   Rhat #> (Intercept)    10.9863 0.1728 10.6532 11.3254 0.0000 1.0033 #> year            0.2081 0.0774  0.0592  0.3599 0.0070 1.0065 #> sexfemale      -0.4422 0.1831 -0.8040 -0.0912 0.0100 1.0051 #> year:sexfemale  0.0470 0.0809 -0.1130  0.2029 0.5577 1.0088 #> sigma           1.0569 0.0202  1.0185  1.0975 0.0000 1.0004 #>  #> Longitudinal Outcome: ascites (family = binomial, link = logit) #>                Mean  StDev    2.5%   97.5%      P   Rhat #> (Intercept) -4.4912 0.6735 -5.9197 -3.2356 0.0000 1.0121 #> year         0.6393 0.0684  0.5128  0.7854 0.0000 1.0651 #> sexfemale   -0.5556 0.6565 -1.8222  0.7787 0.3913 1.0021 #>  #> MCMC summary: #> chains: 3  #> iterations per chain: 12000  #> burn-in per chain: 2000  #> thinning: 5  #> time: 2 min"},{"path":"https://drizopoulos.github.io/JMbayes2/articles/JMbayes2.html","id":"functional-forms","dir":"Articles","previous_headings":"Fitting Joint Models with JMbayes2","what":"Functional forms","title":"Univariate and Multivariate Joint Models","text":"mentioned , default call jm() includes subject-specific linear predictors mixed-effects models time-varying covariates relative risk model. However, just one many possibilities linking longitudinal survival outcomes. argument functional_forms jm() provides additional options. Based previous experience, two extra functional forms provided: time-varying slope time-varying normalized area/cumulative effect. time-varying slope first-order derivative subject-specific linear predictor mixed-effect model respect (follow-) time variable. time-varying normalized area/cumulative effect integral subject-specific linear predictor mixed-effect model zero current (follow-) time t divided t. integral area subject-specific longitudinal profile; dividing integral t, obtain average subject-specific longitudinal profile corresponding period (0, t). illustrate functional_forms argument can used specify functional forms, update joint model jointFit2 including time-varying slope log serum bilirubin instead value also interaction slope sex prothrombin include normalized cumulative effect. ascites, keep current value functional form. corresponding syntax fit model : seen , functional_forms argument named list elements corresponding longitudinal outcomes. longitudinal outcome specified list, default value functional form used outcome. element list one-sided R formula functions value(), slope(), area() can used. Interaction terms functional forms (baseline) covariates also allowed.","code":"fForms <- list(   \"log(serBilir)\" = ~ slope(log(serBilir)) + slope(log(serBilir)):sex,   \"prothrombin\" = ~ area(prothrombin) )  jointFit3 <- update(jointFit2, functional_forms = fForms) summary(jointFit3) #>  #> Call: #> jm(Surv_object = CoxFit, Mixed_objects = list(fm1, fm2, fm3),  #>     time_var = \"year\", functional_forms = fForms, which_independent = cbind(1,  #>         2), n_iter = 12000L, n_burnin = 2000L, n_thin = 5L) #>  #> Data Descriptives: #> Number of Groups: 312        Number of events: 169 (54.2%) #> Number of Observations: #>   log(serBilir): 1945 #>   prothrombin: 1945 #>   ascites: 1885 #>  #>                  DIC     WAIC      LPML #> marginal    11692.23 12995.55 -7306.362 #> conditional 12656.91 12381.64 -6669.114 #>  #> Random-effects covariance matrix: #>                                                    #>        StdDev   Corr                               #> (Intr) 0.9989 (Intr)   year (Intr)    year  (Intr) #> year   0.1853 0.4548                               #> (Intr) 0.7500                                      #> year   0.3232               -0.0047                #> (Intr) 2.5559 0.5529 0.4692 0.3487  -0.0775        #> year   0.4361 0.4303 0.6690 -0.0720 0.3773         #>  #> Survival Outcome: #>                                   Mean  StDev     2.5%  97.5%      P   Rhat #> sexfemale                       0.3595 0.9644  -1.3670 2.3829 0.7557 1.0662 #> slope(log(serBilir))            4.3938 2.5197  -0.0624 9.5851 0.0577 1.1294 #> slope(log(serBilir)):sexfemale -4.3880 3.0045 -11.1525 0.5844 0.1020 1.1396 #> area(prothrombin)              -0.4097 0.3097  -0.9998 0.1627 0.1957 1.3476 #> value(ascites)                  1.0639 0.2373   0.6257 1.5698 0.0000 1.3015 #>  #> Longitudinal Outcome: log(serBilir) (family = gaussian, link = identity) #>                   Mean  StDev    2.5%   97.5%      P   Rhat #> (Intercept)     0.6684 0.1660  0.3397  0.9945 0.0003 1.0079 #> year            0.2658 0.0336  0.2025  0.3346 0.0000 1.0005 #> sexfemale      -0.2049 0.1768 -0.5497  0.1392 0.2433 1.0087 #> year:sexfemale -0.0745 0.0348 -0.1450 -0.0079 0.0270 1.0008 #> sigma           0.3483 0.0066  0.3352  0.3615 0.0000 1.0046 #>  #> Longitudinal Outcome: prothrombin (family = gaussian, link = identity) #>                   Mean  StDev    2.5%   97.5%      P   Rhat #> (Intercept)    10.9993 0.1684 10.6565 11.3294 0.0000 1.0003 #> year            0.1839 0.0764  0.0325  0.3362 0.0140 1.0056 #> sexfemale      -0.4574 0.1786 -0.7983 -0.1039 0.0140 1.0006 #> year:sexfemale  0.0702 0.0806 -0.0884  0.2279 0.3857 1.0058 #> sigma           1.0591 0.0203  1.0197  1.0994 0.0000 1.0152 #>  #> Longitudinal Outcome: ascites (family = binomial, link = logit) #>                Mean  StDev    2.5%   97.5%      P   Rhat #> (Intercept) -4.4105 0.6235 -5.7030 -3.2274 0.0000 1.0378 #> year         0.6304 0.0777  0.4830  0.7938 0.0000 1.2194 #> sexfemale   -0.4225 0.6122 -1.6453  0.7616 0.4833 1.0057 #>  #> MCMC summary: #> chains: 3  #> iterations per chain: 12000  #> burn-in per chain: 2000  #> thinning: 5  #> time: 2.1 min"},{"path":"https://drizopoulos.github.io/JMbayes2/articles/JMbayes2.html","id":"penalized-coefficients-using-shrinkage-priors","dir":"Articles","previous_headings":"Fitting Joint Models with JMbayes2","what":"Penalized Coefficients using Shrinkage Priors","title":"Univariate and Multivariate Joint Models","text":"multiple longitudinal outcomes considered possibly different functional forms per outcome, require fit relative risk model containing several terms. Moreover, often scientific interest select terms/functional forms per longitudinal outcome strongly associated risk event interest. facilitate selection, jm() allows penalizing regression coefficients using shrinkage priors. example, refit jointFit3 assuming Horseshoe prior alphas coefficients (.e., coefficients longitudinal outcomes relative risk model): Apart Horseshoe prior, ridge prior also provided.","code":"jointFit4 <- update(jointFit3, priors = list(\"penalty_alphas\" = \"horseshoe\")) cbind(\"un-penalized\" = unlist(coef(jointFit3)),        \"penalized\" = unlist(coef(jointFit4))) #>                                            un-penalized  penalized #> gammas.Mean                                   0.3594950 -0.5053443 #> association.slope(log(serBilir))              4.3938467  2.0175752 #> association.slope(log(serBilir)):sexfemale   -4.3879624 -0.8996426 #> association.area(prothrombin)                -0.4096893 -0.1321933 #> association.value(ascites)                    1.0639313  0.8572684"},{"path":[]},{"path":"https://drizopoulos.github.io/JMbayes2/articles/Multi_State_Processes.html","id":"introduction","dir":"Articles","previous_headings":"Multi-state Processes","what":"Introduction","title":"Multi-State Processes","text":"subject may often transition multiple states, interested assessing association longitudinal marker(s) transitions. vignette illustrates achieve using JMbayes2. consider simple case one longitudinal outcome three-state (illness-death) model, application can extended cases multiple longitudinal markers three states.","code":""},{"path":"https://drizopoulos.github.io/JMbayes2/articles/Multi_State_Processes.html","id":"data","dir":"Articles","previous_headings":"Multi-state Processes","what":"Data","title":"Multi-State Processes","text":"First, simulate data joint model single linear mixed effects model multi-state process three possible states. multi-state process can visualized : subjects start state “Healthy” can transition either state “Illness” state “Death” directly state “Death.” case, states “Healthy” “Illness” transient states subject, occupying states, can still transition states, whereas “Death” absorbing state subject reaches state, transitions can occur. means three transitions possible: 1 \\rightarrow 2, 1 \\rightarrow 3 2 \\rightarrow 3 transition intensities h_{12}\\left(t\\right), h_{13}\\left(t\\right) h_{23}\\left(t\\right) respectively. example, default functional form assumed, .e., linear predictor \\eta(t) mixed model associated transition intensity time t. following piece code simulates data: data multi-state process need appropriate long format: example, subject 1 experienced following transition: 1 \\rightarrow 2 therefore represented 3 rows, one transition, transitions plausible. hand, subject 2 represented two rows, transitions 1 \\rightarrow 2 1 \\rightarrow 3 since transitions possible state 1. Since subject 2 never actually transitioned state 2, transition 2 \\rightarrow 3 never possible, therefore, row transition dataset. also important note time dataset follows counting process formulation intervals specified Tstart Tstop variable (case transition) indicating transition row corresponds .","code":"# Set seed for reproducibility set.seed(1710)  # Sample sizes and settings N <- 1500 n_per <- 14  # Baseline covariate (binary) X <- rbinom(N, 1, 0.5)  # Longitudinal parameters beta <- c(5, -0.1) sigma_e <- 1 D <- matrix(c(1.0, 0.2, 0.2, 0.3), 2, 2) b <- MASS::mvrnorm(N, mu = c(0, 0), Sigma = D)  # Simulate longitudinal data df_long <- do.call(rbind, lapply(1:N, function(i) {     obs_times <- sort(c(0, runif(n_per - 1, 0, 18)))     XX <- cbind(1, obs_times)     eta <- XX %*% beta + XX %*% b[i, ]     y <- rnorm(n_per, eta, sigma_e)     data.frame(id = i, time = obs_times, y = y, X = X[i]) }))  # Weibull hazard parameters (shape, scale), association, covariate effects weib_shape <- c(2.2, 1.8, 2.5) weib_scale <- c(0.04, 0.03, 0.05) alpha <- c(0.6, 0.4, 0.8) # different for each transition gamma <- c(0.5, -0.3, 0.7) # different for each transition Ctimes <- runif(N, 7, 10)  # Longitudinal trajectory function yfun <- function(b_i, t) beta[1] + b_i[1] + (beta[2] + b_i[2]) * t  # Simulate event time via inverse transform sim_time <- function(shape, scale, alpha, gamma, X, b_i, tmax = 20) {     U <- runif(1)     cumhaz <- function(t) {         integrate(function(s) {             h0 <- shape * scale * (scale * s)^(shape - 1)             h0 * exp(alpha * yfun(b_i, s) + gamma * X)         }, 0, t)$value     }     f <- function(t) cumhaz(t) + log(U)     out <- try(uniroot(f, c(1e-5, tmax))$root, silent = TRUE)     if (inherits(out, \"try-error\")) Inf else out }  # Simulate multi-state transitions df_surv <- do.call(rbind, lapply(1:N, function(i) {     b_i <- b[i, ]; X_i <- X[i]; C <- Ctimes[i]     T01 <- sim_time(weib_shape[1], weib_scale[1], alpha[1], gamma[1], X_i, b_i)     T02 <- sim_time(weib_shape[2], weib_scale[2], alpha[2], gamma[2], X_i, b_i)          if (T01 < T02 && T01 < C) {         T12 <- sim_time(weib_shape[3], weib_scale[3], alpha[3], gamma[3], X_i, b_i)         Tdeath <- T01 + T12         data.frame(id = i,                     transition = c(1, 2, 3),                     Tstart = c(0, 0, T01),                     Tstop = c(T01, T01, min(Tdeath, C)),                     status = c(1, 0, as.integer(T12 < (C - T01))),                     X = X_i)     } else if (T02 < C) {         data.frame(id = i, transition = c(1, 2), Tstart = c(0, 0), Tstop = c(T02, T02), status = c(0, 1), X = X_i)     } else {         data.frame(id = i,                    transition = c(1, 2),                    Tstart = 0,                    Tstop = C,                    status = 0,                    X = X_i)     } }))  # Filter longitudinal data to observed period df_long2 <- merge(df_long, df_surv[, c(\"id\", \"Tstop\")], by = c(\"id\")) df_long2 <- df_long2[!duplicated(df_long2, by = c('id', 'time')), ] df_long2 <- df_long2[df_long2$time <= df_long2$Tstop, ] head(df_surv, n = 5L) #>   id transition   Tstart    Tstop status X #> 1  1          1 0.000000 1.014016      1 0 #> 2  1          2 0.000000 1.014016      0 0 #> 3  1          3 1.014016 1.971082      1 0 #> 4  2          1 0.000000 7.231688      0 1 #> 5  2          2 0.000000 7.231688      0 1"},{"path":"https://drizopoulos.github.io/JMbayes2/articles/Multi_State_Processes.html","id":"fitting-the-model","dir":"Articles","previous_headings":"Multi-state Processes","what":"Fitting the model","title":"Multi-State Processes","text":"data appropriate format available, fitting model straightforward. First fit linear mixed model using lme() function package nlme: , fit multi-state model using function coxph() package survival, making sure use counting process specification add strata(transition) stratify transition indicator variable dataset. Furthermore, add interaction covariate X transition allow effect covariate vary across transitions. Finally, fit joint model, simply run: differs default call jm() addition functional_forms argument specifying want “interaction” marker’s value transition, translates separate association parameter longitudinal marker transition.","code":"mixedmodel <- lme(y ~ time, random = ~ time | id, data = df_long2) msmodel <- coxph(Surv(Tstart, Tstop, status) ~ X:strata(transition), data = df_surv) jm_ms_model <- jm(msmodel, mixedmodel, time_var = \"time\", n_iter = 5000L,                   functional_forms = ~ value(y):strata(transition))  summary(jm_ms_model) #>  #> Call: #> jm(Surv_object = msmodel, Mixed_objects = mixedmodel, time_var = \"time\",  #>     functional_forms = ~value(y):strata(transition), n_iter = 5000L) #>  #> Data Descriptives: #> Number of Groups: 1500       Number of events: 1784 (45.8%) #> Number of Observations: #>   y: 11573 #>  #>                  DIC     WAIC      LPML #> marginal    46878.89 46819.94 -23410.00 #> conditional 49735.76 48815.58 -25551.82 #>  #> Random-effects covariance matrix: #>                      #>        StdDev   Corr #> (Intr) 1.0559 (Intr) #> time   0.5624 0.2185 #>  #> Survival Outcome: #>                                            Mean  StDev    2.5%  97.5%     P #> X:strata(transition)transition=1         0.4802 0.1091  0.2696 0.7001 0.000 #> X:strata(transition)transition=2        -0.2421 0.1541 -0.5442 0.0593 0.115 #> X:strata(transition)transition=3         0.6566 0.0821  0.4999 0.8175 0.000 #> value(y):strata(transition)transition=1  0.5593 0.0227  0.5173 0.6044 0.000 #> value(y):strata(transition)transition=2  0.3224 0.0422  0.2342 0.4012 0.000 #> value(y):strata(transition)transition=3  0.2993 0.0185  0.2653 0.3394 0.000 #>                                           Rhat #> X:strata(transition)transition=1        1.0070 #> X:strata(transition)transition=2        1.0160 #> X:strata(transition)transition=3        1.0349 #> value(y):strata(transition)transition=1 1.0534 #> value(y):strata(transition)transition=2 1.0910 #> value(y):strata(transition)transition=3 1.2216 #>  #> Longitudinal Outcome: y (family = gaussian, link = identity) #>                Mean  StDev    2.5%   97.5% P   Rhat #> (Intercept)  5.0100 0.0309  4.9507  5.0713 0 0.9998 #> time        -0.1051 0.0167 -0.1377 -0.0726 0 1.0054 #> sigma        0.9313 0.0071  0.9174  0.9450 0 1.0004 #>  #> MCMC summary: #> chains: 3  #> iterations per chain: 5000  #> burn-in per chain: 500  #> thinning: 1  #> time: 4.4 min"},{"path":"https://drizopoulos.github.io/JMbayes2/articles/Non_Gaussian_Mixed_Models.html","id":"non-gaussian-joint-models-with-jmbayes2","dir":"Articles","previous_headings":"","what":"Non-Gaussian Joint Models with JMbayes2","title":"Non-Gaussian Mixed Models","text":"Taking advantage versatility GLMMadaptive package, JMbayes2 can fit joint models several different types mixed-effects models. following examples illustrate capabilities. examples structure, namely, first, short motivation mixed-model given, followed piece R code simulating data joint model respective mixed-effects sub-model, closing syntax fit joint model. last part, main difference per example call mixed_model().","code":""},{"path":"https://drizopoulos.github.io/JMbayes2/articles/Non_Gaussian_Mixed_Models.html","id":"beta-mixed-models","dir":"Articles","previous_headings":"Non-Gaussian Joint Models with JMbayes2","what":"Beta mixed models","title":"Non-Gaussian Mixed Models","text":"exceptions, continuous outcomes wish analyze natural bounds. example, levels blood biomarkers set patients. However, observations often located far away natural bounds, assumption normal distribution outcome can safely made. settings, though, can outcomes substantial percentage observations located near boundaries, leading skewed U-shaped distributions. linear mixed model normal error terms often fit longitudinal outcomes well. natural alternative select distribution respects bounded nature outcome. well-known distribution outcomes Beta distribution defined (0, 1) interval (note: bounded outcome Y^* (, b) interval can transformed Y = (Y^* - ) / (b - ) (0, 1) interval). following code illustrates simulate data joint model Beta mixed effects model. default functional form assumed, .e., linear predictor \\eta(t) mixed model associated hazard event time t. linear predictor related mean \\mu(t) Beta distribution logit link function, .e., \\log[\\mu(t) / \\{1 - \\mu(t)\\}] = \\eta(t). fit corresponding joint model, fit first Beta mixed model using beta.fam() family object call mixed_model():","code":"set.seed(1234) n <- 200 # number of subjects K <- 8 # number of measurements per subject t_max <- 10 # maximum follow-up time  # we construct a data frame with the design: # everyone has a baseline measurement, and then measurements at random  # follow-up times up to t_max DF <- data.frame(id = rep(seq_len(n), each = K),                  time = c(replicate(n, c(0, sort(runif(K - 1, 0, t_max))))),                  sex = rep(gl(2, n/2, labels = c(\"male\", \"female\")), each = K))  # design matrices for the fixed and random effects X <- model.matrix(~ sex * time, data = DF) Z <- model.matrix(~ time, data = DF)  betas <- c(-2.2, -0.25, 0.24, -0.05) # fixed effects coefficients phi <- 5 # precision parameter of the Beta distribution D11 <- 1.0 # variance of random intercepts D22 <- 0.5 # variance of random slopes  # we simulate random effects b <- cbind(rnorm(n, sd = sqrt(D11)), rnorm(n, sd = sqrt(D22))) # linear predictor eta_y <- as.vector(X %*% betas + rowSums(Z * b[DF$id, ])) # mean of the Beta distribution mu_y <- plogis(eta_y) # plogis(eta_y) = exp(eta_y) / (1 + exp(eta_y)) # we simulate Beta longitudinal data DF$y <- rbeta(n * K, shape1 = mu_y * phi, shape2 = phi * (1 - mu_y)) # we transform to (0, 1) DF$y <- (DF$y * (nrow(DF) - 1) + 0.5) / nrow(DF)  upp_Cens <- 15 # fixed Type I censoring time shape_wb <- 5 # shape Weibull alpha <- 0.8 # association coefficients gammas <- c(\"(Intercept)\" = -9, \"sex\" = 0.5) W <- model.matrix(~ sex, data = DF[!duplicated(DF$id), ]) # linear predictor for the survival model eta_t <- as.vector(W %*% gammas) # to simulate event times we use inverse transform sampling # (https://en.wikipedia.org/wiki/Inverse_transform_sampling). Namely, we want  # to find t, such that S(t) = u, where S(.) is the survival function, and u a  # number from the Unif(0, 1) distribution. The function below calculates  # log(u) - log(S(t)), and for a given u, we want to find t for which it equals # zero. We do that below using the uniroot() function invS <- function (t, i) {   # i denotes the subject   sex_i <- W[i, 2L]   # h() is the hazard function and we assume a Weibull baseline hazard   h <- function (s) {     X_at_s <- cbind(1, sex_i, s, sex_i * s)     Z_at_s <- cbind(1, s)     # the linear predictor from the mixed model evaluated at time s     f <- as.vector(X_at_s %*% betas +                      rowSums(Z_at_s * b[rep(i, nrow(Z_at_s)), ]))     exp(log(shape_wb) + (shape_wb - 1) * log(s) + eta_t[i] + f * alpha)   }   # -log(S(t)) = H(t), where H(t) is the cumulative hazard function   integrate(h, lower = 0, upper = t)$value + log(u[i]) } # we simulate the event times u <- runif(n) trueTimes <- numeric(n) for (i in seq_len(n)) {     Up <- 100     Root <- try(uniroot(invS, interval = c(1e-05, Up), i = i)$root, TRUE)     trueTimes[i] <- if (!inherits(Root, \"try-error\")) Root else 150 }  # we use fixed Type I right censoring denoting the end of the trial. Ctimes <- upp_Cens Time <- pmin(trueTimes, Ctimes) event <- as.numeric(trueTimes <= Ctimes) # event indicator  # we keep the longitudinal measurements before the event times DF$Time <- Time[DF$id] DF$event <- event[DF$id] DF <- DF[DF$time <= DF$Time, ] DF_id <- DF[!duplicated(DF$id), ] Cox_fit <- coxph(Surv(Time, event) ~ sex, data = DF_id) Beta_MixMod <- mixed_model(y ~ sex * time, random = ~ time | id, data = DF,                            family = beta.fam())  jointFit <- jm(Cox_fit, Beta_MixMod, time_var = \"time\") summary(jointFit) #>  #> Call: #> jm(Surv_object = Cox_fit, Mixed_objects = Beta_MixMod, time_var = \"time\") #>  #> Data Descriptives: #> Number of Groups: 200        Number of events: 158 (79%) #> Number of Observations: #>   y: 1182 #>  #>                   DIC      WAIC     LPML #> marginal    -4018.171 -4061.024 1910.317 #> conditional -3837.701 -3938.538 1799.508 #>  #> Random-effects covariance matrix: #>                      #>        StdDev   Corr #> (Intr) 0.8436 (Intr) #> time   0.4664 0.0812 #>  #> Survival Outcome: #>             Mean  StDev    2.5%  97.5%      P   Rhat #> sexfemale 0.2153 0.2944 -0.3672 0.7865 0.4669 1.0030 #> value(y)  1.0656 0.1018  0.8866 1.2781 0.0000 1.0832 #>  #> Longitudinal Outcome: y (family = beta, link = logit) #>                   Mean  StDev    2.5%   97.5%      P   Rhat #> (Intercept)    -2.3410 0.1115 -2.5592 -2.1270 0.0000 1.0046 #> sexfemale      -0.0689 0.1486 -0.3584  0.2241 0.6462 1.0144 #> time            0.3271 0.0523  0.2258  0.4312 0.0000 1.0022 #> sexfemale:time -0.0615 0.0729 -0.2035  0.0801 0.3898 1.0059 #> sigma           6.2757 0.3932  5.5169  7.0813 0.0000 1.0064 #>  #> MCMC summary: #> chains: 3  #> iterations per chain: 3500  #> burn-in per chain: 500  #> thinning: 1  #> time: 20 sec"},{"path":"https://drizopoulos.github.io/JMbayes2/articles/Non_Gaussian_Mixed_Models.html","id":"censored-linear-mixed-models","dir":"Articles","previous_headings":"Non-Gaussian Joint Models with JMbayes2","what":"Censored linear mixed models","title":"Non-Gaussian Mixed Models","text":"continuous longitudinal outcomes may censored nature. typical example outcomes limit detection issue. , values outcome detected specified threshold (laboratory) equipment used determine measurements. settings, even complete data follows normal distribution observed censored data analyzed using standard mixed model. mixed_model() function can accommodate outcomes using censored.normal() family object. following code simulates data joint model linear mixed model longitudinal outcomes applies censoring realized longitudinal observations. corresponding joint model fitted following syntax:","code":"set.seed(1234) n <- 200 # number of subjects K <- 12 # number of measurements per subject t_max <- 14 # maximum follow-up time  # we construct a data frame with the design: # everyone has a baseline measurement, and then measurements at random  # follow-up times up to t_max DF <- data.frame(id = rep(seq_len(n), each = K),                  time = c(replicate(n, c(0, sort(runif(K - 1, 0, t_max))))),                  sex = rep(gl(2, n/2, labels = c(\"male\", \"female\")), each = K))  # design matrices for the fixed and random effects X <- model.matrix(~ sex * time, data = DF) Z <- model.matrix(~ time, data = DF)  betas <- c(-2.2, -0.25, 0.24, -0.05) # fixed effects coefficients sigma <- 0.5 # errors' standard deviation D11 <- 1.0 # variance of random intercepts D22 <- 0.5 # variance of random slopes  # we simulate random effects b <- cbind(rnorm(n, sd = sqrt(D11)), rnorm(n, sd = sqrt(D22))) # linear predictor eta_y <- as.vector(X %*% betas + rowSums(Z * b[DF$id, ])) # we simulate normal longitudinal data DF$y <- rnorm(n * K, mean = eta_y, sd = sigma) # we assume that values below -4 are not observed, and set equal to -4 DF$ind <- as.numeric(DF$y < -4) DF$y <- pmax(DF$y, -4)  upp_Cens <- 15 # fixed Type I censoring time shape_wb <- 5 # shape Weibull alpha <- 0.8 # association coefficients gammas <- c(\"(Intercept)\" = -9, \"sex\" = 0.5) W <- model.matrix(~ sex, data = DF[!duplicated(DF$id), ]) # linear predictor for the survival model eta_t <- as.vector(W %*% gammas) # to simulate event times we use inverse transform sampling # (https://en.wikipedia.org/wiki/Inverse_transform_sampling). Namely, we want  # to find t, such that S(t) = u, where S(.) is the survival function, and u a  # number from the Unif(0, 1) distribution. The function below calculates  # log(u) - log(S(t)), and for a given u, we want to find t for which it equals # zero. We do that below using the uniroot() function invS <- function (t, i) {   # i denotes the subject   sex_i <- W[i, 2L]   # h() is the hazard function and we assume a Weibull baseline hazard   h <- function (s) {     X_at_s <- cbind(1, sex_i, s, sex_i * s)     Z_at_s <- cbind(1, s)     # the linear predictor from the mixed model evaluated at time s     f <- as.vector(X_at_s %*% betas +                      rowSums(Z_at_s * b[rep(i, nrow(Z_at_s)), ]))     exp(log(shape_wb) + (shape_wb - 1) * log(s) + eta_t[i] + f * alpha)   }   # -log(S(t)) = H(t), where H(t) is the cumulative hazard function   integrate(h, lower = 0, upper = t)$value + log(u[i]) } # we simulate the event times u <- runif(n) trueTimes <- numeric(n) for (i in seq_len(n)) {     Up <- 100     Root <- try(uniroot(invS, interval = c(1e-05, Up), i = i)$root, TRUE)     trueTimes[i] <- if (!inherits(Root, \"try-error\")) Root else 150 }  # we use fixed Type I right censoring denoting the end of the trial. Ctimes <- upp_Cens Time <- pmin(trueTimes, Ctimes) event <- as.numeric(trueTimes <= Ctimes) # event indicator  # we keep the longitudinal measurements before the event times DF$Time <- Time[DF$id] DF$event <- event[DF$id] DF <- DF[DF$time <= DF$Time, ] DF_id <- DF[!duplicated(DF$id), ] Cox_fit <- coxph(Surv(Time, event) ~ sex, data = DF_id) CensNorm_MixMod <-     mixed_model(cbind(y, ind) ~ sex * time, random = ~ time | id, data = DF,                 family = censored.normal())  jointFit <- jm(Cox_fit, CensNorm_MixMod, time_var = \"time\") summary(jointFit) #>  #> Call: #> jm(Surv_object = Cox_fit, Mixed_objects = CensNorm_MixMod, time_var = \"time\") #>  #> Data Descriptives: #> Number of Groups: 200        Number of events: 165 (82.5%) #> Number of Observations: #>   cbind(y, ind): 1346 #>  #>                  DIC     WAIC      LPML #> marginal    3718.336 4647.791 -3267.595 #> conditional 3330.882 3218.840 -1744.693 #>  #> Random-effects covariance matrix: #>                      #>        StdDev   Corr #> (Intr) 0.9502 (Intr) #> time   0.6633 0.1447 #>  #> Survival Outcome: #>                        Mean  StDev   2.5%  97.5%      P   Rhat #> sexfemale            0.6065 0.2483 0.1192 1.0889 0.0107 1.0027 #> value(cbind(y, ind)) 0.8702 0.0641 0.7540 1.0005 0.0000 1.0477 #>  #> Longitudinal Outcome: cbind(y, ind) (family = censored normal, link = identity) #>                   Mean  StDev    2.5%   97.5%      P   Rhat #> (Intercept)    -2.2588 0.1023 -2.4597 -2.0543 0.0000 1.0019 #> sexfemale      -0.0300 0.1433 -0.3120  0.2483 0.8382 1.0011 #> time            0.3344 0.0698  0.1989  0.4710 0.0000 1.0001 #> sexfemale:time -0.1175 0.0983 -0.3082  0.0732 0.2260 1.0011 #> sigma           0.4947 0.0138  0.4690  0.5227 0.0000 1.0028 #>  #> MCMC summary: #> chains: 3  #> iterations per chain: 3500  #> burn-in per chain: 500  #> thinning: 1  #> time: 15 sec"},{"path":"https://drizopoulos.github.io/JMbayes2/articles/Non_Gaussian_Mixed_Models.html","id":"studentss-t-mixed-models","dir":"Articles","previous_headings":"Non-Gaussian Joint Models with JMbayes2","what":"Students’s-t mixed models","title":"Non-Gaussian Mixed Models","text":"Outlying observations common issue practice. Several methods proposed literature identifying observations context longitudinal data. However, removing values analysis generally recommended unless also external information values outlying. Hence, need fit mixed models accommodate observations settings. well-known approach achieve replacing normal distribution error terms linear mixed model Student’s-t distribution heavier tails. following syntax simulates data joint model Student’s-t mixed effects model: fit corresponding joint model use students.t() family object call mixed_model():","code":"set.seed(1234) n <- 200 # number of subjects K <- 12 # number of measurements per subject t_max <- 14 # maximum follow-up time  # we construct a data frame with the design: # everyone has a baseline measurement, and then measurements at random  # follow-up times up to t_max DF <- data.frame(id = rep(seq_len(n), each = K),                  time = c(replicate(n, c(0, sort(runif(K - 1, 0, t_max))))),                  sex = rep(gl(2, n/2, labels = c(\"male\", \"female\")), each = K))  # design matrices for the fixed and random effects X <- model.matrix(~ sex * time, data = DF) Z <- model.matrix(~ time, data = DF)  betas <- c(-2.2, -0.25, 0.24, -0.05) # fixed effects coefficients sigma <- 0.5 # error standard deviation D11 <- 1.0 # variance of random intercepts D22 <- 0.5 # variance of random slopes  # we simulate random effects b <- cbind(rnorm(n, sd = sqrt(D11)), rnorm(n, sd = sqrt(D22))) # linear predictor eta_y <- as.vector(X %*% betas + rowSums(Z * b[DF$id, ])) # we simulate Student's-t longitudinal data DF$y <- eta_y + sigma * rt(n * K, df = 4)  upp_Cens <- 15 # fixed Type I censoring time shape_wb <- 5 # shape Weibull alpha <- 0.8 # association coefficients gammas <- c(\"(Intercept)\" = -9, \"sex\" = 0.5) W <- model.matrix(~ sex, data = DF[!duplicated(DF$id), ]) # linear predictor for the survival model eta_t <- as.vector(W %*% gammas) # to simulate event times we use inverse transform sampling # (https://en.wikipedia.org/wiki/Inverse_transform_sampling). Namely, we want  # to find t, such that S(t) = u, where S(.) is the survival function, and u a  # number from the Unif(0, 1) distribution. The function below calculates  # log(u) - log(S(t)), and for a given u, we want to find t for which it equals # zero. We do that below using the uniroot() function invS <- function (t, i) {   # i denotes the subject   sex_i <- W[i, 2L]   # h() is the hazard function and we assume a Weibull baseline hazard   h <- function (s) {     X_at_s <- cbind(1, sex_i, s, sex_i * s)     Z_at_s <- cbind(1, s)     # the linear predictor from the mixed model evaluated at time s     f <- as.vector(X_at_s %*% betas +                      rowSums(Z_at_s * b[rep(i, nrow(Z_at_s)), ]))     exp(log(shape_wb) + (shape_wb - 1) * log(s) + eta_t[i] + f * alpha)   }   # -log(S(t)) = H(t), where H(t) is the cumulative hazard function   integrate(h, lower = 0, upper = t)$value + log(u[i]) } # we simulate the event times u <- runif(n) trueTimes <- numeric(n) for (i in seq_len(n)) {     Up <- 100     Root <- try(uniroot(invS, interval = c(1e-05, Up), i = i)$root, TRUE)     trueTimes[i] <- if (!inherits(Root, \"try-error\")) Root else 150 }  # we use fixed Type I right censoring denoting the end of the trial. Ctimes <- upp_Cens Time <- pmin(trueTimes, Ctimes) event <- as.numeric(trueTimes <= Ctimes) # event indicator  # we keep the longitudinal measurements before the event times DF$Time <- Time[DF$id] DF$event <- event[DF$id] DF <- DF[DF$time <= DF$Time, ] DF_id <- DF[!duplicated(DF$id), ] Cox_fit <- coxph(Surv(Time, event) ~ sex, data = DF_id) Stdt_MixMod <-     mixed_model(y ~ sex * time, random = ~ time | id, data = DF,                 family = students.t(df = 4))  jointFit <- jm(Cox_fit, Stdt_MixMod, time_var = \"time\") summary(jointFit) #>  #> Call: #> jm(Surv_object = Cox_fit, Mixed_objects = Stdt_MixMod, time_var = \"time\") #>  #> Data Descriptives: #> Number of Groups: 200        Number of events: 165 (82.5%) #> Number of Observations: #>   y: 1347 #>  #>                  DIC     WAIC      LPML #> marginal    5197.868 6842.793 -3988.557 #> conditional 4447.164 4349.718 -2333.522 #>  #> Random-effects covariance matrix: #>                      #>        StdDev   Corr #> (Intr) 0.9791 (Intr) #> time   0.6749 0.1175 #>  #> Survival Outcome: #>             Mean  StDev    2.5%  97.5%     P   Rhat #> sexfemale 0.0207 0.2538 -0.4730 0.5131 0.932 1.0012 #> value(y)  0.8350 0.0647  0.7152 0.9658 0.000 1.0569 #>  #> Longitudinal Outcome: y (family = Student's-t, link = identity) #>                   Mean  StDev    2.5%   97.5%      P   Rhat #> (Intercept)    -2.2485 0.1083 -2.4626 -2.0334 0.0000 1.0038 #> sexfemale      -0.1212 0.1513 -0.4205  0.1691 0.4267 1.0005 #> time            0.2828 0.0710  0.1455  0.4235 0.0000 1.0007 #> sexfemale:time -0.0335 0.0993 -0.2263  0.1598 0.7318 1.0007 #>  #> MCMC summary: #> chains: 3  #> iterations per chain: 3500  #> burn-in per chain: 500  #> thinning: 1  #> time: 15 sec"},{"path":"https://drizopoulos.github.io/JMbayes2/articles/Non_Gaussian_Mixed_Models.html","id":"negative-binomial-mixed-models","dir":"Articles","previous_headings":"Non-Gaussian Joint Models with JMbayes2","what":"Negative binomial mixed models","title":"Non-Gaussian Mixed Models","text":"Count longitudinal outcomes typically modeled Poisson distribution. However, outcomes often exhibit variance allowed Poisson distribution, leading well-known problem -dispersion. accommodate -dispersion, typically, negative binomial distribution used. following piece code simulates data joint model count longitudinal data follow negative binomial distribution: corresponding joint model fitted using following syntax:","code":"set.seed(1234) n <- 500 # number of subjects K <- 10 # number of measurements per subject t_max <- 5 # maximum follow-up time  # we construct a data frame with the design: # everyone has a baseline measurement, and then measurements at random  # follow-up times up to t_max DF <- data.frame(id = rep(seq_len(n), each = K),                  time = c(replicate(n, c(0, sort(runif(K - 1, 0, t_max))))),                  sex = rep(gl(2, n/2, labels = c(\"male\", \"female\")), each = K))  # design matrices for the fixed and random effects X <- model.matrix(~ sex * time, data = DF) Z <- model.matrix(~ time, data = DF)  betas <- c(0.8, -0.5, 0.8, -0.5) # fixed effects coefficients shape <- 2 # shape/size parameter of the negative binomial distribution D11 <- 1.0 # variance of random intercepts D22 <- 0.3 # variance of random slopes  # we simulate random effects b <- cbind(rnorm(n, sd = sqrt(D11)), rnorm(n, sd = sqrt(D22))) # linear predictor eta_y <- as.vector(X %*% betas + rowSums(Z * b[DF$id, ])) # mean of the Beta distribution mu_y <- plogis(eta_y) # plogis(eta_y) = exp(eta_y) / (1 + exp(eta_y)) # we simulate negative binomial longitudinal data DF$y <- rnbinom(n * K, size = shape, mu = exp(eta_y))  # simulate event times upp_Cens <- 5 # fixed Type I censoring time shape_wb <- 5 # shape Weibull alpha <- 0.8 # association coefficient gammas <- c(\"(Intercept)\" = -9, \"sex\" = 0.5) W <- model.matrix(~ sex, data = DF[!duplicated(DF$id), ]) # linear predictor for the survival model eta_t <- as.vector(W %*% gammas) # to simulate event times we use inverse transform sampling # (https://en.wikipedia.org/wiki/Inverse_transform_sampling). Namely, we want  # to find t, such that S(t) = u, where S(.) is the survival function, and u a  # number from the Unif(0, 1) distribution. The function below calculates  # log(u) - log(S(t)), and for a given u, we want to find t for which it equals # zero. We do that below using the uniroot() function invS <- function (t, i) {   # i denotes the subject   sex_i <- W[i, 2L]   # h() is the hazard function and we assume a Weibull baseline hazard   h <- function (s) {     X_at_s <- cbind(1, sex_i, s, sex_i * s)     Z_at_s <- cbind(1, s)     # the linear predictor from the mixed model evaluated at time s     f <- as.vector(X_at_s %*% betas +                      rowSums(Z_at_s * b[rep(i, nrow(Z_at_s)), ]))     exp(log(shape_wb) + (shape_wb - 1) * log(s) + eta_t[i] + f * alpha)   }   # -log(S(t)) = H(t), where H(t) is the cumulative hazard function   integrate(h, lower = 0, upper = t)$value + log(u[i]) } # we simulate the event times u <- runif(n) trueTimes <- numeric(n) for (i in seq_len(n)) {     Up <- 100     Root <- try(uniroot(invS, interval = c(1e-05, Up), i = i)$root, TRUE)     trueTimes[i] <- if (!inherits(Root, \"try-error\")) Root else 150 }  # we use fixed Type I right censoring denoting the end of the trial. Ctimes <- upp_Cens Time <- pmin(trueTimes, Ctimes) event <- as.numeric(trueTimes <= Ctimes) # event indicator  # we keep the longitudinal measurements before the event times DF$Time <- Time[DF$id] DF$event <- event[DF$id] DF <- DF[DF$time <= DF$Time, ] DF_id <- DF[!duplicated(DF$id), ] Cox_fit <- coxph(Surv(Time, event) ~ sex, data = DF_id) NB_MixMod <- mixed_model(y ~ sex * time, random = ~ time | id, data = DF,                          family = negative.binomial())  jointFit <- jm(Cox_fit, NB_MixMod, time_var = \"time\") summary(jointFit) #>  #> Call: #> jm(Surv_object = Cox_fit, Mixed_objects = NB_MixMod, time_var = \"time\") #>  #> Data Descriptives: #> Number of Groups: 500        Number of events: 409 (81.8%) #> Number of Observations: #>   y: 3842 #>  #>                  DIC     WAIC      LPML #> marginal    21347.40 21300.55 -10650.44 #> conditional 22639.19 22350.27 -11565.82 #>  #> Random-effects covariance matrix: #>                       #>        StdDev   Corr  #> (Intr) 1.0401 (Intr)  #> time   0.5382 -0.0551 #>  #> Survival Outcome: #>             Mean  StDev   2.5%  97.5% P   Rhat #> sexfemale 0.6141 0.1608 0.2967 0.9385 0 1.0126 #> value(y)  0.8114 0.0536 0.7136 0.9274 0 1.0458 #>  #> Longitudinal Outcome: y (family = negative binomial, link = log) #>                   Mean  StDev    2.5%   97.5% P   Rhat #> (Intercept)     0.8422 0.0791  0.6852  0.9952 0 1.0116 #> sexfemale      -0.5812 0.1143 -0.8014 -0.3573 0 1.0035 #> time            0.8617 0.0415  0.7813  0.9427 0 1.0053 #> sexfemale:time -0.5161 0.0591 -0.6298 -0.3989 0 1.0010 #> sigma           1.9921 0.0848  1.8281  2.1608 0 1.0027 #>  #> MCMC summary: #> chains: 3  #> iterations per chain: 3500  #> burn-in per chain: 500  #> thinning: 1  #> time: 26 sec"},{"path":"https://drizopoulos.github.io/JMbayes2/articles/Non_Gaussian_Mixed_Models.html","id":"beta-binomial-longitudinal-outcomes","dir":"Articles","previous_headings":"Non-Gaussian Joint Models with JMbayes2","what":"Beta-binomial longitudinal outcomes","title":"Non-Gaussian Mixed Models","text":"count data binomial data, may -dispersion problem. accommodate , can change standard binomial distribution beta-binomial one. following piece code simulates data joint model binomial longitudinal data follow beta-binomial distribution: corresponding joint model fitted syntax:","code":"set.seed(1234) n <- 500 # number of subjects K <- 8 # number of measurements per subject t_max <- 10 # maximum follow-up time  # we construct a data frame with the design: # everyone has a baseline measurement, and then measurements at random  # follow-up times up to t_max DF <- data.frame(id = rep(seq_len(n), each = K),                  time = c(replicate(n, c(0, sort(runif(K - 1, 0, t_max))))),                  sex = rep(gl(2, n/2, labels = c(\"male\", \"female\")), each = K))  # design matrices for the fixed and random effects X <- model.matrix(~ sex * time, data = DF) Z <- model.matrix(~ time, data = DF)  betas <- c(-2.2, -0.25, 0.24, -0.05) # fixed effects coefficients phi <- 5 # precision parameter of the Beta distribution D11 <- 1.0 # variance of random intercepts D22 <- 0.5 # variance of random slopes  # we simulate random effects b <- cbind(rnorm(n, sd = sqrt(D11)), rnorm(n, sd = sqrt(D22))) # linear predictor eta_y <- as.vector(X %*% betas + rowSums(Z * b[DF$id, ])) # mean of the Beta distribution mu_y <- plogis(eta_y) # plogis(eta_y) = exp(eta_y) / (1 + exp(eta_y)) # we simulate probabilities from the Beta distribution probs <- rbeta(n * K, shape1 = mu_y * phi, shape2 = phi * (1 - mu_y)) # we transform to (0, 1) probs <- (probs * (nrow(DF) - 1) + 0.5) / nrow(DF) # we simulate binomial data use the probs DF$y <- rbinom(n * K, size = 20, prob = probs)  upp_Cens <- 15 # fixed Type I censoring time shape_wb <- 5 # shape Weibull alpha <- 0.8 # association coefficients gammas <- c(\"(Intercept)\" = -9, \"sex\" = 0.5) W <- model.matrix(~ sex, data = DF[!duplicated(DF$id), ]) # linear predictor for the survival model eta_t <- as.vector(W %*% gammas) # to simulate event times we use inverse transform sampling # (https://en.wikipedia.org/wiki/Inverse_transform_sampling). Namely, we want  # to find t, such that S(t) = u, where S(.) is the survival function, and u a  # number from the Unif(0, 1) distribution. The function below calculates  # log(u) - log(S(t)), and for a given u, we want to find t for which it equals # zero. We do that below using the uniroot() function invS <- function (t, i) {   # i denotes the subject   sex_i <- W[i, 2L]   # h() is the hazard function and we assume a Weibull baseline hazard   h <- function (s) {     X_at_s <- cbind(1, sex_i, s, sex_i * s)     Z_at_s <- cbind(1, s)     # the linear predictor from the mixed model evaluated at time s     f <- as.vector(X_at_s %*% betas +                      rowSums(Z_at_s * b[rep(i, nrow(Z_at_s)), ]))     exp(log(shape_wb) + (shape_wb - 1) * log(s) + eta_t[i] + f * alpha)   }   # -log(S(t)) = H(t), where H(t) is the cumulative hazard function   integrate(h, lower = 0, upper = t)$value + log(u[i]) } # we simulate the event times u <- runif(n) trueTimes <- numeric(n) for (i in seq_len(n)) {     Up <- 100     Root <- try(uniroot(invS, interval = c(1e-05, Up), i = i)$root, TRUE)     trueTimes[i] <- if (!inherits(Root, \"try-error\")) Root else 150 }  # we use fixed Type I right censoring denoting the end of the trial. Ctimes <- upp_Cens Time <- pmin(trueTimes, Ctimes) event <- as.numeric(trueTimes <= Ctimes) # event indicator  # we keep the longitudinal measurements before the event times DF$Time <- Time[DF$id] DF$event <- event[DF$id] DF <- DF[DF$time <= DF$Time, ] DF_id <- DF[!duplicated(DF$id), ] Cox_fit <- coxph(Surv(Time, event) ~ sex, data = DF_id) BetaBinom_MixMod <-     mixed_model(cbind(y, 20 - y) ~ sex * time, random = ~ time | id, data = DF,                 family = beta.binomial())  jointFit <- jm(Cox_fit, BetaBinom_MixMod, time_var = \"time\") summary(jointFit) #>  #> Call: #> jm(Surv_object = Cox_fit, Mixed_objects = BetaBinom_MixMod, time_var = \"time\") #>  #> Data Descriptives: #> Number of Groups: 500        Number of events: 395 (79%) #> Number of Observations: #>   cbind(y, 20 - y): 2837 #>  #>                  DIC     WAIC      LPML #> marginal    11921.66 11871.70 -5942.471 #> conditional 13491.02 13297.62 -7547.969 #>  #> Random-effects covariance matrix: #>                       #>        StdDev   Corr  #> (Intr) 1.0077 (Intr)  #> time   0.7146 -0.0045 #>  #> Survival Outcome: #>                           Mean  StDev   2.5%  97.5%      P   Rhat #> sexfemale               0.5800 0.1952 0.2149 0.9642 0.0036 1.0050 #> value(cbind(y, 20 - y)) 0.9346 0.0598 0.8248 1.0519 0.0000 1.0299 #>  #> Longitudinal Outcome: cbind(y, 20 - y) (family = beta binomial, link = logit) #>                   Mean  StDev    2.5%   97.5%      P   Rhat #> (Intercept)    -2.1593 0.0940 -2.3486 -1.9754 0.0000 1.0194 #> sexfemale      -0.2722 0.1310 -0.5360 -0.0178 0.0336 1.0087 #> time            0.3316 0.0522  0.2299  0.4334 0.0000 1.0039 #> sexfemale:time -0.1798 0.0749 -0.3276 -0.0368 0.0142 1.0007 #> sigma           4.8145 0.2810  4.2778  5.3776 0.0000 1.0262 #>  #> MCMC summary: #> chains: 3  #> iterations per chain: 3500  #> burn-in per chain: 500  #> thinning: 1  #> time: 53 sec"},{"path":[]},{"path":"https://drizopoulos.github.io/JMbayes2/articles/Recurring_Events.html","id":"introduction","dir":"Articles","previous_headings":"Recurrent events","what":"Introduction","title":"Recurrent Events","text":"JMbayes2 also provides capability fit joint models recurrent event process, possibly combined terminating event. Recurrent events correlated events may occur follow-period given subject. current implementation allows multiple longitudinal markers different distributions various functional forms link markers risk recurrent terminal events. Furthermore, enables risk intervals defined terms gap calendar timescales. two timescales use different zero-time reference. calendar uses study entry, gap uses end previous event (Figure 1). Gap assumes renewal event resets time zero. Figure 1 Visual representation hazard function gap calendar timescale. follow-, subject experienced three events. model also accommodates discontinuous risk intervals, .e., periods subject risk experiencing recurring event (Figure 2). example, patient hospital, risk hospitalized . Figure 2 Visual representation hazard function gap calendar timescale, accounting non-risk periods (gray areas). follow-, subject experienced three events. joint model p normally distributed longitudinal markers, terminal event process, recurrent event process can described follows: \\small{ \\begin{cases} y_{1_i}(t)= x_{1_i}(t)^\\top \\beta_1 +  z_{1_i}(t)^\\top b_{1_i} + \\varepsilon_1(t) = \\eta_{1_i}(t) + \\varepsilon_1(t) & \\text{Longitudinal marker 1,}\\\\ \\vdots \\\\ y_{p_i}(t)= x_{p_i}(t)^\\top \\beta_p +  z_{p_i}(t)^\\top b_{p_i} + \\varepsilon_p(t) = \\eta_{p_i}(t) + \\varepsilon_p(t) & \\text{Longitudinal marker p,}\\\\ h_{T_i}(t)= h_{T_0}(t)\\exp \\left \\{  w_{T_i}(t)^\\top \\gamma_T + \\mathcal{f}_{T_1}\\left\\{\\eta_{1_i}(t)\\right\\} \\alpha_{T_1} + \\dots + \\mathcal{f}_{T_p}\\left\\{\\eta_{p_i}(t)\\right\\} \\alpha_{T_p} + b_{F_i} \\alpha_{F} \\right\\} & \\text{Terminal event,}\\\\ h_{R_i}(t)= h_{R_0}(t)\\exp\\left\\{  w_{R_i}(t)^\\top \\gamma_R + \\mathcal{f}_{R_1}\\left\\{\\eta_{2_i}(t)\\right\\} \\alpha_{R_1} + \\dots + \\mathcal{f}_{R_p}\\left\\{\\eta_{p_i}(t)\\right\\} \\alpha_{R_p} + b_{F_i} \\right\\} & \\text{Recurrent event,}\\\\ \\end{cases} }  \\begin{pmatrix} b_{1_i} \\\\ \\vdots \\\\ b_{p_i} \\\\ b_{F_i}\\end{pmatrix} \\sim \\mathcal{N} \\left(0, \\begin{pmatrix}D & 0 \\\\ & \\sigma^2_F\\end{pmatrix}\\right), \\qquad \\varepsilon(t) \\sim N \\left(0, \\sigma^2\\right),  = 1, \\ldots, n. specify linear mixed-effects models longitudinal outcomes, terminal recurrence processes, use proportional hazard models. longitudinal event time processes linked via latent structure random effects, highlighted color equations . terms \\mathcal{f}_{R_j}\\left\\{\\eta_{j_i}(t)\\right\\} \\mathcal{f}_{R_j}\\left\\{\\eta_{j_i}(t)\\right\\} describe functional forms link longitudinal marker j risk recurrent terminal events, respectively. frailty b_{F_i} random effect accounts correlations recurrent events. coefficient \\alpha_{F} quantifies strength association terminal recurrent event processes. notational simplicity, formulation presented , shown normally distributed longitudinal outcomes; however, JMbayes2 provides option consider longitudinal outcomes different distributions.","code":""},{"path":[]},{"path":"https://drizopoulos.github.io/JMbayes2/articles/Recurring_Events.html","id":"data","dir":"Articles","previous_headings":"Recurrent events > Example","what":"Data","title":"Recurrent Events","text":"simulate data joint model three outcomes: one longitudinal outcome, one terminal failure time, one recurrent failure time. assume underlying value longitudinal outcome associated risk models use gap timescale. reader can easily extend example accommodate multiple longitudinal markers forms association, including competing risks, considering recurrent events process, using different timescale. now three data frames, one corresponding different outcome. fit joint model, user must organize failure-time data counting process formulation combining data terminal recurrent events. , strata variable used distinguish two processes. facilitate , provide package rc_setup() function: subject many rows new data frame number recurrent risk periods plus one terminal event. data frame follows counting process formulation risk intervals delimited start stop variables. strata variable denotes type event, 1 recurrent, 2 terminal. status equals 1 subject event 0 otherwise. shown Figure 3, subject 1 experienced seven recurrent events follow-; terminal event censored eighth recurrent event. Figure 3 Visual representation failure-time data follow-subject 1. horizontal black line denotes risk periods, blue line denotes non-risk periods. ‘R’ ‘T’ represent recurrent terminal event, respectively.","code":"gen_data <- function(){   n <- 500 # desired number of subjects    n_i <- 15  # number of (planned) measurements per subject   tmax <- 7 # maximum follow-up time (type I censoring)   scale <- \"gap\" # hazard timescale   ##############################################################################   n_scl <- 1.5   n_target <- n   n <- n * n_scl   # longitudinal outcome 1/2   ## param true values   betas <- c(\"Intercept\" = 6.94, \"Time1\" = 1.30, \"Time2\" = 1.84, \"Time3\" = 1.82)   sigma_y <- 0.6 # measurement error sd   D <- matrix(0, 4, 4)   D[lower.tri(D, TRUE)] <- c(0.71, 0.33, 0.07, 1.26, 2.68, 3.81, 4.35, 7.62, 5.4, 8)   D <- D + t(D)   diag(D) <- diag(D) * 0.5   b <- MASS::mvrnorm(n, rep(0, nrow(D)), D)   Bkn <- c(0, 7)   kn <- c(1, 3)   remove(D)   ##############################################################################   # terminal outcome   ## param true values   gammas_t <- c(\"(Intercept)\" = -9, \"Group\" = 0.5, \"Age\" = 0.05) # phi = exp(Intercept)   sigma_t <- 2   alpha_t <- 0.5 # association biomarker   alphaF <- 0.25 # association frailty   sigmaF <- 0.25 # frailty SD   frailty <- rnorm(n, mean = 0, sd = sigmaF)   ## terminal data   group <- rep(0:1, each = n/2)   age <- runif(n, 30, 70)   W_t <- cbind(\"(Intercept)\" = 1, \"Group\" = group, \"Age\" = age)   eta_t <- as.vector(W_t %*% gammas_t + alphaF * frailty)    invS_t <- function(t, u, i) {     h <- function(s) {        NS <- splines::ns(s, knots = kn, Boundary.knots = Bkn)       X <- cbind(1, NS)       Z <- cbind(1, NS)       eta_y <- as.vector(X %*% betas + rowSums(Z * b[rep(i, nrow(Z)), ]))       exp(log(sigma_t) + (sigma_t - 1) * log(s) + eta_t[i] + eta_y * alpha_t)      }     integrate(h, lower = 0, upper = t)$value + log(u)   }   u_t <- runif(n)   ter_times <- numeric(n)   for(i in seq_len(n)) {     root <- try(uniroot(invS_t, interval = c(1e-05, 250), # arbitrary upper limit                         u = u_t[i], i = i)$root, TRUE)       ter_times[i] <- if (!inherits(root, \"try-error\")) root else NA   }   ter_na <- !is.na(ter_times)   if(sum(ter_na) < n_target) stop(\"Not enough patients. Increase 'n_scl'.\")   rmv_ids <- sample(which(ter_na), sum(ter_na) - n_target)   ter_na[rmv_ids] <- FALSE # remove the excess of subjects   ter <- data.frame(id    = seq_len(n)[ter_na],                     tstop = ter_times[ter_na],                     group = group[ter_na],                     age   = age[ter_na])   frailty <- frailty[ter_na]   b <- b[ter_na, , drop = FALSE]   cens_times <- tmax   ter$status <- as.numeric(ter$tstop <= cens_times) # event indicator   ter$tstop <- pmin(ter$tstop, cens_times) # add censoring time   remove(gammas_t, sigma_t, group, W_t, eta_t, alpha_t, invS_t, u_t, i, root,           n_target, rmv_ids, ter_times, cens_times, n, alphaF, age, ter_na,          sigmaF)   ##############################################################################   # recurring outcome   ## param true values   gammas_r <- c(\"(Intercept)\" = -9+3, \"Group\" = 0.5, \"Age\" = 0.05) # phi = exp(Intercept)   sigma_r <- 2   alpha_r <- 0.5 # association biomarker   ## recurring data   W_r <- cbind(\"(Intercept)\" = 1, \"Group\" = ter$group, \"Age\" = ter$age)   eta_r <- as.vector(W_r %*% gammas_r + frailty)   if(scale == \"gap\") {     invS_r <- function(t, u, i, tstart) {       h <- function(s) {          NS <- splines::ns(s + tstart, knots = kn, Boundary.knots = Bkn)         X <- cbind(1, NS)         Z <- cbind(1, NS)         eta_y <- as.vector(X %*% betas + rowSums(Z * b[rep(i, nrow(Z)), ]))         exp(log(sigma_r) + (sigma_r - 1) * log(s) + eta_r[i] + eta_y * alpha_r)        }       integrate(h, lower = 0, upper = t)$value + log(u)     }   } else if(scale == \"calendar\") {     invS_r <- function(t, u, i, tstart) {       h <- function(s) {          NS <- splines::ns(s + tstart, knots = kn, Boundary.knots = Bkn)         X <- cbind(1, NS)         Z <- cbind(1, NS)         eta_y <- as.vector(X %*% betas + rowSums(Z * b[rep(i, nrow(Z)), ]))         exp(log(sigma_r) + (sigma_r - 1) * log(s + tstart) + eta_r[i] + eta_y * alpha_r)        }       integrate(h, lower = 0, upper = t)$value + log(u)     }   }   stop_times <- start_times <- id_times <- list()   j <- 1   for(i in seq_along(ter$id)) {     tstart <- 0     while(!is.na(tstart) & tstart < ter$tstop[i]) {       u_r <- runif(1)       root <- try(uniroot(invS_r, interval = c(1e-05, 250), # arbitrary upper limit                           u = u_r, i = i, tstart = tstart)$root, TRUE)         tstop <- if(!inherits(root, \"try-error\")) root else NA       start_times[[j]] <- tstart       stop_times[[j]] <- tstart + tstop       dur <- runif(1, 0, 0.1) # recurrent event duration       tstart <- tstart + tstop + dur       id_times[[j]] <- ter$id[i]       j <- j + 1     }   }   rec <- data.frame(id     = unlist(id_times),                                            tstart = unlist(start_times),                     tstop  = unlist(stop_times))   rec$id  <- match(rec$id, unique(rec$id)) # rename IDs   rec$group <- ter$group[rec$id]   rec$age <- ter$age[rec$id]   rec$Stime <- ter$tstop[rec$id]   rec$status <- as.numeric(!is.na(rec$tstop) & rec$tstop < rec$Stime)  # event indicator   rec$tstop <- pmin(rec$tstop, rec$Stime, na.rm = TRUE) # add cens time   rec$Stime <- NULL   ter$id <- seq_along(ter$id)   remove(gammas_r, sigma_r, W_r, eta_r, alpha_r, invS_r, stop_times, start_times,           id_times, dur, j, i, tstart, u_r, root, tstop)   ##############################################################################   # longitudinal outcome 2/2   long <- data.frame(id   = rep(ter$id, each = n_i),                      time = c(replicate(length(ter$id), c(0, sort(runif(n_i - 1, 1, tmax))))))   X <- model.matrix(~ 1 + splines::ns(time, knots = kn, Boundary.knots = Bkn),                      data = long)   Z <- model.matrix(~ 1 + splines::ns(time, knots = kn, Boundary.knots = Bkn),                      data = long)   eta_y <- as.vector(X %*% betas + rowSums(Z * b[long$id, ]))   long$y <- rnorm(length(eta_y), eta_y, sigma_y)   long_cens <- long$time <= rep(ter$tstop, times = rle(long$id)$lengths)    long <- long[long_cens, , drop = FALSE] # drop censored encounters   remove(kn, Bkn, X, betas, Z, b, eta_y, sigma_y, n_i, tmax, long_cens, scale)   ##############################################################################   # return   list(long = long, ter = ter, rec = rec) } set.seed(2022); fake_data <- gen_data() term_data <- fake_data$ter # terminal event data recu_data <- fake_data$rec # recurrent events data lme_data <- fake_data$long # longitudial marker data cox_data <- rc_setup(rc_data = recu_data, trm_data = term_data,                      idVar = \"id\", statusVar = \"status\",                      startVar = \"tstart\", stopVar = \"tstop\",                      trm_censLevel = 0,                      nameStrata = \"strata\", nameStatus = \"status\") cox_data[cox_data$id == 1, c(\"id\", \"tstart\", \"tstop\", \"status\", \"strata\")] #>   id    tstart     tstop status strata #> 1  1 0.0000000 0.3756627      1      R #> 2  1 0.4275324 0.7832841      1      R #> 3  1 0.8724938 1.0863887      1      R #> 4  1 1.1212953 1.8741434      1      R #> 5  1 1.9372355 2.7843451      1      R #> 6  1 2.7906559 3.4618622      1      R #> 7  1 3.5166929 3.5830169      1      R #> 8  1 3.6251219 4.0375415      0      R #> 9  1 0.0000000 4.0375415      1     T1"},{"path":"https://drizopoulos.github.io/JMbayes2/articles/Recurring_Events.html","id":"fitting-the-model","dir":"Articles","previous_headings":"Recurrent events > Example","what":"Fitting the model","title":"Recurrent Events","text":"user needs use nlme::lme() function first fit linear mixed model describes longitudinal outcome, , use survival::coxph() function fit stratified Cox model using transformed data, models provided arguments jm() function. user specifies desired functional forms mixed model relative-risk model. recurrent argument specifying desired timescale, One can find association parameters underlying value longitudinal outcome recurrent terminating event processes summary output value(y):strataRec (\\alpha_{R_1}) value(y):strataTer (\\alpha_{T_1}), respectively. \\exp\\{\\alpha_{R_1}\\} denotes relative increase risk next recurrent event time t results one unit increase \\eta_{1_i}(t) since end previous event1. association parameter frailty term terminal risk model, \\alpha_{F}, identified output frailty. sigma_frailty refers frailty standard deviation, \\sigma_F.","code":"lme_fit <- lme(y ~ ns(time, k =  c(1, 3), B = c(0, 7)),                 random = list(id = pdDiag(form = ~ ns(time, k = c(1, 3),                                                         B = c(0, 7)))),                data = lme_data,                control = lmeControl(opt = \"optim\", niterEM = 45)) cox_fit <- coxph(Surv(tstart, tstop, status) ~ (group + age):strata(strata),                  data = cox_data) jm_fit <- jm(cox_fit, lme_fit, time_var = \"time\", recurrent = \"gap\",              functional_forms =  ~ value(y):strata)  summary(jm_fit) #>  #> Call: #> jm(Surv_object = cox_fit, Mixed_objects = lme_fit, time_var = \"time\",  #>     recurrent = \"gap\", functional_forms = ~value(y):strata) #>  #> Data Descriptives: #> Number of Groups: 500        Number of events: 2250 (81.6%) #> Number of Observations: #>   y: 3075 #>  #>                  DIC     WAIC       LPML #> marginal    13149.97 12983.05  -6736.434 #> conditional 19832.17 19095.66 -10201.566 #>  #> Random-effects covariance matrix: #>                                                             #>                        StdDev   Corr                        #> (Intr)                 0.7423 (Intr) n(,k=c(1,3),B=c(0,7))1 #> n(,k=c(1,3),B=c(0,7))1 2.0832                               #> n(,k=c(1,3),B=c(0,7))2 1.4450                               #> n(,k=c(1,3),B=c(0,7))3 1.7567                               #>                                               #>                                               #> (Intr)                 n(,k=c(1,3),B=c(0,7))2 #> n(,k=c(1,3),B=c(0,7))1                        #> n(,k=c(1,3),B=c(0,7))2                        #> n(,k=c(1,3),B=c(0,7))3                        #>  #> Frailty standard deviation: #>                 Mean   2.5%  97.5% #> sigma_frailty 0.1928 0.0212 0.3105 #>  #> Survival Outcome: #>                             Mean  StDev    2.5%  97.5%      P   Rhat #> group:strata(strata)R     0.4638 0.0826  0.3032 0.6233 0.0000 1.0022 #> group:strata(strata)T1    0.4348 0.1071  0.2215 0.6346 0.0000 1.0204 #> age:strata(strata)R       0.0497 0.0029  0.0442 0.0555 0.0000 1.0395 #> age:strata(strata)T1      0.0475 0.0048  0.0383 0.0570 0.0000 1.2322 #> value(y):strataR          0.5071 0.0275  0.4563 0.5605 0.0000 1.0678 #> value(y):strataT1         0.4983 0.0402  0.4222 0.5762 0.0000 1.5801 #> frailty:strata(strata)T1 -0.6146 1.1373 -3.0913 2.2689 0.3878 1.1494 #>  #> Longitudinal Outcome: y (family = gaussian, link = identity) #>                           Mean  StDev    2.5%  97.5%      P   Rhat #> (Intercept)             6.9873 0.0427  6.9034 7.0701 0.0000 1.0228 #> n(,k=c(1,3),B=c(0,7))1  1.3662 0.1472  1.0788 1.6537 0.0000 1.0120 #> n(,k=c(1,3),B=c(0,7))2  0.6188 0.1477  0.3321 0.9173 0.0000 1.3360 #> n(,k=c(1,3),B=c(0,7))3 -0.1523 0.2027 -0.5384 0.2605 0.4333 1.2847 #> sigma                   0.6159 0.0100  0.5960 0.6356 0.0000 1.0121 #>  #> MCMC summary: #> chains: 3  #> iterations per chain: 3500  #> burn-in per chain: 500  #> thinning: 1  #> time: 1.7 min"},{"path":[]},{"path":"https://drizopoulos.github.io/JMbayes2/articles/Super_Learning.html","id":"motivation-and-theory","dir":"Articles","previous_headings":"Super Learning","what":"Motivation and Theory","title":"Combined Dynamic Predictions via Super Learning","text":"Joint models longitudinal time--event data established versatile tool calculating dynamic predictions longitudinal survival outcomes. advantageous feature predictions updated time extra information becomes available. result, found numerous applications precision medicine, including cancer cardiovascular diseases. Previous applications joint models considered single model obtaining dynamic predictions. However, finding well-specified model can challenging, especially considering multiple longitudinal outcomes. Moreover, due dynamic nature predictions, different models may provide different levels accuracy different follow-times. , consider multiple joint models instead combine dynamic predictions models optimize predictive accuracy. use concept super learning (SL) achieve . SL ensemble method allows researchers combine several different prediction algorithms one. uses V-fold cross-validation build optimally weighted combination predictions library candidate algorithms. Optimality defined user-specified objective function, minimizing mean squared error maximizing area receiver operating characteristic curve. basic idea behind super learning derive model weights optimize cross-validated predictions. specifically, let \\mathcal{L} = \\{M_1, \\ldots, M_L\\} denote library L models. restrictions models included library, recommended consider wide range possible models. Among others, joint models differ specification time trend longitudinal submodels functions form event submodel. split original dataset \\mathcal{D}_n V folds. choice V depend size number events \\mathcal{D}_n. particular, fold, need sufficient number events quantify predictive performance robustly. Using cross-validation method, fit L models combined v-1 folds, calculate predictions v-th fold left outside. Due dynamic nature predictions, want derive optimal weights different follow-times. specifically, consider sequence time points t_1, \\ldots, t_Q. number placing time points consider available event information \\mathcal{D}_n. t_q \\\\{t_1, \\ldots, t_Q\\}, define \\mathcal{R}(t_q, v) denote subjects risk time t_q belong v-th fold. subjects \\mathcal{R}(t_q, v), calculate cross-validated predictions, \\hat{\\pi}_i^{(v)}(t_q + \\Delta t \\mid t_q, M_l) = \\Pr \\{T_i^* < t_q + \\Delta t \\mid T_i^* > t_q, \\mathcal H_i(t), M_l, \\mathcal{D}_n^{(-v)}\\}. predictions calculated based model M_l library \\mathcal{L} fitted dataset \\mathcal{D}_n^{(-v)} excludes patients v-th fold. calculation based Monte Carlo approach. define \\hat{\\tilde{\\pi}}_i^{v}(t_q + \\Delta t \\mid t_q) denote convex combination L predictions, .e., \\hat{\\tilde{\\pi}}_i^{v}(t_q + \\Delta t \\mid t_q) = \\sum\\limits_{l = 1}^L \\varpi_l(t_q) \\hat{\\pi}_i^{(v)}(t_q + \\Delta t \\mid t_q, M_l), \\quad \\mbox{} v \\{1, \\ldots, V}, \\varpi_l(t_q) > 0, l = 1, \\ldots, L, \\sum_l \\varpi_l(t_q) = 1. Note weights \\varpi_l(\\cdot) time-varying, .e., different follow-times, different combinations L models may yield accurate predictions. time t, select weights \\{\\varpi_l(t); l = 1, \\ldots, L\\} optimize predictive performance combined cross-validated predictions using proper scoring rules. scoring rule \\mathcal{S}\\{\\pi_i(u \\mid t), \\mathbb{}(t < T_i^* < u)\\} called proper true distribution achieves optimal expected score, .e., case E \\left [\\mathcal{S}\\{\\pi_i^{true}(u \\mid t), \\; \\mathbb{}(t < T_i^* < u) \\} \\right] \\leq E \\left [\\mathcal{S}\\{\\hat{\\pi}_i(u \\mid t), \\; \\mathbb{}(t < T_i^* < u) \\} \\right], \\quad u > t, \\pi_i^{true}(u \\mid t) denotes conditional risk probabilities true model, \\hat{\\pi}_i(u \\mid t) estimate \\pi_i^{true}(u \\mid t). expectation taken respect conditional density survival outcome true model \\{T_i^* \\mid T_i^* > t, \\mathcal Y_i(t)\\}, \\mathcal Y_i(t) = \\{ y_i(t_{il}); 0 \\leq t_{il} \\leq t, l = 1, \\ldots, n_i\\}, scoring rule \\mathcal S(\\cdot, \\cdot) defined lower score indicates better accuracy. Brier score proper scoring rule combines discrimination calibration measure overall predictive performance. particular, follow-time t medically-relevant time window \\Delta t, define Brier score \\mbox{BS}(t + \\Delta t, t) = E \\left [\\left \\{ \\mathbb{}(T_i^* \\leq t + \\Delta t) - \\tilde{\\pi}_i^{v}(t + \\Delta t \\mid t) \\right \\}^2 \\; \\Big | \\; T_i^* > t \\right]. alternative proper scoring rule interval (t, t + \\Delta t] consider adaptation expected predictive cross-entropy (EPCE): \\mbox{EPCE}(t + \\Delta t, t) = E \\left \\{-\\log \\left [ p \\bigl \\{ T_i^* \\mid t < T_i^* < t + \\Delta t, \\mathcal Y_i(t), \\mathcal D_{n} \\bigr \\} \\right ] \\right \\}, expectation taken respect \\{T_i^* \\mid T_i^* > t, \\mathcal Y_i(t)\\} true model. context, \\mbox{BS}(t + \\Delta t, t) \\mbox{EPCE}(t + \\Delta t, t) calculated using convex combination cross-validated predictions \\hat{\\tilde{\\pi}}_i^{v}(t + \\Delta t \\mid t). particular, using super-learning procedure, obtain weights \\widehat{\\varpi}_l(t) minimize proper scoring rule (case, either \\mbox{BS}(t + \\Delta t, t) \\mbox{EPCE}(t + \\Delta t, t)) cross-validated predictions, \\widehat{\\varpi}_l(t) = \\mbox{argmin}_{\\varpi} \\left [ \\mathcal{S} \\left \\{ \\sum_{l = 1}^L \\varpi_l \\hat{\\pi}_i^{(v)}(t + \\Delta t \\mid t, M_l), T_i, \\delta_i \\right \\} \\right], \\quad v = 1, \\ldots, V, constraints \\varpi_l(t) > 0, l = 1, \\ldots, L, \\sum_l \\varpi_l(t) = 1.","code":""},{"path":"https://drizopoulos.github.io/JMbayes2/articles/Super_Learning.html","id":"example","dir":"Articles","previous_headings":"Super Learning","what":"Example","title":"Combined Dynamic Predictions via Super Learning","text":"illustrate application super learning combining dynamic predictions joint models using PBC dataset. start splitting pbc2 database five folds using function create_folds(): first argument function data.frame wish split V folds. argument id_var specifies name subject’s id variable dataset. output create_folds() list two components named \"training\" \"testing\". component another list V data.frames. Next, define function fit joint models wish consider calculating predictions. function single argument data.frame used fit joint models. optimize computational performance use parallel computing fit models different training datasets. Hence, within function call library(\"JMbayes2\") load package JMbayes2 worker. output function list fitted joint models class \"jmList\". Assigning class resulting list facilitate combining predictions later. example, use following specifications: particular, consider library univariate joint models longitudinal outcome serBilir composite event transplantation death. first three models consider simple linear mixed effects model serum bilirubin random intercepts random slopes per subject covariates. Also, Cox model composite event, specify baseline covariates; hence, risk composite event depends serum bilirubin. three models differ corresponding functional forms, .e., current value log serum bilirubin, current slope/velocity log serum bilirubin, current value plus area log serum bilirubin trajectory. last models consider elaborate specification linear mixed model includes natural cubic splines fixed random effects allow non-linearities log serum bilirubin trajectories main effects sex age mixed Cox models. functional forms , , current value current slope. fit models training datasets using parallel computing facilitated using parallel package (note: subsequent computations require time perform depending machine; machine Intel(R) Core(TM) i9-10885H CPU @ 2.40GHz 32.0 GB RAM takes 20 min run whole vignette): calculate weights combine predictions five models optimize integrated Brier score expected predictive cross-entropy follow-time t = 6 years relevant window \\Delta t = 2 years. function tvBrier() automatically performs task providing list joint models fitted training datasets first argument. integrated Brier score calculated using testing datasets provided newdata argument: observe fourth model dominates weights. Hence, integrated Brier score based combined predictions essentially integrated Brier score model. calculate model weights using expected predictive cross-entropy, use function tvEPCE() almost identical call Brier score: EPCE results indicate models M2 M3 share weight. observe EPCE based combined cross-validated predictions smaller EPCE based cross-validated predictions individual model. use weights practice, must first refit five joint models considered original dataset. , construct dataset subjects risk year six consider longitudinal measurements collected follow-time. Also, set dataset observed event time six event variable zero, .e., indicating patients event-free time: illustration, combine cumulative risk predictions Patient 8 using EPCE weights. achieve using predict() method objects class \"jmList\"; also need provide weights argument. rest arguments predict() method \"jm\" objects (see also Dynamic Predictions vignette):","code":"CVdats <- create_folds(pbc2, V = 5, id_var = \"id\") fit_models <- function (data) {     library(\"JMbayes2\")     data$status2 <- as.numeric(data$status != \"alive\")     data_id <- data[!duplicated(data$id), ]     lmeFit <- lme(log(serBilir) ~ year, data = data,                   random = ~ year | id,                   control = lmeControl(opt = \"optim\"))     CoxFit <- coxph(Surv(years, status2) ~ 1, data = data_id)     jmFit1 <- jm(CoxFit, lmeFit, time_var = \"year\")     jmFit2 <- update(jmFit1,                       functional_forms = ~ slope(log(serBilir)))     jmFit3 <- update(jmFit1,                       functional_forms = ~ value(log(serBilir)) + area(log(serBilir)))     ###     lmeFit2 <- lme(log(serBilir) ~ ns(year, 2, B = c(0, 14.4)) + sex + age,                     data = data, random = ~ ns(year, 2, B = c(0, 14.4)) | id,                    control = lmeControl(opt = \"optim\"))     CoxFit2 <- coxph(Surv(years, status2) ~ sex + age, data = data_id)     jmFit4 <- jm(CoxFit2, lmeFit2, time_var = \"year\")     jmFit5 <- update(jmFit4,                       functional_forms = ~ slope(log(serBilir)))     out <- list(M1 = jmFit1, M2 = jmFit2, M3 = jmFit3, M4 = jmFit4, M5 = jmFit5)     class(out) <- \"jmList\"     out } cl <- parallel::makeCluster(5L) Models_folds <- parallel::parLapply(cl, CVdats$training, fit_models) parallel::stopCluster(cl) tstr <- 6 thor <- 8  Brier_weights <- tvBrier(Models_folds, newdata = CVdats$testing,                           integrated = TRUE, Tstart = tstr, Thoriz = thor) Brier_weights #>  #> Cross-Validated Prediction Error using the Library of Joint Models 'Models_folds' #>  #> Super Learning Estimated Integrated Brier score: 0.0548 #> In the time interval: [6, 8) #> For the 166 subjects at risk at time 6 #> Number of subjects with an event in [6, 8): 18 #> Number of subjects with a censored time in [6, 8): 44 #> Accounting for censoring using model-based weights #>  #> Integrated Brier score per model: 0.0596 0.0588 0.0613 0.0523 0.0611 #> Weights per model: 0.199 0.1976 0.1925 0.214 0.1969 #> Number of folds: 5 EPCE_weights <- tvEPCE(Models_folds, newdata = CVdats$testing,                         Tstart = tstr, Thoriz = thor) EPCE_weights #>  #> Cross-Validated Expected Predictive Cross-Entropy using the Library of Joint Models 'Models_folds' #>  #> Super Learning Estimated EPCE: 0.3109 #> In the time interval: [6, 8) #> For the 166 subjects at risk at time 6 #> Number of subjects with an event in [6, 8): 18 #> Number of subjects with a censored time in [6, 8): 44 #>  #> EPCE per model: 0.3568 0.3599 0.3639 0.3589 0.4157 #> Weights per model: 0.0013 0.5387 0.4599 0 1e-04 #> Number of folds: 5 Models <- fit_models(pbc2) ND <- pbc2[pbc2$years > tstr & pbc2$year <= tstr, ] ND$id <- ND$id[, drop = TRUE] ND$years <- tstr ND$status2 <- 0 model_weights <- EPCE_weights$weights  predsEvent <- predict(Models, weights = model_weights, newdata = ND[ND$id == 8, ],                       process = \"event\", return_newdata = TRUE) predsLong <- predict(Models, weights = model_weights, newdata = ND[ND$id == 8, ],                      return_newdata = TRUE) plot(predsLong, predsEvent)"},{"path":"https://drizopoulos.github.io/JMbayes2/articles/Time_Varying_Effects.html","id":"non-proportional-hazards","dir":"Articles","previous_headings":"","what":"Non Proportional Hazards","title":"Time Varying Effects","text":"basic definition joint model assumes coefficients quantify association versions longitudinal outcomes hazard event time-constant (.e., proportional hazards assumption). can relax assumption specifying time-varying coefficients via functional_forms argument function jm(). illustrate capability using PBC dataset. start fitting Cox model composite event transplantation death, including sex baseline covariate: aim assess strength association risk composite event serum bilirubin level. describe patient-specific profiles time biomarker using linear mixed-effects model, include intercept fixed random effects, well linear quadratic time effects. fixed effects, also include interaction time effect sex. syntax fit model lme() : default call jm() adds subject-specific linear predictor mixed model time-varying covariate survival relative risk model: specify association serum bilirubin may change time, include interaction time-varying covariate natural cubic spline time using function ns() splines package. Important Note: work correctly, need explicitly specify internal boundary knots B-splines basis, .e., following example, set internal knots 3, 6, 9 years, boundary knots 0 14.5 years: spline coefficients straightforward interpretation. , therefore, visualize time-varying association log serum bilirubin hazard composite event using following piece code:  observe 95% credible interval time-varying coefficient includes horizontal line corresponding proportional hazards. also confirmed comparing two models: WAIC LPML indicate jointFit1 better model jointFit2. DIC magnitude models.","code":"pbc2.id$status2 <- as.numeric(pbc2.id$status != 'alive') CoxFit <- coxph(Surv(years, status2) ~ sex, data = pbc2.id) fm <- lme(log(serBilir) ~ poly(year, 2) * sex, data = pbc2,            random = ~ poly(year, 2) | id, control = lmeControl(opt = 'optim')) jointFit1 <- jm(CoxFit, fm, time_var = \"year\") summary(jointFit1) #>  #> Call: #> jm(Surv_object = CoxFit, Mixed_objects = fm, time_var = \"year\") #>  #> Data Descriptives: #> Number of Groups: 312        Number of events: 169 (54.2%) #> Number of Observations: #>   log(serBilir): 1945 #>  #>                  DIC     WAIC      LPML #> marginal    4346.937 6096.897 -3271.149 #> conditional 8713.787 8448.451 -4517.738 #>  #> Random-effects covariance matrix: #>                                #>        StdDev    Corr          #> (Intr) 1.3091  (Intr)  p(,2)1  #> p(,2)1 21.6892 0.6786          #> p(,2)2 12.1450 -0.2361 -0.1267 #>  #> Survival Outcome: #>                         Mean  StDev    2.5%  97.5%      P   Rhat #> sexfemale            -0.1531 0.2625 -0.6448 0.3834 0.5444 1.0118 #> value(log(serBilir))  1.2974 0.0989  1.1169 1.5105 0.0000 1.0469 #>  #> Longitudinal Outcome: log(serBilir) (family = gaussian, link = identity) #>                   Mean  StDev     2.5%   97.5%      P   Rhat #> (Intercept)     1.4897 0.2236   1.0479  1.9216 0.0000 1.0008 #> poly(year, 2)1 29.5318 5.1216  19.7020 39.8127 0.0000 1.0106 #> poly(year, 2)2 -4.8101 3.1672 -11.1911  1.2785 0.1256 1.0055 #> sexfemale      -0.4703 0.2386  -0.9310  0.0002 0.0502 1.0001 #> p(,2)1         -5.0308 5.3098 -15.6799  5.3492 0.3393 1.0088 #> p(,2)2          6.3008 3.2751  -0.1080 12.8040 0.0540 1.0120 #> sigma           0.3028 0.0061   0.2909  0.3149 0.0000 1.0077 #>  #> MCMC summary: #> chains: 3  #> iterations per chain: 3500  #> burn-in per chain: 500  #> thinning: 1  #> time: 18 sec form_splines <- ~ value(log(serBilir)) * ns(year, k = c(3, 6, 9), B = c(0, 14.5)) jointFit2 <- update(jointFit1, functional_forms = form_splines,                      n_iter = 6500L, n_burnin = 2500L) summary(jointFit2) #>  #> Call: #> jm(Surv_object = CoxFit, Mixed_objects = fm, time_var = \"year\",  #>     functional_forms = form_splines, n_iter = 6500L, n_burnin = 2500L) #>  #> Data Descriptives: #> Number of Groups: 312        Number of events: 169 (54.2%) #> Number of Observations: #>   log(serBilir): 1945 #>  #>                  DIC     WAIC      LPML #> marginal    4341.405 6355.209 -3701.785 #> conditional 8721.121 8458.791 -4518.159 #>  #> Random-effects covariance matrix: #>                                #>        StdDev    Corr          #> (Intr) 1.3165  (Intr)  p(,2)1  #> p(,2)1 22.1410 0.6886          #> p(,2)2 12.1107 -0.2160 -0.1051 #>  #> Survival Outcome: #>                                                                   Mean  StDev #> sexfemale                                                      -0.1687 0.2778 #> value(log(serBilir))                                            1.3764 0.2307 #> value(log(serBilir)):ns(year, k = c(3, 6, 9), B = c(0, 14.5))1 -0.2749 0.2747 #> value(log(serBilir)):ns(year, k = c(3, 6, 9), B = c(0, 14.5))2 -0.0072 0.3547 #> value(log(serBilir)):ns(year, k = c(3, 6, 9), B = c(0, 14.5))3 -0.6068 0.7512 #> value(log(serBilir)):ns(year, k = c(3, 6, 9), B = c(0, 14.5))4 -1.1876 0.9046 #>                                                                   2.5%  97.5% #> sexfemale                                                      -0.7010 0.3837 #> value(log(serBilir))                                            0.9567 1.8273 #> value(log(serBilir)):ns(year, k = c(3, 6, 9), B = c(0, 14.5))1 -0.8186 0.2543 #> value(log(serBilir)):ns(year, k = c(3, 6, 9), B = c(0, 14.5))2 -0.7200 0.7006 #> value(log(serBilir)):ns(year, k = c(3, 6, 9), B = c(0, 14.5))3 -2.0471 0.9432 #> value(log(serBilir)):ns(year, k = c(3, 6, 9), B = c(0, 14.5))4 -2.7763 0.6365 #>                                                                     P   Rhat #> sexfemale                                                      0.5503 1.0000 #> value(log(serBilir))                                           0.0000 1.0511 #> value(log(serBilir)):ns(year, k = c(3, 6, 9), B = c(0, 14.5))1 0.3257 1.0029 #> value(log(serBilir)):ns(year, k = c(3, 6, 9), B = c(0, 14.5))2 0.9955 1.0172 #> value(log(serBilir)):ns(year, k = c(3, 6, 9), B = c(0, 14.5))3 0.4217 1.0656 #> value(log(serBilir)):ns(year, k = c(3, 6, 9), B = c(0, 14.5))4 0.2075 1.1052 #>  #> Longitudinal Outcome: log(serBilir) (family = gaussian, link = identity) #>                   Mean  StDev     2.5%   97.5%      P   Rhat #> (Intercept)     1.4928 0.2264   1.0449  1.9387 0.0000 1.0071 #> poly(year, 2)1 30.0902 5.3321  19.8109 40.8594 0.0000 1.0643 #> poly(year, 2)2 -4.4062 3.2052 -10.5846  1.9815 0.1732 1.0559 #> sexfemale      -0.4713 0.2410  -0.9480  0.0006 0.0505 1.0053 #> p(,2)1         -5.3315 5.6721 -16.7089  5.5721 0.3432 1.0534 #> p(,2)2          6.0298 3.3524  -0.5961 12.6127 0.0733 1.0530 #> sigma           0.3030 0.0062   0.2907  0.3151 0.0000 1.0019 #>  #> MCMC summary: #> chains: 3  #> iterations per chain: 6500  #> burn-in per chain: 2500  #> thinning: 1  #> time: 35 sec x_times <- seq(0.001, 12, length = 501) X <- cbind(1, ns(x_times, knots = c(3, 6, 9), B = c(0, 14.5))) mcmc_alphas <- do.call('rbind', jointFit2$mcmc$alphas) log_hr <- X %*% t(mcmc_alphas) log_hr_mean <- rowMeans(log_hr) log_hr_low <- apply(log_hr, 1, quantile, probs = 0.025) log_hr_upp <- apply(log_hr, 1, quantile, probs = 0.975)  matplot(x_times, cbind(exp(log_hr_mean), exp(log_hr_low), exp(log_hr_upp)),          type = \"l\", col = c(\"red\", \"black\", \"black\"), lty = c(1, 2, 2), lwd = 2,         xlab = \"Follow-up Time (years)\", ylab = \"Hazard Ratio log serum Bilirubin\",         ylim = c(0.5, 6.4)) abline(h = exp(coef(jointFit1)$association), lty = 2, col = \"red\") abline(h = 1, lty = 2) legend(\"topright\", c(\"time-varying coefficient\", \"proportional hazards\"),        lty = c(1, 2), lwd = c(2, 1), col = \"red\", bty = \"n\") compare_jm(jointFit1, jointFit2) #>  #>                 DIC     WAIC      LPML #>  jointFit1 4346.937 6096.897 -3271.149 #>  jointFit2 4341.405 6355.209 -3701.785 #>  #> The criteria are calculated based on the marginal log-likelihood."},{"path":[]},{"path":"https://drizopoulos.github.io/JMbayes2/articles/Transformation_Functions.html","id":"simplified-syntax","dir":"Articles","previous_headings":"Functional Forms","what":"Simplified syntax","title":"Transformation Functions for Functional Forms","text":"previously seen function jm() via functional_forms argument allows specification different functional forms link longitudinal event time outcomes. argument accepts either single formula list formulas per longitudinal outcome terms wish include. illustrate possibilities using PBC dataset. start fitting Cox model composite event transplantation death, including sex baseline covariate: aim assess strength association risk composite event whether patients experienced hepatomegaly follow-. describe patient-specific profiles time biomarker using mixed-effects logistic model, include intercept time effect fixed random effects. syntax fit model mixed_model() : default call jm() adds subject-specific linear predictor mixed-effects logistic regression time-varying covariate survival relative risk model: output, named value(hepatomegaly) denote current value functional form used. , assume risk specific time t associated value linear predictor longitudinal outcome time point t. case, subject-specific linear predictor denotes log odds experiencing hepatomegaly time t.","code":"pbc2.id$status2 <- as.numeric(pbc2.id$status != 'alive') CoxFit <- coxph(Surv(years, status2) ~ sex, data = pbc2.id) fm <- mixed_model(hepatomegaly ~ year, data = pbc2, random = ~ year | id,                    family = binomial()) jointFit1 <- jm(CoxFit, fm, time_var = \"year\") summary(jointFit1) #>  #> Call: #> jm(Surv_object = CoxFit, Mixed_objects = fm, time_var = \"year\") #>  #> Data Descriptives: #> Number of Groups: 312        Number of events: 169 (54.2%) #> Number of Observations: #>   hepatomegaly: 1884 #>  #>                  DIC     WAIC      LPML #> marginal    3077.880 3066.424 -1533.651 #> conditional 4988.864 4850.268 -2651.221 #>  #> Random-effects covariance matrix: #>                       #>        StdDev   Corr  #> (Intr) 3.2996 (Intr)  #> year   0.5368 -0.1730 #>  #> Survival Outcome: #>                        Mean  StDev    2.5%  97.5%      P   Rhat #> sexfemale           -0.4733 0.3019 -1.0613 0.1357 0.1191 1.0011 #> value(hepatomegaly)  0.3591 0.0531  0.2641 0.4690 0.0000 1.0712 #>  #> Longitudinal Outcome: hepatomegaly (family = binomial, link = logit) #>               Mean  StDev    2.5%  97.5%      P   Rhat #> (Intercept) 0.0527 0.2282 -0.3928 0.5037 0.8244 1.0037 #> year        0.2836 0.0646  0.1561 0.4083 0.0000 1.0248 #>  #> MCMC summary: #> chains: 3  #> iterations per chain: 3500  #> burn-in per chain: 500  #> thinning: 1  #> time: 15 sec"},{"path":"https://drizopoulos.github.io/JMbayes2/articles/Transformation_Functions.html","id":"transformation-functions","dir":"Articles","previous_headings":"Functional Forms","what":"Transformation functions","title":"Transformation Functions for Functional Forms","text":"fact default version current value functional form linear predictor scale mixed model may problematic interpret linear predictor connected nonlinear link function mean longitudinal outcome. situations, may want transform subject-specific linear predictor back scale outcome. achieve , can use transformation function. Continuing previous example, update jointFit1 now linking expit transformation linear predictor (.e., \\mbox{expit}(x) = \\exp(x) / \\{1 + \\exp(x)\\}) risk event. done using vexpit() function: available functions use definition functional_forms argument vexp() calculate exponent, vlog() calculate natural logarithm, vsqrt() calculate square root. want include time-varying slope transformed linear predictor, also Dexpit() Dexp() functions available. example, extend jointFit2 including derivative \\mbox{expit}() transformation: call Dexpit(slope(hepatomegaly)) internally transformed Dexpit(value(hepatomegaly)):slope(hepatomegaly), calculates derivative \\mbox{expit}() evaluated linear predictor times derivative linear predictor. \\frac{d}{dt} \\mbox{expit}\\{\\eta(t)\\} = \\mbox{expit}\\{\\eta(t)\\} \\, \\Bigl [ 1 - \\mbox{expit}\\{\\eta(t)\\} \\Bigr ] \\times \\frac{d}{dt}\\eta(t)","code":"jointFit2 <- update(jointFit1, functional_forms = ~ vexpit(value(hepatomegaly))) summary(jointFit2) #>  #> Call: #> jm(Surv_object = CoxFit, Mixed_objects = fm, time_var = \"year\",  #>     functional_forms = ~vexpit(value(hepatomegaly))) #>  #> Data Descriptives: #> Number of Groups: 312        Number of events: 169 (54.2%) #> Number of Observations: #>   hepatomegaly: 1884 #>  #>                  DIC     WAIC      LPML #> marginal    3068.775 3059.436 -1530.111 #> conditional 5005.254 4904.042 -2701.585 #>  #> Random-effects covariance matrix: #>                       #>        StdDev   Corr  #> (Intr) 3.3268 (Intr)  #> year   0.5302 -0.3244 #>  #> Survival Outcome: #>                                Mean  StDev    2.5%  97.5%      P   Rhat #> sexfemale                   -0.3479 0.2838 -0.8972 0.2201 0.2196 1.0019 #> vexpit(value(hepatomegaly))  3.2874 0.4691  2.3812 4.2400 0.0000 1.0166 #>  #> Longitudinal Outcome: hepatomegaly (family = binomial, link = logit) #>               Mean  StDev    2.5%  97.5%      P   Rhat #> (Intercept) 0.0657 0.2354 -0.3840 0.5423 0.7862 1.0015 #> year        0.2377 0.0619  0.1191 0.3605 0.0004 1.0017 #>  #> MCMC summary: #> chains: 3  #> iterations per chain: 3500  #> burn-in per chain: 500  #> thinning: 1  #> time: 17 sec forms <- ~ vexpit(value(hepatomegaly)) + Dexpit(slope(hepatomegaly)) jointFit3 <- update(jointFit1, functional_forms = forms) summary(jointFit3) #>  #> Call: #> jm(Surv_object = CoxFit, Mixed_objects = fm, time_var = \"year\",  #>     functional_forms = forms) #>  #> Data Descriptives: #> Number of Groups: 312        Number of events: 169 (54.2%) #> Number of Observations: #>   hepatomegaly: 1884 #>  #>                  DIC     WAIC      LPML #> marginal    3067.439 3058.267 -1529.488 #> conditional 4990.422 4886.822 -2701.964 #>  #> Random-effects covariance matrix: #>                       #>        StdDev   Corr  #> (Intr) 3.4301 (Intr)  #> year   0.5544 -0.4777 #>  #> Survival Outcome: #>                                                    Mean  StDev    2.5%   97.5% #> sexfemale                                       -0.3234 0.2953 -0.8756  0.2695 #> vexpit(value(hepatomegaly))                      3.2922 0.5259  2.3173  4.3695 #> Dexpit(value(hepatomegaly)):slope(hepatomegaly) -0.9686 0.4667 -2.0680 -0.2517 #>                                                      P   Rhat #> sexfemale                                       0.2764 1.0079 #> vexpit(value(hepatomegaly))                     0.0000 1.0142 #> Dexpit(value(hepatomegaly)):slope(hepatomegaly) 0.0071 1.3755 #>  #> Longitudinal Outcome: hepatomegaly (family = binomial, link = logit) #>               Mean  StDev    2.5%  97.5%      P   Rhat #> (Intercept) 0.1410 0.2439 -0.3245 0.6345 0.5656 1.0179 #> year        0.1603 0.0688  0.0262 0.2970 0.0156 1.1988 #>  #> MCMC summary: #> chains: 3  #> iterations per chain: 3500  #> burn-in per chain: 500  #> thinning: 1  #> time: 19 sec"},{"path":"https://drizopoulos.github.io/JMbayes2/articles/Transformation_Functions.html","id":"the-slope-functional-form","dir":"Articles","previous_headings":"Functional Forms","what":"The Slope functional form","title":"Transformation Functions for Functional Forms","text":"seen previous examples, slope() function used specify slope functional form d \\eta(t)/dt. According definition derivative, corresponds change longitudinal profile \\{\\eta(t + \\varepsilon) - \\eta(t)\\}/ \\varepsilon \\varepsilon approaches zero. However, interpretation term may challenging settings. possible alternative increase value \\varepsilon, e.g., \\varepsilon = 1. example, time scale years, quantify change longitudinal profile last year t. fit joint model term, can use eps direction arguments slope() function. illustrate following example, use serum bilirubin first fit joint model time-varying slope term: specify want include change log serum bilirubin levels last year t, specify eps = 1 direction = \"back\" call slope(). calculates term \\{\\eta(t) - \\eta(t - \\varepsilon)\\} / \\varepsilon \\varepsilon set equal eps = 1: compare two fits","code":"gm <- lme(log(serBilir) ~ ns(year, 2), data = pbc2, random = ~ ns(year, 2) | id,           control = lmeControl(opt = \"optim\")) jFit1 <- jm(CoxFit, gm, time_var = \"year\",             functional_forms = ~ value(log(serBilir)) + slope(log(serBilir))) jFit2 <- jm(CoxFit, gm, time_var = \"year\",             functional_forms = ~ value(log(serBilir)) +                slope(log(serBilir), eps = 1, direction = \"back\")) summary(jFit1)$Survival #>                            Mean     StDev       2.5%    97.5%         P #> sexfemale            -0.1683743 0.2795170 -0.6744899 0.405122 0.5535556 #> value(log(serBilir))  1.2223588 0.1054294  1.0243374 1.429878 0.0000000 #> slope(log(serBilir))  2.9624164 0.6749065  1.7579233 4.393638 0.0000000 #>                          Rhat #> sexfemale            1.008869 #> value(log(serBilir)) 1.010025 #> slope(log(serBilir)) 1.043587  summary(jFit2)$Survival #>                                                         Mean     StDev #> sexfemale                                         -0.1647358 0.2732504 #> value(log(serBilir))                               1.2098188 0.1075358 #> slope(log(serBilir), eps = 1, direction = \"back\")  2.8433863 0.6355504 #>                                                         2.5%     97.5% #> sexfemale                                         -0.6761072 0.3902834 #> value(log(serBilir))                               0.9971623 1.4245781 #> slope(log(serBilir), eps = 1, direction = \"back\")  1.7099160 4.1559186 #>                                                           P     Rhat #> sexfemale                                         0.5344444 1.007342 #> value(log(serBilir))                              0.0000000 1.013989 #> slope(log(serBilir), eps = 1, direction = \"back\") 0.0000000 1.044426"},{"path":"https://drizopoulos.github.io/JMbayes2/authors.html","id":null,"dir":"","previous_headings":"","what":"Authors","title":"Authors and Citation","text":"Dimitris Rizopoulos. Author, maintainer. Pedro Miranda Afonso. Author. Grigorios Papageorgiou. Author.","code":""},{"path":"https://drizopoulos.github.io/JMbayes2/authors.html","id":"citation","dir":"","previous_headings":"","what":"Citation","title":"Authors and Citation","text":"Rizopoulos D, Miranda Afonso P, Papageorgiou G (2025). JMbayes2: Extended Joint Models Longitudinal Time--Event Data. R package version 0.5-91, https://drizopoulos.github.io/JMbayes2/.","code":"@Manual{,   title = {JMbayes2: Extended Joint Models for Longitudinal and Time-to-Event Data},   author = {Dimitris Rizopoulos and Pedro {Miranda Afonso} and Grigorios Papageorgiou},   year = {2025},   note = {R package version 0.5-91},   url = {https://drizopoulos.github.io/JMbayes2/}, }"},{"path":"https://drizopoulos.github.io/JMbayes2/index.html","id":"jmbayes2-extended-joint-models-for-longitudinal-and-time-to-event-data-","dir":"","previous_headings":"","what":"JMbayes2","title":"JMbayes2","text":"package JMbayes2 fits joint models longitudinal time--event data. can accommodate multiple longitudinal outcomes different type (e.g., continuous, dichotomous, ordinal, counts), assuming different distributions, .e., Gaussian, Student’s-t, Gamma, Beta, unit Lindley, censored Normal, Binomial, Poisson, Negative Binomial, Beta-Binomial. event time process, right, left interval censored data can handled, competing risks, multi-sate recurrent-event processes also covered.. JMbayes2 fits joint models using Markov chain Monte Carlo algorithms implemented C++. Besides main modeling function, package also provides number functions summarize visualize results.","code":""},{"path":"https://drizopoulos.github.io/JMbayes2/index.html","id":"installation","dir":"","previous_headings":"","what":"Installation","title":"JMbayes2","text":"JMbayes2 can installed CRAN: development version can installed GitHub:","code":"install.packages(\"JMbayes2\") # install.packages(\"remotes\") remotes::install_github(\"drizopoulos/jmbayes2\")"},{"path":"https://drizopoulos.github.io/JMbayes2/index.html","id":"minimal-example","dir":"","previous_headings":"","what":"Minimal Example","title":"JMbayes2","text":"fit joint model JMbayes2 first need fit separately mixed-effects models longitudinal outcomes Cox accelerated failure time (AFT) model event process. mixed models need fitted function lme() nlme package function mixed_model() GLMMadaptive package. Cox AFT model need fitted function coxph() function survreg() survival package. resulting model objects passed arguments jm() function fits corresponding joint model. illustrate procedure joint model three longitudinal outcomes using PBC dataset:","code":"# Cox model for the composite event death or transplantation pbc2.id$status2 <- as.numeric(pbc2.id$status != 'alive') CoxFit <- coxph(Surv(years, status2) ~ sex, data = pbc2.id)  # a linear mixed model for log serum bilirubin fm1 <- lme(log(serBilir) ~ year * sex, data = pbc2, random = ~ year | id)  # a linear mixed model for the prothrombin time fm2 <- lme(prothrombin ~ year * sex, data = pbc2, random = ~ year | id)  # a mixed effects logistic regression for ascites fm3 <- mixed_model(ascites ~ year + sex, data = pbc2,                    random = ~ year | id, family = binomial())  # the joint model that links all sub-models jointFit <- jm(CoxFit, list(fm1, fm2, fm3), time_var = \"year\",                 n_iter = 12000L, n_burnin = 2000L, n_thin = 5L) summary(jointFit)"},{"path":"https://drizopoulos.github.io/JMbayes2/reference/accuracy.html","id":null,"dir":"Reference","previous_headings":"","what":"Time-Dependent Predictive Accuracy Measures for Joint Models — Accuracy Measures","title":"Time-Dependent Predictive Accuracy Measures for Joint Models — Accuracy Measures","text":"Using available longitudinal information starting time point, functions compute estimates ROC curve AUC, Brier score expected predictive cross-entropy horizon time point based joint models.","code":""},{"path":"https://drizopoulos.github.io/JMbayes2/reference/accuracy.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Time-Dependent Predictive Accuracy Measures for Joint Models — Accuracy Measures","text":"","code":"tvROC(object, newdata, Tstart, ...)  # S3 method for class 'jm' tvROC(object, newdata, Tstart, Thoriz = NULL,     Dt = NULL, type_weights = c(\"model-based\", \"IPCW\"), ...)  tvAUC(object, newdata, Tstart, ...)  # S3 method for class 'jm' tvAUC(object, newdata, Tstart, Thoriz = NULL,     Dt = NULL, type_weights = c(\"model-based\", \"IPCW\"), ...)  # S3 method for class 'tvROC' tvAUC(object, ...)  calibration_plot(object, newdata, Tstart, ...)  # S3 method for class 'jm' calibration_plot(object, newdata, Tstart, Thoriz = NULL,     Dt = NULL, df_ns = NULL, plot = TRUE,     col = \"red\", lty = 1, lwd = 1,     add_CI = TRUE, col_CI = \"lightgrey\",     add_density = TRUE, col_dens = \"grey\",     xlab = \"Predicted Probabilities\",     ylab = \"Observed Probabilities\", main = \"\", ...)  calibration_metrics(object, newdata, Tstart, Thoriz = NULL,     Dt = NULL, df_ns = NULL, ...)  tvBrier(object, newdata, Tstart, ...)  # S3 method for class 'jm' tvBrier(object, newdata, Tstart, Thoriz = NULL, Dt = NULL,     integrated = FALSE, type_weights = c(\"model-based\", \"IPCW\"),     model_weights = NULL, eventData_fun = NULL,     parallel = c(\"snow\", \"multicore\"),     cores = parallelly::availableCores(omit = 1L), ...)  tvEPCE(object, newdata, Tstart, Thoriz = NULL, Dt = NULL, eps = 0.001,     model_weights = NULL, eventData_fun = NULL,     parallel = c(\"snow\", \"multicore\"),     cores = parallelly::availableCores(omit = 1L), ...)  create_folds(data, V = 5, id_var = \"id\",     method = c(\"CV\", \"Bootstrap\"), strata = NULL, seed = 123L)"},{"path":"https://drizopoulos.github.io/JMbayes2/reference/accuracy.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Time-Dependent Predictive Accuracy Measures for Joint Models — Accuracy Measures","text":"object object inheriting class jm, except tvAUC.tvROC() object class tvROC. tvBrier() tvEPCE() can also library joint models. newdata data.frame contains longitudinal covariate information subjects prediction survival probabilities required. names variables data.frame must data.frames used fit linear mixed effects event process model supplied two first argument jm. Tstart numeric scalar denoting time point longitudinal information used derive predictions. Thoriz numeric scalar denoting time point prediction survival status interest; Thoriz must later Tstart either Dt Thoriz must specified. Thoriz NULL set equal Tstart + Dt. Dt numeric scalar denoting length time interval prediction; either Dt Thoriz must specified. integrated logical; TRUE integrated Brier score calculated. type_weights character string denoting type weights use account censorting. Options model-based (default) inverse probability censoring weighting (using Kaplan-Meier estimate censoring distribution). eps numeric scalar used approximation hazard function. model_weights numeric vector weights combine predictions object list joint models class \"jmList\". eventData_fun function takes input newdata produces dataset used event process model. useful , example, event process model contains time-varying covariates. important function alter ordering subjects newdata. parallel character string; type parallel computing use. cores integer denoting number cores used library joint models provided     object. cores = 1, parallel computing used. df_ns degrees freedom natural cubic spline cloglog transformation predicted     probabilities used Cox model assesses calibration. default 3 unless less 25 events     interval (Tstart, Thoriz] case 2. plot logical; plot produced. FALSE, list returned observed predicted probabilities. add_CI logical; 0.95 pointwise confidence intervals added around calibration line. col_CI character; color shaded area representing 0.95 pointwise confidence intervals around calibration line. add_density logical; kernal density estimation predicted probabilities superimposed calibration plot. col, lwd, lty, col_dens, xlab, ylab, main graphical parameters. data data.frame split folds. V numeric scalar denoting number folds cross-validation number sample Bootstrap methods. id_var character string denoting name subject id variable data. strata character vector names stratifying variables. method character string indicating method use create training testing datasets create_folds(). default V-fold cross-validation. Bootstrap option, V samples replacement original dataset proruced training data. testing data contains subjects selected respective Bootstrap sample. seed integer denoting seed. ... additional arguments passed predict.jm().","code":""},{"path":"https://drizopoulos.github.io/JMbayes2/reference/accuracy.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Time-Dependent Predictive Accuracy Measures for Joint Models — Accuracy Measures","text":"list class tvAUC components: auc numeric scalar denoting estimated prediction error. Tstart copy Tstart argument. Thoriz copy Thoriz argument. nr numeric scalar denoting number subjects risk time Tstart. classObject class object. nameObject name object. list class tvROC components: TP, FP, nTP, nFN, nTN, qSN, qSP, qOverall accuracy indexes. F1score, Youden numeric scalars optimal cut-point using F1 score Youden index. thr numeric vector thresholds. Tstart copy Tstart argument. Thoriz copy Thoriz argument. nr numeric scalar denoting number subjects risk time Tstart. classObject class object. nameObject name object.","code":""},{"path":"https://drizopoulos.github.io/JMbayes2/reference/accuracy.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Time-Dependent Predictive Accuracy Measures for Joint Models — Accuracy Measures","text":"Antolini, L., Boracchi, P., Biganzoli, E. (2005). time-dependent discrimination index survival data. Statistics Medicine 24, 3927–3944. Commenges, D., Liquet, B., Proust-Lima, C. (2012). Choice prognostic estimators joint models estimating differences expected conditional Kullback-Leibler risks. Biometrics 68, 380–387. Harrell, F., Kerry, L. Mark, D. (1996). Multivariable prognostic models: issues developing models, evaluating assumptions adequacy, measuring reducing errors. Statistics Medicine 15, 361–387. Heagerty, P. Zheng, Y. (2005). Survival model predictive accuracy ROC curves. Biometrics 61, 92–105. Rizopoulos, D. (2016). R package JMbayes fitting joint models longitudinal time--event data using MCMC. Journal Statistical Software 72(7), 1–45. doi:10.18637/jss.v072.i07. Rizopoulos, D. (2012) Joint Models Longitudinal Time--Event Data: Applications R. Boca Raton: Chapman Hall/CRC. Rizopoulos, D. (2011). Dynamic predictions prospective accuracy joint models longitudinal time--event data. Biometrics 67, 819–829. Rizopoulos, D., Molenberghs, G. Lesaffre, E.M.E.H. (2017). Dynamic predictions time-dependent covariates survival analysis using joint modeling landmarking. Biometrical Journal 59, 1261–1276.","code":""},{"path":"https://drizopoulos.github.io/JMbayes2/reference/accuracy.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"Time-Dependent Predictive Accuracy Measures for Joint Models — Accuracy Measures","text":"Dimitris Rizopoulos d.rizopoulos@erasmusmc.nl","code":""},{"path":[]},{"path":"https://drizopoulos.github.io/JMbayes2/reference/accuracy.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Time-Dependent Predictive Accuracy Measures for Joint Models — Accuracy Measures","text":"","code":"# \\donttest{ # We fit a multivariate joint model pbc2.id$status2 <- as.numeric(pbc2.id$status != 'alive') CoxFit <- coxph(Surv(years, status2) ~ sex, data = pbc2.id) fm1 <- lme(log(serBilir) ~ ns(year, 3) * sex, data = pbc2,            random = ~ ns(year, 3) | id, control = lmeControl(opt = 'optim')) fm2 <- lme(prothrombin ~ ns(year, 2) * sex, data = pbc2,            random = ~ ns(year, 2) | id, control = lmeControl(opt = 'optim')) fm3 <- mixed_model(ascites ~ year * sex, data = pbc2,                    random = ~ year | id, family = binomial())  jointFit <- jm(CoxFit, list(fm1, fm2, fm3), time_var = \"year\", n_chains = 1L)  roc <- tvROC(jointFit, newdata = pbc2, Tstart = 4, Dt = 3, cores = 1L) roc #>  #> \tTime-dependent Sensitivity and Specificity for the Joint Model jointFit #>  #> At time: 7 #> Using information up to time: 4 (225 subjects still at risk) #> Accounting for censoring using model-based weights #>  #>    cut-off      SN     SP   #> 1     0.00 0.00000 1.0000   #> 2     0.01 0.01306 0.9978   #> 3     0.03 0.02703 0.9958   #> 4     0.05 0.04880 0.9958   #> 5     0.06 0.06077 0.9933   #> 6     0.07 0.06077 0.9877   #> 7     0.08 0.08253 0.9877   #> 8     0.09 0.10430 0.9877   #> 9     0.10 0.12607 0.9877   #> 10    0.13 0.14478 0.9813   #> 11    0.17 0.15942 0.9795   #> 12    0.18 0.18119 0.9795   #> 13    0.19 0.18119 0.9739   #> 14    0.20 0.23145 0.9700   #> 15    0.21 0.28848 0.9679   #> 16    0.22 0.30214 0.9658   #> 17    0.23 0.32391 0.9602   #> 18    0.25 0.34567 0.9602   #> 19    0.26 0.36360 0.9481   #> 20    0.30 0.36360 0.9425   #> 21    0.32 0.38537 0.9425   #> 22    0.34 0.40714 0.9425   #> 23    0.36 0.42891 0.9369   #> 24    0.37 0.45067 0.9369   #> 25    0.41 0.49421 0.9369   #> 26    0.45 0.50564 0.9287   #> 27    0.46 0.50564 0.9231   #> 28    0.47 0.51426 0.9141   #> 29    0.51 0.52846 0.9066   #> 30    0.54 0.53187 0.8963   #> 31    0.55 0.55364 0.8851   #> 32    0.56 0.56056 0.8813   #> 33    0.57 0.60409 0.8758   #> 34    0.58 0.64763 0.8758   #> 35    0.60 0.66939 0.8758   #> 36    0.61 0.66939 0.8702   #> 37    0.62 0.66939 0.8590   #> 38    0.63 0.69619 0.8547   #> 39    0.65 0.71796 0.8547   #> 40    0.66 0.71796 0.8491   #> 41    0.68 0.71908 0.8382   #> 42    0.69 0.74085 0.8382 * #> 43    0.70 0.74085 0.8327   #> 44    0.71 0.74530 0.8282   #> 45    0.72 0.74530 0.8226   #> 46    0.73 0.74530 0.8059   #> 47    0.74 0.76707 0.8059   #> 48    0.75 0.77172 0.7791   #> 49    0.77 0.77398 0.7630   #> 50    0.78 0.77398 0.7574   #> 51    0.79 0.77398 0.7462   #> 52    0.80 0.79806 0.7412   #> 53    0.81 0.82369 0.7255   #> 54    0.82 0.83206 0.6997   #> 55    0.83 0.85792 0.6784   #> 56    0.84 0.85843 0.6618   #> 57    0.85 0.86268 0.6349   #> 58    0.86 0.86854 0.5918   #> 59    0.87 0.87327 0.5762   #> 60    0.88 0.87327 0.5483   #> 61    0.89 0.87385 0.5373   #> 62    0.90 0.88081 0.4609   #> 63    0.91 0.90438 0.4390   #> 64    0.92 0.92843 0.4228   #> 65    0.93 0.92945 0.3784   #> 66    0.94 0.93024 0.3339   #> 67    0.95 0.99618 0.2783   #> 68    0.96 0.99936 0.1897   #> 69    0.97 0.99963 0.1172   #> 70    0.98 0.99990 0.0279   #> 71    0.99 1.00000 0.0000   #>  tvAUC(roc) #>  #> \tTime-dependent AUC for the Joint Model jointFit #>  #> Estimated AUC:  0.8374 #> At time: 7 #> Using information up to time: 4 (225 subjects still at risk) #> Accounting for censoring using model-based weights #>  plot(roc, legend = TRUE, optimal_cutoff = \"Youden\")  # }"},{"path":"https://drizopoulos.github.io/JMbayes2/reference/aids.html","id":null,"dir":"Reference","previous_headings":"","what":"Didanosine versus Zalcitabine in HIV Patients — aids","title":"Didanosine versus Zalcitabine in HIV Patients — aids","text":"randomized clinical trial longitudinal survival data collected compare efficacy   safety two antiretroviral drugs treating patients failed intolerant zidovudine (AZT) therapy.","code":""},{"path":"https://drizopoulos.github.io/JMbayes2/reference/aids.html","id":"format","dir":"Reference","previous_headings":"","what":"Format","title":"Didanosine versus Zalcitabine in HIV Patients — aids","text":"data frame 1408 observations following 9 variables. patient patients identifier; total 467 patients. Time time death censoring. death numeric vector 0 denoting censoring 1 death. CD4 CD4 cells count. obstime time points CD4 cells count recorded. drug factor levels ddC denoting zalcitabine ddI denoting didanosine. gender factor levels female male. prevOI factor levels AIDS denoting previous opportunistic infection (AIDS         diagnosis) study entry, noAIDS denoting previous infection. AZT factor levels intolerance failure denoting AZT intolerance         AZT failure, respectively.","code":""},{"path":"https://drizopoulos.github.io/JMbayes2/reference/aids.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Didanosine versus Zalcitabine in HIV Patients — aids","text":"Goldman, ., Carlin, B., Crane, L., Launer, C., Korvick, J., Deyton, L. Abrams, D. (1996) Response CD4+ clinical consequences treatment using ddI ddC patients advanced HIV infection. Journal Acquired Immune Deficiency Syndromes Human Retrovirology 11, 161–169. Guo, X. Carlin, B. (2004) Separate joint modeling longitudinal event time data using standard computer packages. American Statistician 58, 16–24.","code":""},{"path":"https://drizopoulos.github.io/JMbayes2/reference/aids.html","id":"note","dir":"Reference","previous_headings":"","what":"Note","title":"Didanosine versus Zalcitabine in HIV Patients — aids","text":"data frame aids.id contains first CD4 cell count measurement patient. data frame used fit survival model.","code":""},{"path":"https://drizopoulos.github.io/JMbayes2/reference/coda_methods.html","id":null,"dir":"Reference","previous_headings":"","what":"Various Methods for Functions from the coda Package — jm coda Methods","title":"Various Methods for Functions from the coda Package — jm coda Methods","text":"Methods object class \"jm\" diagnostic functions.","code":""},{"path":"https://drizopoulos.github.io/JMbayes2/reference/coda_methods.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Various Methods for Functions from the coda Package — jm coda Methods","text":"","code":"traceplot(object, ...)  # S3 method for class 'jm' traceplot(object,   parm = c(\"all\", \"betas\", \"sigmas\", \"D\", \"bs_gammas\",            \"tau_bs_gammas\", \"gammas\", \"alphas\"), ...)  ggtraceplot(object, ...)  # S3 method for class 'jm' ggtraceplot(object,   parm = c(\"all\", \"betas\", \"sigmas\", \"D\", \"bs_gammas\",            \"tau_bs_gammas\", \"gammas\", \"alphas\"),   size = 1, alpha = 0.8,   theme = c('standard', 'catalog', 'metro',                 'pastel', 'beach', 'moonlight', 'goo', 'sunset', 'custom'),   grid = FALSE, gridrows = 3, gridcols = 1, custom_theme = NULL, ...)  gelman_diag(object, ...)  # S3 method for class 'jm' gelman_diag(object,   parm = c(\"all\", \"betas\", \"sigmas\", \"D\", \"bs_gammas\",            \"tau_bs_gammas\", \"gammas\", \"alphas\"), ...)  densplot(object, ...)  # S3 method for class 'jm' densplot(object,   parm = c(\"all\", \"betas\", \"sigmas\", \"D\", \"bs_gammas\",            \"tau_bs_gammas\", \"gammas\", \"alphas\"), ...)  ggdensityplot(object, ...)  # S3 method for class 'jm' ggdensityplot(object,   parm = c(\"all\", \"betas\", \"sigmas\", \"D\", \"bs_gammas\",            \"tau_bs_gammas\", \"gammas\", \"alphas\"),   size = 1, alpha = 0.6,   theme = c('standard', 'catalog', 'metro', 'pastel',                 'beach', 'moonlight', 'goo', 'sunset', 'custom'),   grid = FALSE, gridrows = 3, gridcols = 1, custom_theme = NULL, ...)  cumuplot(object, ...)  # S3 method for class 'jm' cumuplot(object,   parm = c(\"all\", \"betas\", \"sigmas\", \"D\", \"bs_gammas\",            \"tau_bs_gammas\", \"gammas\", \"alphas\"), ...)"},{"path":"https://drizopoulos.github.io/JMbayes2/reference/coda_methods.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Various Methods for Functions from the coda Package — jm coda Methods","text":"object object inheriting class \"jm\". parm character string specifying parameters joint model plot. Possible options '', 'betas', 'alphas', 'sigmas', 'D', 'bs_gammas', 'tau_bs_gammas', 'gammas'. size width traceplot line mm. Defaults 1. alpha opacity level traceplot line. Defaults 0.8. theme character string specifying color theme used. Possible options 'standard', 'catalog', 'metro', 'pastel', 'beach', 'moonlight', 'goo', 'sunset'. Note option supports fitted objects three chains. object fitted using different number chains colors either automatically chosen, can specified user via argument custom_theme. grid logical; defaults FALSE. TRUE, plots returned grids split multiple pages. details see documentation gridExtra::marrangeGrob(). gridrows number rows per page grid. relevant using grid = TRUE. Defaults 3. gridcols number columns per page grid. relevant using grid = TRUE. Defaults 1. custom_theme named character vector elements equal number chains (n_chains). name element number corresponding respective chain. Defaults NULL. ... arguments passed corresponding function coda package.","code":""},{"path":"https://drizopoulos.github.io/JMbayes2/reference/coda_methods.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Various Methods for Functions from the coda Package — jm coda Methods","text":"traceplot() Plots evolution estimated parameter vs. iterations fitted joint model. ggtraceplot() Plots evolution estimated parameter vs. iterations fitted joint model using ggplot2. gelman_diag() Calculates potential scale reduction factor estimated parameters fitted joint model, together upper confidence limits. densplot() Plots density estimate estimated parameters fitted joint model. ggdensityplot() Plots evolution estimated parameter vs. iterations fitted joint model using ggplot2. cumuplot() Plots evolution sample quantiles vs. iterations fitted joint model.","code":""},{"path":"https://drizopoulos.github.io/JMbayes2/reference/coda_methods.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"Various Methods for Functions from the coda Package — jm coda Methods","text":"Dimitris Rizopoulos d.rizopoulos@erasmusmc.nl","code":""},{"path":[]},{"path":"https://drizopoulos.github.io/JMbayes2/reference/coda_methods.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Various Methods for Functions from the coda Package — jm coda Methods","text":"","code":"# \\donttest{ # linear mixed model fits fit_lme1 <- lme(log(serBilir) ~ year:sex + age,                 random = ~ year | id, data = pbc2)  fit_lme2 <- lme(prothrombin ~ sex,                 random = ~ year | id, data = pbc2)  # cox model fit fit_cox <- coxph(Surv(years, status2) ~ age, data = pbc2.id)  # joint model fit fit_jm <- jm(fit_cox, list(fit_lme1, fit_lme2), time_var = \"year\", n_chains = 1L)  # trace plot for the fixed effects in the linear mixed submodels traceplot(fit_jm, parm = \"betas\")        # density plot for the fixed effects in the linear mixed submodels densplot(fit_jm, parm = \"betas\")        # cumulative quantile plot for the fixed effects in the linear mixed submodels cumuplot(fit_jm, parm = \"betas\")    # trace plot for the fixed effects in the linear mixed submodels ggtraceplot(fit_jm, parm = \"betas\")       ggtraceplot(fit_jm, parm = \"betas\", grid = TRUE)   ggtraceplot(fit_jm, parm = \"betas\", custom_theme = c('1' = 'black'))        # trace plot for the fixed effects in the linear mixed submodels ggdensityplot(fit_jm, parm = \"betas\")       ggdensityplot(fit_jm, parm = \"betas\", grid = TRUE)   ggdensityplot(fit_jm, parm = \"betas\", custom_theme = c('1' = 'black'))       # }"},{"path":"https://drizopoulos.github.io/JMbayes2/reference/cr_setup.html","id":null,"dir":"Reference","previous_headings":"","what":"Transform Competing Risks Data in Long Format — crisk_setup","title":"Transform Competing Risks Data in Long Format — crisk_setup","text":"competing risks setting function expands data frame   single row per subject data frame long format   subject many rows number competing events.","code":""},{"path":"https://drizopoulos.github.io/JMbayes2/reference/cr_setup.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Transform Competing Risks Data in Long Format — crisk_setup","text":"","code":"crisk_setup(data, statusVar, censLevel,     nameStrata = \"strata\", nameStatus = \"status2\")"},{"path":"https://drizopoulos.github.io/JMbayes2/reference/cr_setup.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Transform Competing Risks Data in Long Format — crisk_setup","text":"data data frame containing competing risk data single       row per subject. statusVar character string denoting name variable           data identifies status variable equals 1           subject competing events 0 otherwise. censLevel character string scalar denoting censoring level       statusVar variable data. nameStrata character string denoting variable added     long version data denoting various causes event. nameStatus character string denoting variable added     long version data denoting subject experience     competing events.","code":""},{"path":"https://drizopoulos.github.io/JMbayes2/reference/cr_setup.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Transform Competing Risks Data in Long Format — crisk_setup","text":"data frame long format multiple rows per subject.","code":""},{"path":"https://drizopoulos.github.io/JMbayes2/reference/cr_setup.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Transform Competing Risks Data in Long Format — crisk_setup","text":"Rizopoulos, D. (2012) Joint Models Longitudinal Time--Event Data: Applications R. Boca Raton: Chapman Hall/CRC. Putter, H., Fiocco, M., Geskus, R. (2007). Tutorial biostatistics: Competing risks multi-state models. Statistics Medicine 26, 2389–2430.","code":""},{"path":"https://drizopoulos.github.io/JMbayes2/reference/cr_setup.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"Transform Competing Risks Data in Long Format — crisk_setup","text":"Dimitris Rizopoulos d.rizopoulos@erasmusmc.nl","code":""},{"path":"https://drizopoulos.github.io/JMbayes2/reference/cr_setup.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Transform Competing Risks Data in Long Format — crisk_setup","text":"","code":"head(crisk_setup(pbc2.id, \"status\", \"alive\")) #>     id     years status      drug      age    sex year ascites hepatomegaly #> 1    1  1.095170   dead D-penicil 58.76684 female    0     Yes          Yes #> 1.1  1  1.095170   dead D-penicil 58.76684 female    0     Yes          Yes #> 2    2 14.152338  alive D-penicil 56.44782 female    0      No          Yes #> 2.1  2 14.152338  alive D-penicil 56.44782 female    0      No          Yes #> 3    3  2.770781   dead D-penicil 70.07447   male    0      No           No #> 3.1  3  2.770781   dead D-penicil 70.07447   male    0      No           No #>     spiders                   edema serBilir serChol albumin alkaline  SGOT #> 1       Yes edema despite diuretics     14.5     261    2.60     1718 138.0 #> 1.1     Yes edema despite diuretics     14.5     261    2.60     1718 138.0 #> 2       Yes                No edema      1.1     302    4.14     7395 113.5 #> 2.1     Yes                No edema      1.1     302    4.14     7395 113.5 #> 3        No      edema no diuretics      1.4     176    3.48      516  96.1 #> 3.1      No      edema no diuretics      1.4     176    3.48      516  96.1 #>     platelets prothrombin histologic status2       strata #> 1         190        12.2          4       1         dead #> 1.1       190        12.2          4       0 transplanted #> 2         221        10.6          3       0         dead #> 2.1       221        10.6          3       0 transplanted #> 3         151        12.0          4       1         dead #> 3.1       151        12.0          4       0 transplanted"},{"path":"https://drizopoulos.github.io/JMbayes2/reference/jm.html","id":null,"dir":"Reference","previous_headings":"","what":"Joint Models for Longitudinal and Time-to-Event Data — jm","title":"Joint Models for Longitudinal and Time-to-Event Data — jm","text":"Fits multivariate joint models longitudinal time--event data.","code":""},{"path":"https://drizopoulos.github.io/JMbayes2/reference/jm.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Joint Models for Longitudinal and Time-to-Event Data — jm","text":"","code":"jm(Surv_object, Mixed_objects, time_var, recurrent = FALSE,   functional_forms = NULL, which_independent = NULL,   base_hazard = NULL, data_Surv = NULL, id_var = NULL,   priors = NULL, control = NULL, ...)  value(x) coefs(x, zero_ind = NULL) slope(x, eps = 0.001, direction = \"both\") velocity(x, eps = 0.001, direction = \"both\") acceleration(x) area(x, time_window = NULL)  vexpit(x) Dexpit(x)  vexp(x) Dexp(x)  vabs(x)  vlog(x) vlog2(x) vlog10(x)  vsqrt(x) poly2(x) poly3(x) poly4(x)  tv(x, knots = NULL, ord = 2L)"},{"path":"https://drizopoulos.github.io/JMbayes2/reference/jm.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Joint Models for Longitudinal and Time-to-Event Data — jm","text":"Surv_object object: class 'coxph' fitted function coxph() package survival, class 'survreg' fitted function survreg() package survival. Mixed_objects list objects single object. Objects may : class 'lme' fitted function lme() package nlme, class 'MixMod' fitted function mixed_model() package GLMMadaptive. time_var character string indicating time variable mixed-effects model(s). recurrent character string indicating \"calendar\" \"gap\" timescale fit recurrent event model. functional_forms list formulas. formula corresponds one longitudinal outcome specifies association structure outcome survival submodel well interaction terms components longitudinal outcome survival submodel. See Examples. which_independent numeric indicator matrix denoting outcomes independent. can also character string \"\" case longitudinal outcomes assumed independent. relevant joint models multiple longitudinal outcomes. base_hazard character vector indicating type hazard function. data_Surv data.frame used fit Cox/AFT survival submodel. id_var character string indicating id variable survival submodel. priors named list user-specified prior parameters: mean_betas_HC prior mean vector normal prior regression coefficients covariates longitudinal model(s), hierarchically centered. Tau_betas_HC prior precision matrix normal prior regression coefficients longitudinal model(s), hierarchically centered. mean_betas_nHC list prior mean vector(s) normal prior(s) regression coefficients covariates longitudinal model(s), hierarchically centered. Tau_betas_nHC list prior precision matrix(ces) normal prior(s) regression coefficients longitudinal model(s), Hierarchically Centered. mean_bs_gammas prior mean vector normal prior B-splines             coefficients used approximate baseline hazard. Tau_bs_gammas prior precision matrix normal prior B-splines             coefficients used approximate baseline hazard. A_tau_bs_gammas prior shape parameter gamma prior             precision parameter penalty term B-splines coefficients             baseline hazard. B_tau_bs_gammas prior rate parameter gamma prior             precision parameter penalty term B-splines coefficients             baseline hazard. rank_Tau_bs_gammas prior rank parameter precision matrix normal prior B-splines coefficients used approximate baseline hazard. mean_gammas prior mean vector normal prior regression             coefficients baseline covariates. Tau_gammas prior precision matrix normal prior regression             coefficients baseline covariates. penalty_gammas character string value 'none', 'ridge', 'horseshoe' indicating whether coefficients baseline covariates included survival submodel shrunk, shrank using ridge prior, shrank using horseshoe prior, respectively. A_lambda_gammas prior shape parameter gamma prior             precision parameter local penalty term baseline regression coefficients. relevant penalty_gammas = 'ridge' penalty_gammas = 'horseshoe'. B_lambda_gammas prior rate parameter gamma prior             precision parameter local penalty term baseline regression coefficients. relevant penalty_gammas = 'ridge' penalty_gammas = 'horseshoe'. A_tau_gammas prior shape parameter gamma prior             precision parameter global penalty term baseline regression coefficients. relevant penalty_gammas = 'ridge' penalty_gammas = 'horseshoe'. B_tau_gammas prior rate parameter gamma prior             precision parameter global penalty term baseline regression coefficients. relevant penalty_gammas = 'ridge' penalty_gammas = 'horseshoe'. A_nu_gammas prior shape parameter gamma prior variance hyperparameter precision parameter local penalty term baseline regression coefficients. relevant penalty_gammas = 'ridge' penalty_gammas = 'horseshoe'. B_nu_gammas prior rate parameter gamma prior variance hyperparameter precision parameter local penalty term baseline regression coefficients. relevant penalty_gammas = 'ridge' penalty_gammas = 'horseshoe'. A_xi_gammas prior shape parameter gamma prior variance hyperparameter precision parameter global penalty term baseline regression coefficients. relevant penalty_gammas = 'ridge' penalty_gammas = 'horseshoe'. B_xi_gammas prior rate parameter gamma prior variance hyperparameter precision parameter global penalty term baseline regression coefficients. relevant penalty_gammas = 'ridge' penalty_gammas = 'horseshoe'. mean_alphas prior mean vector normal prior association             parameter(s). Tau_alphas prior mean vector normal prior association             parameter(s). penalty_alphas character string value 'none', 'ridge', 'horseshoe' indicating whether coefficients association parameters shrunk, shrank using ridge prior, shrank using horseshoe prior, respectively. A_lambda_alphas prior shape parameter gamma prior             precision parameter local penalty term association parameters. relevant penalty_gammas = 'ridge' penalty_gammas = 'horseshoe'. B_lambda_alphas prior rate parameter gamma prior             precision parameter local penalty term association parameters. relevant penalty_gammas = 'ridge' penalty_gammas = 'horseshoe'. A_tau_alphas prior shape parameter gamma prior             precision parameter global penalty term association parameters. relevant penalty_gammas = 'ridge' penalty_gammas = 'horseshoe'. B_tau_alphas prior rate parameter gamma prior             precision parameter global penalty term association parameters. relevant penalty_gammas = 'ridge' penalty_gammas = 'horseshoe'. A_nu_alphas prior shape parameter gamma prior variance hyperparameter precision parameter local penalty term association parameters. relevant penalty_gammas = 'ridge', penalty_gammas = 'horseshoe'. B_nu_alphas prior rate parameter gamma prior variance hyperparameter precision parameter local penalty term association parameters. relevant penalty_gammas = 'ridge' penalty_gammas = 'horseshoe'. A_xi_alphas prior shape parameter gamma prior variance hyperparameter precision parameter global penalty term association parameters. relevant penalty_gammas = 'ridge' penalty_gammas = 'horseshoe'. B_xi_alphas prior rate parameter gamma prior variance hyperparameter precision parameter global penalty term association parameters. relevant penalty_gammas = 'ridge' penalty_gammas = 'horseshoe'. gamma_prior_D_sds logical; TRUE, gamma prior used standard deviations D matrix (variance-covariance matrix random effects). Defaults TRUE D_sds_df prior degrees freedom parameter half-t prior standard deviations D matrix (variance-covariance matrix random effects). D_sds_sigma prior sigma parameter vector half-t prior standard deviations D matrix (variance-covariance matrix random effects). D_sds_shape prior shape parameter gamma prior standard deviations D matrix (variance-covariance matrix random effects). D_sds_mean prior mean parameter vector gamma prior standard deviations D matrix (variance-covariance matrix random effects). D_L_etaLKJ prior eta parameter LKJ prior correlation matrix random effects. sigmas_df prior degrees freedom parameter half-t prior error term(s). sigmas_sigma prior sigma parameter half-t prior error term(s). control list control values components: GK_k number quadrature points Gauss Kronrod rule; options 15 7. n_chains integer specifying number chains MCMC. Defaults 3. n_burnin integer specifying number burn-iterations. Defaults 500. n_iter integer specifying number total iterations per chain. Defaults 3500. n_thin integer specifying thinning chains. Defaults 1. seed seed used sampling procedures. Defaults 123. MALA logical; TRUE, MALA algorithm used updating elements         Cholesky factor D matrix. Defaults FALSE. save_random_effects logical; TRUE, full MCMC results random         effects saved returned jm object. Defaults FALSE. save_logLik_contributions logical; TRUE, log-likelihood contributions         saved mcmc component jm object. Defaults FALSE cores integer specifying number cores use running chains         parallel; point setting greater n_chains. parallel character string indicating parallel sampling chains         performed. Options \"snow\" (default) \"multicore\". basis character string possible values \"bs\" (default) \"ns\".             \"bs\" B-spline basis used approximate log baseline hazard function             degree spline specified Bsplines_degree. \"ns\" natrual cubic             spline basis used; case value Bsplines_degree control argument             ignored. Bsplines_degree degree splines basis; default quadratic splines. base_hazard_segments number segments split follow-period             spline approximation log baseline hazard function. Defaults 10. timescale_base_hazard character string possible values \"identity\" (default)             \"log\". \"identity\" spline basis specified time variable             orginal scale. \"log\" spline basis specified logarithm time variable. diff order difference used penalty matrix coefficients             splines used approximate log baseline hazard function. Defaults 2. knots numeric vector position knots spline approximation             log baseline hazard function. default equally-spaced knots starting             sqrt(.Machine$double.eps) maximum follow-time.  x numeric input variable. knots numeric vector knots. ord integer denoting order spline. zero_ind list integer vectors indicating coefficients set zero calculation value  term. can used include example random intercept; default NULL. eps numeric scalar denoting step-size finite difference approximation. direction character string direction numerical derivative, options \"\", \"backward\". time_window numeric scalar denoting lower limit calculating integral. ... arguments passed control.","code":""},{"path":"https://drizopoulos.github.io/JMbayes2/reference/jm.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Joint Models for Longitudinal and Time-to-Event Data — jm","text":"mathematical details regarding definition multivariate joint model, capabilities package can found vignette doc directory. Notes: ordering subjects datasets used fit mixed Cox regression models needs . units time variables mixed Cox models need .","code":""},{"path":"https://drizopoulos.github.io/JMbayes2/reference/jm.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Joint Models for Longitudinal and Time-to-Event Data — jm","text":"list class jm components: mcmc list MCMC samples parameter. acc_rates list acceptance rates parameter. logLik matrix dimensions [((n_iter - n_burnin)/n_thin)*n_thin, number individuals], element [, j] conditional log-Likelihood value \\(^{th}\\) iteration \\(j^{th}\\) individual. mlogLik matrix dimensions [((n_iter - n_burnin)/n_thin)*n_thin, number individuals], element [, j] marginal log-Likelihood value \\(^{th}\\) iteration \\(j^{th}\\) individual. running_time object class proc_time time used run jm. statistics list posterior estimates parameters (means, medians, standard deviations, standard errors, effective sample sizes, tail probabilities, upper lower bounds credible intervals, etc.). fit_stats list lists fit statistics (DIC, pD, LPML, CPO, WAIC) conditional marginal formulations. model_data list data used fit model. model_info list components fit useful functions. initial_values list initial values parameters. control copy control values used fit model. priors copy priors used fit model. call matched call.","code":""},{"path":"https://drizopoulos.github.io/JMbayes2/reference/jm.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"Joint Models for Longitudinal and Time-to-Event Data — jm","text":"Dimitris Rizopoulos d.rizopoulos@erasmusmc.nl","code":""},{"path":[]},{"path":"https://drizopoulos.github.io/JMbayes2/reference/jm.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Joint Models for Longitudinal and Time-to-Event Data — jm","text":"","code":"# \\donttest{ ################################################################################  ############################################## # Univariate joint model for serum bilirubin # # 1 continuous outcome                       # ##############################################  # [1] Fit the mixed model using lme(). fm1 <- lme(fixed = log(serBilir) ~ year * sex + I(year^2) +            age + prothrombin, random =  ~ year | id, data = pbc2)  # [2] Fit a Cox model, specifying the baseline covariates to be included in the # joint model. fCox1 <- coxph(Surv(years, status2) ~ drug + age, data = pbc2.id)  # [3] The basic joint model is fitted using a call to jm() i.e., joint_model_fit_1 <- jm(fCox1, fm1, time_var = \"year\",         n_chains = 1L, n_iter = 11000L, n_burnin = 1000L) summary(joint_model_fit_1) #>  #> Call: #> jm(Surv_object = fCox1, Mixed_objects = fm1, time_var = \"year\",  #>     n_chains = 1L, n_iter = 11000L, n_burnin = 1000L) #>  #> Data Descriptives: #> Number of Groups: 312\t\tNumber of events: 140 (44.9%) #> Number of Observations: #>   log(serBilir): 1945 #>  #>                  DIC     WAIC      LPML #> marginal    4204.643 5075.364 -2931.823 #> conditional 3334.409 3165.829 -1817.475 #>  #> Random-effects covariance matrix: #>                      #>        StdDev   Corr #> (Intr) 0.9752 (Intr) #> year   0.1772 0.3429 #>  #> Survival Outcome: #>                         Mean  StDev    2.5%  97.5%     P #> drugD-penicil        -0.0294 0.2359 -0.4760 0.4417 0.913 #> age                   0.0639 0.0092  0.0465 0.0824 0.000 #> value(log(serBilir))  1.4254 0.0976  1.2296 1.6264 0.000 #>  #> Longitudinal Outcome: log(serBilir) (family = gaussian, link = identity) #>                   Mean  StDev    2.5%   97.5%      P #> (Intercept)     0.2444 0.3605 -0.4688  0.9355 0.4880 #> year            0.2281 0.0370  0.1568  0.3005 0.0000 #> sexfemale      -0.2421 0.1816 -0.6013  0.1134 0.1850 #> I(year^2)       0.0026 0.0010  0.0007  0.0045 0.0066 #> age            -0.0017 0.0054 -0.0122  0.0092 0.7452 #> prothrombin     0.0529 0.0085  0.0364  0.0695 0.0000 #> year:sexfemale -0.0881 0.0385 -0.1644 -0.0137 0.0206 #> sigma           0.3452 0.0068  0.3322  0.3594 0.0000 #>  #> MCMC summary: #> chains: 1  #> iterations per chain: 11000  #> burn-in per chain: 1000  #> thinning: 1  #> time: 36 sec traceplot(joint_model_fit_1)                            ################################################################################  ########################################################################## # Multivariate joint model for serum bilirubin, hepatomegaly and ascites # # 1 continuous outcome, 2 categorical outcomes                           # ##########################################################################  # [1] Fit the mixed-effects models using lme() for continuous # outcomes and mixed_model() for categorical outcomes. fm1 <- lme(fixed = log(serBilir) ~ year * sex,            random = ~ year | id, data = pbc2)  fm2 <- mixed_model(hepatomegaly ~ sex + age + year, data = pbc2,                    random = ~ year | id, family = binomial())  fm3 <- mixed_model(ascites ~ year + age, data = pbc2,                    random = ~ year | id, family = binomial())  # [2] Save all the fitted mixed-effects models in a list. Mixed <- list(fm1, fm2, fm3)  # [3] Fit a Cox model, specifying the baseline covariates to be included in the # joint model. fCox1 <- coxph(Surv(years, status2) ~ drug + age, data = pbc2.id)  # [4] The joint model is fitted using a call to jm() i.e., joint_model_fit_2 <- jm(fCox1, Mixed, time_var = \"year\",       n_chains = 1L, n_iter = 11000L, n_burnin = 1000L) summary(joint_model_fit_2) #>  #> Call: #> jm(Surv_object = fCox1, Mixed_objects = Mixed, time_var = \"year\",  #>     n_chains = 1L, n_iter = 11000L, n_burnin = 1000L) #>  #> Data Descriptives: #> Number of Groups: 312\t\tNumber of events: 140 (44.9%) #> Number of Observations: #>   log(serBilir): 1945 #>   hepatomegaly: 1884 #>   ascites: 1885 #>  #>                  DIC     WAIC      LPML #> marginal    6642.124 6855.619 -3657.905 #> conditional 9083.033 8826.991 -4889.348 #>  #> Random-effects covariance matrix: #>                                                     #>        StdDev   Corr                                #> (Intr) 0.9912 (Intr)   year (Intr)    year  (Intr)  #> year   0.1757 0.3802                                #> (Intr) 3.2808 0.5267 0.3405                         #> year   0.5670 0.0444 0.3482 -0.3466                 #> (Intr) 2.8763 0.6201 0.4974 0.5264  -0.0074         #> year   0.4205 0.3543 0.6047 0.3516  0.2719  -0.0672 #>  #> Survival Outcome: #>                         Mean  StDev    2.5%  97.5%      P #> drugD-penicil        -0.1890 0.2679 -0.7106 0.3437 0.4658 #> age                   0.0330 0.0143  0.0032 0.0584 0.0316 #> value(log(serBilir))  0.7016 0.2205  0.2706 1.1292 0.0084 #> value(hepatomegaly)  -0.0515 0.0829 -0.2015 0.1152 0.5190 #> value(ascites)        0.5672 0.2027  0.2048 1.0108 0.0000 #>  #> Longitudinal Outcome: log(serBilir) (family = gaussian, link = identity) #>                   Mean  StDev    2.5%   97.5%      P #> (Intercept)     0.6726 0.1405  0.3984  0.9542 0.0000 #> year            0.2465 0.0276  0.1933  0.3007 0.0000 #> sexfemale      -0.2054 0.1446 -0.4946  0.0722 0.1492 #> year:sexfemale -0.0649 0.0283 -0.1209 -0.0106 0.0186 #> sigma           0.3479 0.0068  0.3351  0.3620 0.0000 #>  #> Longitudinal Outcome: hepatomegaly (family = binomial, link = logit) #>                Mean  StDev    2.5%  97.5%      P #> (Intercept)  0.0769 1.0083 -1.8713 2.0778 0.9420 #> sexfemale   -0.7586 0.5246 -1.8069 0.2517 0.1386 #> age          0.0146 0.0162 -0.0175 0.0466 0.3664 #> year         0.2461 0.0689  0.1083 0.3800 0.0000 #>  #> Longitudinal Outcome: ascites (family = binomial, link = logit) #>                Mean  StDev     2.5%   97.5% P #> (Intercept) -9.0119 1.0153 -11.1983 -7.1497 0 #> year         0.5763 0.0687   0.4611  0.7208 0 #> age          0.0811 0.0160   0.0507  0.1152 0 #>  #> MCMC summary: #> chains: 1  #> iterations per chain: 11000  #> burn-in per chain: 1000  #> thinning: 1  #> time: 1.5 min traceplot(joint_model_fit_2)                                                    ################################################################################  ###################### # Slope & Area Terms # ######################  # We extend model 'joint_model_fit_2' by including the value and slope term for # bilirubin, the area term for hepatomegaly (in the log-odds scale), and the # value and area term for spiders (in the log-odds scale). # To include these terms into the model, we specify the 'functional_forms' # argument. This should be a list of right side formulas. Each component of the # list should have as name the name of the corresponding outcome variable. In # the right side formula we specify the functional form of the association using # functions 'value()', 'slope()' and 'area()'. # Notes: (1) For terms not specified in the 'functional_forms' list, the default # value functional form is used.  # [1] Fit the mixed-effects models using lme() for continuous outcomes # and mixed_model() for categorical outcomes. fm1 <- lme(fixed = log(serBilir) ~ year * sex, random = ~ year | id, data = pbc2)  fm2 <- mixed_model(hepatomegaly ~ sex + age + year, data = pbc2,                    random = ~ year | id, family = binomial())  fm3 <- mixed_model(ascites ~ year + age, data = pbc2,                    random = ~ year | id, family = binomial())  # [2] Save all the fitted mixed-effects models in a list. Mixed <- list(fm1, fm2, fm3)  # [3] Fit a Cox model, specifying the baseline covariates to be included in the # joint model. fCox1 <- coxph(Surv(years, status2) ~ drug + age, data = pbc2.id)  # [4] Specify the list of formulas to be passed to the functional_forms argument # of jm(). fForms <- list(\"log(serBilir)\" = ~ value(log(serBilir)) + slope(log(serBilir)),                \"hepatomegaly\" = ~ area(hepatomegaly),                \"ascites\" = ~ value(ascites) + area(ascites))  # [5] The joint model is fitted using a call to jm() and passing the list # to the functional_forms argument. joint_model_fit_2 <- jm(fCox1, Mixed, time_var = \"year\",                         functional_forms = fForms, n_chains = 1L,                         n_iter = 11000L, n_burnin = 1000L) summary(joint_model_fit_2) #>  #> Call: #> jm(Surv_object = fCox1, Mixed_objects = Mixed, time_var = \"year\",  #>     functional_forms = fForms, n_chains = 1L, n_iter = 11000L,  #>     n_burnin = 1000L) #>  #> Data Descriptives: #> Number of Groups: 312\t\tNumber of events: 140 (44.9%) #> Number of Observations: #>   log(serBilir): 1945 #>   hepatomegaly: 1884 #>   ascites: 1885 #>  #>                  DIC     WAIC      LPML #> marginal    6643.644 6952.261 -4059.774 #> conditional 8992.791 8720.794 -4830.170 #>  #> Random-effects covariance matrix: #>                                                    #>        StdDev   Corr                               #> (Intr) 0.9883 (Intr)   year (Intr)    year  (Intr) #> year   0.1813 0.4185                               #> (Intr) 3.3719 0.5278 0.3471                        #> year   0.5866 0.0491 0.3639 -0.3638                #> (Intr) 2.2434 0.6558 0.5818 0.6176  -0.1046        #> year   0.3799 0.4802 0.6989 0.4232  0.3547  0.3394 #>  #> Survival Outcome: #>                         Mean  StDev    2.5%   97.5%      P #> drugD-penicil        -0.1146 0.2661 -0.6416  0.3927 0.6798 #> age                   0.0484 0.0137  0.0208  0.0754 0.0000 #> value(log(serBilir))  0.9236 0.2028  0.5630  1.3718 0.0000 #> slope(log(serBilir))  3.8810 1.3348  1.4004  6.6187 0.0026 #> area(hepatomegaly)    0.1137 0.0836 -0.0660  0.2775 0.1734 #> value(ascites)       -0.6728 0.2285 -1.0753 -0.1067 0.0034 #> area(ascites)         1.0142 0.2915  0.1782  1.4328 0.0028 #>  #> Longitudinal Outcome: log(serBilir) (family = gaussian, link = identity) #>                   Mean  StDev    2.5%   97.5%      P #> (Intercept)     0.7067 0.1429  0.4254  0.9870 0.0000 #> year            0.2605 0.0300  0.2020  0.3203 0.0000 #> sexfemale      -0.2451 0.1481 -0.5341  0.0420 0.0988 #> year:sexfemale -0.0716 0.0305 -0.1324 -0.0125 0.0180 #> sigma           0.3483 0.0066  0.3357  0.3618 0.0000 #>  #> Longitudinal Outcome: hepatomegaly (family = binomial, link = logit) #>                Mean  StDev    2.5%  97.5%      P #> (Intercept)  0.2790 1.0209 -1.7124 2.2872 0.7926 #> sexfemale   -0.9275 0.5312 -1.9833 0.0903 0.0756 #> age          0.0138 0.0165 -0.0190 0.0458 0.3974 #> year         0.2594 0.0730  0.1222 0.4067 0.0004 #>  #> Longitudinal Outcome: ascites (family = binomial, link = logit) #>                Mean  StDev    2.5%   97.5% P #> (Intercept) -8.0466 0.8839 -9.8390 -6.3740 0 #> year         0.4513 0.0598  0.3147  0.5598 0 #> age          0.0733 0.0153  0.0443  0.1052 0 #>  #> MCMC summary: #> chains: 1  #> iterations per chain: 11000  #> burn-in per chain: 1000  #> thinning: 1  #> time: 1.6 min  # }"},{"path":"https://drizopoulos.github.io/JMbayes2/reference/JMbayes2.html","id":null,"dir":"Reference","previous_headings":"","what":"Extended Joint Models for Longitudinal and Time-to-Event Data — JMbayes2","title":"Extended Joint Models for Longitudinal and Time-to-Event Data — JMbayes2","text":"Fit joint models longitudinal time--event data Bayesian approach. Multiple longitudinal outcomes mixed type (continuous/categorical) multiple event times (competing risks multi-state processes) accommodated.","code":""},{"path":"https://drizopoulos.github.io/JMbayes2/reference/JMbayes2.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Extended Joint Models for Longitudinal and Time-to-Event Data — JMbayes2","text":"package fits joint models longitudinal time--event data. can accommodate multiple longitudinal outcomes different type (e.g., continuous, dichotomous, ordinal, counts), assuming different distributions, .e., Gaussian, Student's-t, Gamma, Beta, unit Lindley, censored Normal, Binomial, Poisson, Negative Binomial, Beta-Binomial. event time process, right, left interval censored data can handled, competing risks multi-sate processes also covered. JMbayes2 fits joint models using Markov chain Monte Carlo algorithms implemented C++. package also offers several utility functions can extract useful information fitted joint models. important included See also Section .","code":""},{"path":"https://drizopoulos.github.io/JMbayes2/reference/JMbayes2.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"Extended Joint Models for Longitudinal and Time-to-Event Data — JMbayes2","text":"Dimitris Rizopoulos, Grigorios Papageorgiou, Pedro Miranda Afonso Maintainer: Dimitris Rizopoulos <d.rizopoulos@erasmusmc.nl>","code":""},{"path":"https://drizopoulos.github.io/JMbayes2/reference/JMbayes2.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Extended Joint Models for Longitudinal and Time-to-Event Data — JMbayes2","text":"Rizopoulos, D. (2012). Joint Models Longitudinal Time--Event Data Applications R. Boca Raton: Chapman & Hall/CRC.","code":""},{"path":[]},{"path":"https://drizopoulos.github.io/JMbayes2/reference/methods.html","id":null,"dir":"Reference","previous_headings":"","what":"Various Methods for Standard Generics — jm Methods","title":"Various Methods for Standard Generics — jm Methods","text":"Methods object class \"jm\" standard generic functions.","code":""},{"path":"https://drizopoulos.github.io/JMbayes2/reference/methods.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Various Methods for Standard Generics — jm Methods","text":"","code":"coef(object, ...)  # S3 method for class 'jm' coef(object, ...)  fixef(object, ...)  # S3 method for class 'jm' fixef(object, outcome = Inf, ...)  ranef(object, ...)  # S3 method for class 'jm' ranef(object, outcome = Inf, post_vars = FALSE, ...)  terms(x, ...)  # S3 method for class 'jm' terms(x, process = c(\"longitudinal\", \"event\"),                       type = c(\"fixed\", \"random\"), ...)  model.frame(formula, ...)  # S3 method for class 'jm' model.frame(formula, process = c(\"longitudinal\", \"event\"),                             type = c(\"fixed\", \"random\"), ...)  model.matrix(object, ...)  # S3 method for class 'jm' model.matrix(object, ...)  family(object, ...)  # S3 method for class 'jm' family(object, ...)  compare_jm(..., type = c(\"marginal\", \"conditional\"),   order = c(\"WAIC\", \"DIC\", \"LPML\", \"none\"))"},{"path":"https://drizopoulos.github.io/JMbayes2/reference/methods.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Various Methods for Standard Generics — jm Methods","text":"object, x, formula object inheriting class \"jm\". outcome index linear mixed submodel extract estimated fixed effects. greater total number submodels, extracts . post_vars logical; TRUE, returns variance posterior distribution. process submodel(s) extract terms: \"longitudinal\", linear mixed model(s), \"event\", survival model. type terms() model.frame(), effects select longitudinal process: \"fixed\", fixed-effects, \"random\", random-efects. compare_jm(), log-likelihood function use calculate criteria: \"marginal\", marginal log-likelihood, \"conditional\", conditional log-likelihood. ... arguments; currently, none used.  compare_jm(), series jm objects. order criteria use sort models output.","code":""},{"path":"https://drizopoulos.github.io/JMbayes2/reference/methods.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Various Methods for Standard Generics — jm Methods","text":"coef() Extracts estimated fixed effects event process fitted joint model. fixef() Extracts estimated fixed effects longitudinal processes fitted joint model. ranef() Extracts estimated random effects fitted joint model. terms() Extracts terms object(s) fitted joint model. model.frame() Creates model frame fitted joint model. model.matrix() Creates design matrices linear mixed submodels fitted joint model. family() Extracts error distribution link function used linear mixed submodel(s) fitted joint model. compare_jm() Compares two fitted joint models using criteria WAIC, DIC, LPML.","code":""},{"path":"https://drizopoulos.github.io/JMbayes2/reference/methods.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Various Methods for Standard Generics — jm Methods","text":"coef() list elements: gammas: estimated baseline fixed effects, association: estimated association parameters. fixef() numeric vector estimated fixed effects outcome selected. outcome greater number linear mixed submodels, returns list numeric vectors outcomes. ranef() numeric matrix rows denoting individuals columns random effects. postVar = TRUE, numeric matrix extra attribute \"postVar\". terms() process = \"longitudinal\", list terms object(s) linear mixed model(s).  process = \"event\", terms object survival model. model.frame() process = \"longitudinal\", list model frames used linear mixed model(s).  process = \"event\", model frame used survival model. model.matrix() list design matrix(ces) linear mixed submodel(s). family() list family objects. compare_jm() list elements: table: table criteria calculated joint model, type: log-likelihood function used calculate criteria.","code":""},{"path":"https://drizopoulos.github.io/JMbayes2/reference/methods.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"Various Methods for Standard Generics — jm Methods","text":"Dimitris Rizopoulos d.rizopoulos@erasmusmc.nl","code":""},{"path":[]},{"path":"https://drizopoulos.github.io/JMbayes2/reference/methods.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Various Methods for Standard Generics — jm Methods","text":"","code":"# \\donttest{ # linear mixed model fits fit_lme1 <- lme(log(serBilir) ~ year:sex + age,                 random = ~ year | id, data = pbc2)  fit_lme2 <- lme(prothrombin ~ sex,                 random = ~ year | id, data = pbc2)  # cox model fit fit_cox <- coxph(Surv(years, status2) ~ age, data = pbc2.id)  # joint model fit fit_jm <- jm(fit_cox, list(fit_lme1, fit_lme2), time_var = \"year\",     n_chains = 1L, n_iter = 11000L, n_burnin = 1000L)  # coef(): fixed effects for the event process coef(fit_jm) #> $gammas #>       Mean  #> 0.06070451  #>  #> $association #> value(log(serBilir))   value(prothrombin)  #>            1.3604613            0.1063424  #>   # fixef(): fixed effects for the first linear mixed submodel fixef(fit_jm, outcome = 1) #>    (Intercept)            age   year:sexmale year:sexfemale  #>     0.66594783    -0.00445036     0.23584373     0.16253524   # ranef(): random effects from all linear mixed submodels head(ranef(fit_jm)) #>             [,1]        [,2]        [,3]         [,4] #> [1,]  2.23319313  0.20276852  1.05194350  0.126098411 #> [2,] -0.36290322  0.00382308 -0.03130737  0.089480915 #> [3,] -0.19671871  0.06974686  0.51040201  0.210441867 #> [4,]  0.03344513  0.10239115  0.85942217  0.574548016 #> [5,]  0.32900876  0.22520488 -0.04018424  0.442201332 #> [6,] -0.62705384 -0.16161656 -0.11058573 -0.003544499  # terms(): random effects terms for the first linear mixed submodel terms(fit_jm, process = \"longitudinal\", type = \"random\")[[1]] #> ~year #> attr(,\"variables\") #> list(year) #> attr(,\"factors\") #>      year #> year    1 #> attr(,\"term.labels\") #> [1] \"year\" #> attr(,\"order\") #> [1] 1 #> attr(,\"intercept\") #> [1] 1 #> attr(,\"response\") #> [1] 0 #> attr(,\".Environment\") #> <environment: R_GlobalEnv> #> attr(,\"predvars\") #> list(year) #> attr(,\"dataClasses\") #>      year  #> \"numeric\"   # mode.frame(): model frame for the fixed effects in the second # linear mixed submodel head(model.frame(fit_jm, process = \"longitudinal\", type = \"fixed\")[[2]]) #>   prothrombin    sex #> 1        12.2 female #> 2        11.2 female #> 3        10.6 female #> 4        11.0 female #> 5        11.6 female #> 6        10.6 female  # model.matrix(): fixed effects design matrix for the first linear # mixed submodel head(model.matrix(fit_jm)[[1]]) #>   (Intercept)      age year:sexmale year:sexfemale #> 1           1 58.76684            0      0.0000000 #> 2           1 58.76684            0      0.5256817 #> 3           1 56.44782            0      0.0000000 #> 4           1 56.44782            0      0.4983025 #> 5           1 56.44782            0      0.9993429 #> 6           1 56.44782            0      2.1027270  # family(): family objects from both linear mixed submodels family(fit_jm) #> [[1]] #>  #> Family: gaussian  #> Link function: identity  #>  #>  #> [[2]] #>  #> Family: gaussian  #> Link function: identity  #>  #>   # compare_jm(): compare two fitted joint models fit_lme1b <- lme(log(serBilir) ~ 1,                   random = ~ year | id, data = pbc2)  fit_jm2 <- jm(fit_cox, list(fit_lme1b, fit_lme2), time_var = \"year\",     n_chains = 1L, n_iter = 11000L, n_burnin = 1000L)  compare_jm(fit_jm, fit_jm2) #>  #>               DIC     WAIC      LPML #>  fit_jm2 10512.30 10540.46 -5268.228 #>   fit_jm 10665.69 11146.24 -6097.345 #>  #> The criteria are calculated based on the marginal log-likelihood. # }"},{"path":"https://drizopoulos.github.io/JMbayes2/reference/pbc.html","id":null,"dir":"Reference","previous_headings":"","what":"Mayo Clinic Primary Biliary Cirrhosis Data — pbc2","title":"Mayo Clinic Primary Biliary Cirrhosis Data — pbc2","text":"Follow 312 randomised patients primary biliary cirrhosis, rare autoimmune liver disease, Mayo Clinic.","code":""},{"path":"https://drizopoulos.github.io/JMbayes2/reference/pbc.html","id":"format","dir":"Reference","previous_headings":"","what":"Format","title":"Mayo Clinic Primary Biliary Cirrhosis Data — pbc2","text":"data frame 1945 observations following 20 variables. id patients identifier; total 312 patients. years number years registration earlier death, transplantion, study         analysis time. status factor levels alive, transplanted dead. drug factor levels placebo D-penicil. age registration years. sex factor levels male female. year number years enrollment visit date, remaining values line         data refer visit. ascites factor levels Yes. hepatomegaly factor levels Yes. spiders factor levels Yes. edema factor levels edema (.e., edema diuretic therapy edema),         edema diuretics (.e., edema present without diuretics, edema resolved diuretics),         edema despite diuretics (.e., edema despite diuretic therapy). serBilir serum bilirubin mg/dl. serChol serum cholesterol mg/dl. albumin albumin g/dl. alkaline alkaline phosphatase U/liter. SGOT SGOT U/ml. platelets platelets per cubic ml / 1000. prothrombin prothrombin time seconds. histologic histologic stage disease. status2 numeric vector value 1 denoting patient dead,         0 patient alive transplanted.","code":""},{"path":"https://drizopoulos.github.io/JMbayes2/reference/pbc.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Mayo Clinic Primary Biliary Cirrhosis Data — pbc2","text":"Fleming, T. Harrington, D. (1991) Counting Processes Survival Analysis. Wiley, New York. Therneau, T. Grambsch, P. (2000) Modeling Survival Data: Extending Cox Model. Springer-Verlag, New York.","code":""},{"path":"https://drizopoulos.github.io/JMbayes2/reference/pbc.html","id":"note","dir":"Reference","previous_headings":"","what":"Note","title":"Mayo Clinic Primary Biliary Cirrhosis Data — pbc2","text":"data frame pbc2.id contains first measurement patient. data frame used fit survival model.","code":""},{"path":"https://drizopoulos.github.io/JMbayes2/reference/predict.html","id":null,"dir":"Reference","previous_headings":"","what":"Predictions from Joint Models — Predictions","title":"Predictions from Joint Models — Predictions","text":"Predict method object class \"jm\".","code":""},{"path":"https://drizopoulos.github.io/JMbayes2/reference/predict.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Predictions from Joint Models — Predictions","text":"","code":"# S3 method for class 'jm' predict(object,     newdata = NULL, newdata2 = NULL, times = NULL,     process = c(\"longitudinal\", \"event\"),     type_pred = c(\"response\", \"link\"),     type = c(\"subject_specific\", \"mean_subject\"),     control = NULL, ...)  # S3 method for class 'predict_jm' plot(x, x2 = NULL, subject = 1, outcomes = 1,   fun_long = NULL, fun_event = NULL, CI_long = TRUE, CI_event = TRUE,   xlab = \"Follow-up Time\", ylab_long = NULL, ylab_event = \"Cumulative Risk\",   main = \"\", lwd_long = 2, lwd_event = 2, ylim_event = c(0, 1),   ylim_long_outcome_range = TRUE,   col_line_long = \"#0000FF\",   col_line_event = c(\"#FF0000\", \"#03BF3D\", \"#8000FF\"), pch_points = 16,   col_points = \"blue\", cex_points = 1, fill_CI_long = \"#0000FF4D\",   fill_CI_event = c(\"#FF00004D\", \"#03BF3D4D\", \"#8000FF4D\"), cex_xlab = 1,   cex_ylab_long = 1, cex_ylab_event = 1, cex_main = 1, cex_axis = 1,   col_axis = \"black\", pos_ylab_long = c(0.1, 2, 0.08), bg = \"white\",   ...)  # S3 method for class 'jmList' predict(object,   weights, newdata = NULL, newdata2 = NULL,   times = NULL, process = c(\"longitudinal\", \"event\"),   type_pred = c(\"response\", \"link\"),   type = c(\"subject_specific\", \"mean_subject\"),   control = NULL, ...)"},{"path":"https://drizopoulos.github.io/JMbayes2/reference/predict.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Predictions from Joint Models — Predictions","text":"object object inheriting class \"jm\" list \"jm\" objects. weights numeric vector model weights. newdata, newdata2 data.frames. times numeric vector future times calculate predictions. process process calculation predictions, longitudinal outcomes event times. type level predictions; relevant type_pred = \"longitudinal\". Option type = \"subject_specific\" combines fixed- random-effects parts, whereas type = \"mean_subject\" uses fixed effects. type_pred type predictions; options \"response\" using inverse link function GLMMs, \"link\" correspond linear predictor. control named list control parameters: all_times logical; TRUE predictions longitudinal outcomes calculated times given times argumet, ones last longitudinal measurement. times_per_id logical; TRUE times argument vector times equal number subjects newdata. level level credible interval. return_newdata logical; predict() return predictions extra columns newdata newdata2. use_Y logical; longitudinal measurements used posterior random effects. return_mcmc logical; TRUE mcmc sample predictions returned. can TRUE conjuction return_newdata FALSE. n_samples number samples use original MCMC sample object. n_mcmc number Metropolis-Hastings iterations sampling random effects per iteration n_samples; last iteration retained. parallel character string; type parallel computing use. Options \"snow\" (default) \"multicore\". cores many number cores use. 20 subjects newdata, parallel computing invoked four cores default. cores = 1, parallel computing used. seed integer denoting seed. x, x2 objects returned predict.jm() argument return_data set TRUE. subject multiple subjects included data.frames x x2, selects one plot. single subject can plotted time. outcomes multiple longitudinal outcomes included data.frames x x2, selects ones plot. maximum three outcomes can plotted time. fun_long, fun_event function apply predictions longitudinal event outcomes, respectively. multiple longitudinal outcomes plotted, fun_long can list functions; see examples . CI_long, CI_event logical; credible interval areas plotted. xlab, ylab_long, ylab_event characture strings chracter vector ylab_long multiple longitudinal outcomes considered labels horizontal axis, two vertical axes. lwd_long, lwd_event, col_line_long, col_line_event, main,   fill_CI_long, fill_CI_event, cex_xlab, cex_ylab_long, cex_ylab_event, cex_main,   cex_axis, pch_points, col_points, cex_points, col_axis, bg graphical parameters; see par. pos_ylab_long controls position y-axis labels multiple longitudinal outcomes plotted. ylim_event ylim event outcome. ylim_long_outcome_range logical; TRUE, range y-axis spans across range outcome data used fit model; range values specific subject plotted. ... aguments passed control.","code":""},{"path":"https://drizopoulos.github.io/JMbayes2/reference/predict.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Predictions from Joint Models — Predictions","text":"detailed description methodology behind predictions given : https://drizopoulos.github.io/JMbayes2/articles/Dynamic_Predictions.html.","code":""},{"path":"https://drizopoulos.github.io/JMbayes2/reference/predict.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Predictions from Joint Models — Predictions","text":"Method predict() returns list data.frame (return_newdata set TRUE) predictions. Method plot() produces figures predictions single subject.","code":""},{"path":"https://drizopoulos.github.io/JMbayes2/reference/predict.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"Predictions from Joint Models — Predictions","text":"Dimitris Rizopoulos d.rizopoulos@erasmusmc.nl","code":""},{"path":[]},{"path":"https://drizopoulos.github.io/JMbayes2/reference/predict.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Predictions from Joint Models — Predictions","text":"","code":"# \\donttest{ # We fit a multivariate joint model pbc2.id$status2 <- as.numeric(pbc2.id$status != 'alive') CoxFit <- coxph(Surv(years, status2) ~ sex, data = pbc2.id) fm1 <- lme(log(serBilir) ~ ns(year, 3) * sex, data = pbc2,            random = ~ ns(year, 3) | id, control = lmeControl(opt = 'optim')) fm2 <- lme(prothrombin ~ ns(year, 2) * sex, data = pbc2,            random = ~ ns(year, 2) | id, control = lmeControl(opt = 'optim')) fm3 <- mixed_model(ascites ~ year * sex, data = pbc2,                    random = ~ year | id, family = binomial())  jointFit <- jm(CoxFit, list(fm1, fm2, fm3), time_var = \"year\", n_chains = 1L)  # we select the subject for whom we want to calculate predictions # we use measurements up to follow-up year 3; we also set that the patients # were alive up to this time point t0 <- 3 ND <- pbc2[pbc2$id %in% c(2, 25), ] ND <- ND[ND$year < t0, ] ND$status2 <- 0 ND$years <- t0  # predictions for the longitudinal outcomes using newdata predLong1 <- predict(jointFit, newdata = ND, return_newdata = TRUE)  # predictions for the longitudinal outcomes at future time points # from year 3 to 10 predLong2 <- predict(jointFit, newdata = ND,                      times = seq(t0, 10, length.out = 51),                      return_newdata = TRUE)  # predictions for the event outcome at future time points # from year 3 to 10 predSurv <- predict(jointFit, newdata = ND, process = \"event\",                     times = seq(t0, 10, length.out = 51),                     return_newdata = TRUE)  plot(predLong1)  # for subject 25, outcomes in reverse order plot(predLong2, outcomes = 3:1, subject = 25)     # prediction for the event outcome plot(predSurv)   # combined into one plot, the first longitudinal outcome and cumulative risk plot(predLong2, predSurv, outcomes = 1)   # the first two longitudinal outcomes plot(predLong1, predSurv, outcomes = 1:2)   # all three longitudinal outcomes, we display survival probabilities instead # of cumulative risk, and we transform serum bilirubin to the original scale plot(predLong2, predSurv, outcomes = 1:3, fun_event = function (x) 1 - x,      fun_long = list(exp, identity, identity),      ylab_event = \"Survival Probabilities\",      ylab_long = c(\"Serum Bilirubin\", \"Prothrombin\", \"Ascites\"),      pos_ylab_long = c(1.9, 1.9, 0.08))  # }"},{"path":"https://drizopoulos.github.io/JMbayes2/reference/prothro.html","id":null,"dir":"Reference","previous_headings":"","what":"Prednisone versus Placebo in Liver Cirrhosis Patients — prothro","title":"Prednisone versus Placebo in Liver Cirrhosis Patients — prothro","text":"randomized trial 488 liver cirrhosis patients.","code":""},{"path":"https://drizopoulos.github.io/JMbayes2/reference/prothro.html","id":"format","dir":"Reference","previous_headings":"","what":"Format","title":"Prednisone versus Placebo in Liver Cirrhosis Patients — prothro","text":"Two data frames following variables. id patients identifier; total 467 patients. pro prothrobin measurements. time data frame prothro time points prothrobin measurements taken;         data frame prothros time death censoring. death numeric vector 0 denoting censoring 1 death. treat randomized treatment; factor levels \"placebo\" \"prednisone\".","code":""},{"path":"https://drizopoulos.github.io/JMbayes2/reference/prothro.html","id":"source","dir":"Reference","previous_headings":"","what":"Source","title":"Prednisone versus Placebo in Liver Cirrhosis Patients — prothro","text":"http://www.gllamm.org/books/readme.html#14.6.","code":""},{"path":"https://drizopoulos.github.io/JMbayes2/reference/prothro.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Prednisone versus Placebo in Liver Cirrhosis Patients — prothro","text":"Andersen, P. K., Borgan, O., Gill, R. D. Keiding, N. (1993). Statistical Models Based Counting Processes. New York: Springer.","code":""},{"path":"https://drizopoulos.github.io/JMbayes2/reference/rc_setup.html","id":null,"dir":"Reference","previous_headings":"","what":"Combine Recurring and Terminal Event Data in Long Format — rc_setup","title":"Combine Recurring and Terminal Event Data in Long Format — rc_setup","text":"function combines two data frames, recurring-event terminal-event/competing-risks   datasets, one. subject many rows new data frame   number recurrent risk periods plus one terminal event/competing risk.","code":""},{"path":"https://drizopoulos.github.io/JMbayes2/reference/rc_setup.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Combine Recurring and Terminal Event Data in Long Format — rc_setup","text":"","code":"rc_setup(rc_data, trm_data,     idVar = \"id\", statusVar = \"status\",     startVar = \"start\", stopVar = \"stop\",     trm_censLevel,     nameStrata = \"strata\", nameStatus = \"status\")"},{"path":"https://drizopoulos.github.io/JMbayes2/reference/rc_setup.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Combine Recurring and Terminal Event Data in Long Format — rc_setup","text":"rc_data data frame containing recurring-event data       multiple rows per subject. trm_data data frame containing terminal-event/competing-risks       data single row per subject. idVar character string denoting name variable       rc_data trm_data identifies subject/group. statusVar character string denoting name variable       rc_data trm_data identifies status variable.       rc_data equals 1 subject event 0 otherwise.       trm_data equals event censoring level. startVar character string denoting name variable       rc_data identifies starting time risk interval. stopVar character string denoting name variable       rc_data trm_data identifies event censoring       time. trm_censLevel character string scalar denoting censoring     level statusVar variable trm_data. nameStrata character string denoting variable added       long version data denoting various causes event. nameStatus character string denoting variable added       long version data denoting subject event.","code":""},{"path":"https://drizopoulos.github.io/JMbayes2/reference/rc_setup.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Combine Recurring and Terminal Event Data in Long Format — rc_setup","text":"data frame long format multiple rows per subject.","code":""},{"path":"https://drizopoulos.github.io/JMbayes2/reference/rc_setup.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"Combine Recurring and Terminal Event Data in Long Format — rc_setup","text":"Pedro Miranda Afonso p.mirandaafonso@erasmusmc.nl","code":""},{"path":[]},{"path":"https://drizopoulos.github.io/JMbayes2/news/index.html","id":"major-0-6-0","dir":"Changelog","previous_headings":"","what":"Major","title":"JMbayes2 0.6.0","text":"jm() allows greater flexibility specifying baseline hazard function via control arguments basis, Bsplines_degree, base_hazard_segments, timescale_base_hazard. example, now piecewise-constant, piecewise-linear, Weibull baseline hazard functions possible. Also, possible extrapolate last event time basis = \"ns\". new function ppcheck() performs posterior predictive checks. Functions tvROC(), tvAUC() tvBrier() now also work Cox regression models.","code":""},{"path":[]},{"path":"https://drizopoulos.github.io/JMbayes2/news/index.html","id":"major-0-5-0","dir":"Changelog","previous_headings":"","what":"Major","title":"JMbayes2 0.5.0","text":"jm() now allows zero-correlations constraints covariance matrix random effects. mixed models provided Mixed_objects argument fitted assuming diagonal matrix random effects, also assumed joint model (previous versions, ignored). addition, new argument which_independent can used specify longitudinal outcomes assumed independent. jm() can fit joint models combination interval-censored data competing risks (e.g., one competing events interval-censored (s) ). bug predict() method causing low AUC values corrected. time-varying ROC AUC now allow correct censoring interval Tstart Thoriz using inverse probability censoring weighting. default remains model-based weights.","code":""},{"path":[]},{"path":"https://drizopoulos.github.io/JMbayes2/news/index.html","id":"major-0-4-1","dir":"Changelog","previous_headings":"","what":"Major","title":"JMbayes2 0.4.1","text":"Portable implementation parallel computing. function area() gained argument time_window specifies window integrating linear predictor corresponding longitudinal outcome.","code":""},{"path":[]},{"path":"https://drizopoulos.github.io/JMbayes2/news/index.html","id":"major-0-4-0","dir":"Changelog","previous_headings":"","what":"Major","title":"JMbayes2 0.4.0","text":"Function tvBrier() gained argument integrated calculating integrated Brier score. Function tvBrier() gained argument type_weights now also allows correct censoring interval Tstart Thoriz using inverse probability censoring weighting. default remains model-based weights. new function tvEPCE() calculates time-varying expected predictive cross-entropy. version supports Super Learning optimizing predictions using cross-validation library joint models. regard, new function create_folds() can used split dataset V-folds training test datasets. information can found corresponding vignette.","code":""},{"path":"https://drizopoulos.github.io/JMbayes2/news/index.html","id":"minor-0-4-0","dir":"Changelog","previous_headings":"","what":"Minor","title":"JMbayes2 0.4.0","text":"Weak informative priors now used fixed-effects mixed-effects models. Several improvements various internal functions.","code":""},{"path":[]},{"path":"https://drizopoulos.github.io/JMbayes2/news/index.html","id":"major-0-3-0","dir":"Changelog","previous_headings":"","what":"Major","title":"JMbayes2 0.3.0","text":"issue resulting wider expected credible intervals fixed-effects coefficients longitudinal submodels resolved.","code":""},{"path":"https://drizopoulos.github.io/JMbayes2/news/index.html","id":"minor-0-3-0","dir":"Changelog","previous_headings":"","what":"Minor","title":"JMbayes2 0.3.0","text":"Several improvements various internal functions.","code":""},{"path":[]},{"path":"https://drizopoulos.github.io/JMbayes2/news/index.html","id":"major-0-2-9","dir":"Changelog","previous_headings":"","what":"Major","title":"JMbayes2 0.2.9","text":"default placing knots B-spline approximation log baseline hazard changed. cause difference compared previous versions.","code":""},{"path":[]},{"path":"https://drizopoulos.github.io/JMbayes2/news/index.html","id":"major-0-2-0","dir":"Changelog","previous_headings":"","what":"Major","title":"JMbayes2 0.2.0","text":"Dynamic predictions competing risks data can now computed. example given Competing Risks vignette. Function jm() can now fit joint models recurrent event process without terminating event. model accommodates discontinuous risk intervals, time can defined terms gap calendar timescale. example given Recurrent Events vignette.","code":""},{"path":[]},{"path":"https://drizopoulos.github.io/JMbayes2/news/index.html","id":"major-0-1-7","dir":"Changelog","previous_headings":"","what":"Major","title":"JMbayes2 0.1.7","text":"Added function tvBrier() calculating time-varying Brier score fitted joint models. Currently, right-censored data supported. Added functions calibration_plot() calibration_metrics() calculating time-varying calibration plot calibration metrics fitted joint models. Currently, right-censored data supported. Added new section vignette Dynamic Prediction (available website package) showcase use functions mentioned .","code":""},{"path":"https://drizopoulos.github.io/JMbayes2/news/index.html","id":"minor-0-1-7","dir":"Changelog","previous_headings":"","what":"Minor","title":"JMbayes2 0.1.7","text":"Improved plot method dynamic predictions. Several bug corrections.","code":""},{"path":[]},{"path":"https://drizopoulos.github.io/JMbayes2/news/index.html","id":"major-0-1-6","dir":"Changelog","previous_headings":"","what":"Major","title":"JMbayes2 0.1.6","text":"Added predict() method jm objects corresponding plot() objects class predict_jm calculating displaying predictions joint models. Currently, standard survival models covered. Future versions include predictions competing risks multi-state models. Added functions tvROC() tvAUC() calculating time-varying Receiver Operating Characteristic (ROC) curves areas ROC curves fitted joint models. Currently, right-censored data supported. Added vignette (available website package) explain (dynamic) predictions calculated package.","code":""},{"path":[]},{"path":"https://drizopoulos.github.io/JMbayes2/news/index.html","id":"major-0-1-5","dir":"Changelog","previous_headings":"","what":"Major","title":"JMbayes2 0.1.5","text":"Added two vignettes (available website package) showcase joint models competing risks joint models non-Gaussian longitudinal outcomes. Simplified syntax additional options specifying transformation functions functional forms. slope() function gained two new arguments, eps direction. allows calculating difference longitudinal profile user-specified interval.","code":""},{"path":[]},{"path":"https://drizopoulos.github.io/JMbayes2/news/index.html","id":"minor-0-1-3","dir":"Changelog","previous_headings":"","what":"Minor","title":"JMbayes2 0.1.3","text":"Used parallel::clusterSetRNGStream() jm_fit() distributing seed workers. Changed default position knots B-spline approximation log baseline hazard.","code":""},{"path":[]},{"path":"https://drizopoulos.github.io/JMbayes2/news/index.html","id":"minor-0-1-2","dir":"Changelog","previous_headings":"","what":"Minor","title":"JMbayes2 0.1.2","text":"Changed calls floor() C++ code.","code":""},{"path":[]},{"path":"https://drizopoulos.github.io/JMbayes2/news/index.html","id":"general-0-1-0","dir":"Changelog","previous_headings":"","what":"General","title":"JMbayes2 0.1.0","text":"First version package.","code":""}]
